{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ec4ecc40-57c6-46c8-bad0-0ade6e8aa60c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model(\n",
      "  (conv1): Conv2d(1, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(20, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "## Containers\n",
    "\n",
    "## Modules\n",
    "\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1  =nn.Conv2d(1,20,5)\n",
    "        self.conv2 = nn.Conv2d(20,20,5)\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv1(x))\n",
    "        return x\n",
    "    \n",
    "model = Model()\n",
    "\n",
    "print(model)\n",
    "\n",
    "dummy_input = torch.randn(1,1,28,28)\n",
    "\n",
    "# output = model(dummy_input)\n",
    "\n",
    "# print(\"Output shape:\", output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5d2ce9a3-25f0-421d-b825-248b2298f3ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DynamicModel(\n",
      "  (input_layer): Linear(in_features=10, out_features=20, bias=True)\n",
      "  (hidden_layer_1): Linear(in_features=20, out_features=30, bias=True)\n",
      "  (hidden_layer_2): Linear(in_features=30, out_features=40, bias=True)\n",
      "  (output_layer): Linear(in_features=40, out_features=5, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "## add_module\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class DynamicModel(nn.Module):\n",
    "    def __init__(self,input_size,hidden_sizes,output_size):\n",
    "        super().__init__()\n",
    "\n",
    "        self.add_module('input_layer',nn.Linear(input_size,hidden_sizes[0]))\n",
    "\n",
    "        #Hidden Layers\n",
    "        for i, hidden_size in enumerate(hidden_sizes):\n",
    "            if i > 0:\n",
    "                layer_name = f'hidden_layer_{i}'\n",
    "                self.add_module(layer_name, nn.Linear(hidden_sizes[i-1], hidden_size))\n",
    "\n",
    "        #output layer\n",
    "        self.add_module('output_layer',nn.Linear(hidden_sizes[-1], output_size))\n",
    "\n",
    "    def forward(self,x):\n",
    "        for name, module in self.named_children():\n",
    "            x = torch.relu(module(x))\n",
    "        return x\n",
    "    \n",
    "\n",
    "input_size = 10\n",
    "\n",
    "hidden_sizes = [20,30,40]\n",
    "\n",
    "output_sizes = 5\n",
    "\n",
    "model = DynamicModel(input_size, hidden_sizes, output_sizes)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3311bcd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CustomModel(\n",
      "  (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (fc_layers): Sequential(\n",
      "    (0): Linear(in_features=896, out_features=128, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=128, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# add_module, adding predefined modules\n",
    "\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "\n",
    "class CustomModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        \n",
    "        super().__init__()\n",
    "\n",
    "        self.add_module('conv1', nn.Conv2d(1,32,kernel_size=3, stride=1, padding=1))\n",
    "\n",
    "        sequential_layers = nn.Sequential(\n",
    "            nn.Linear(32 * 28 , 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128,10)\n",
    "        )\n",
    "\n",
    "        self.add_module('fc_layers', sequential_layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.conv1(x)) #apply ReLU after convolution\n",
    "        x = x.view(x.size(0),-1)        #flatter the tensor\n",
    "        x = self.fc_layers(x)           # pass through the sequential layers\n",
    "\n",
    "#example usage\n",
    "model = CustomModel()\n",
    "print(model)\n",
    "\n",
    "#test the model with dummy input\n",
    "dummy_input = torch.randn(1,1,28,28)\n",
    "# output = model(dummy_input)\n",
    "# print(\"Output shape\",output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4266a71e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized weights of input_layer:\n",
      "Parameter containing:\n",
      "tensor([[-0.3189, -0.1001,  0.0435, -0.0555, -0.2206,  0.3877,  0.2900, -0.4394,\n",
      "         -0.0062,  0.2300],\n",
      "        [-0.3620, -0.1434,  0.2258, -0.1466,  0.2818, -0.2664,  0.2420, -0.1008,\n",
      "          0.3838,  0.3238],\n",
      "        [-0.3508, -0.4227, -0.0360,  0.0292, -0.4013,  0.2699, -0.1715,  0.1462,\n",
      "          0.0721,  0.4111],\n",
      "        [ 0.0515,  0.2634, -0.2497,  0.3960, -0.1172, -0.2831,  0.0980,  0.0502,\n",
      "         -0.0728, -0.2099],\n",
      "        [-0.4028, -0.2895, -0.2639, -0.4414,  0.3371, -0.0018,  0.3418, -0.2585,\n",
      "         -0.0889,  0.2634],\n",
      "        [-0.0484,  0.2885,  0.3568,  0.1521,  0.0667,  0.3111, -0.3108,  0.1520,\n",
      "          0.2754,  0.2477],\n",
      "        [ 0.1167, -0.2664, -0.2696, -0.3815, -0.0566,  0.2637,  0.2939, -0.2938,\n",
      "          0.2794,  0.3037],\n",
      "        [ 0.4436,  0.2564,  0.2436, -0.3032, -0.0301,  0.3401, -0.1926, -0.1543,\n",
      "          0.1444, -0.1874],\n",
      "        [-0.2768,  0.1304, -0.4417, -0.2970, -0.2713, -0.1505,  0.3054, -0.3146,\n",
      "          0.2692, -0.0085],\n",
      "        [ 0.4446,  0.2682,  0.0197,  0.1345,  0.0522, -0.3952, -0.0715, -0.3065,\n",
      "          0.3863, -0.0228],\n",
      "        [ 0.0122, -0.0135,  0.4071,  0.3497, -0.1295, -0.2777, -0.3156, -0.2405,\n",
      "          0.4368, -0.1548],\n",
      "        [ 0.0386, -0.1730, -0.4398,  0.2734, -0.0786, -0.4013, -0.0097, -0.4454,\n",
      "         -0.1173,  0.4065],\n",
      "        [ 0.1256, -0.0836, -0.1938,  0.3117, -0.0616, -0.1088,  0.1257, -0.0809,\n",
      "         -0.1923, -0.2630],\n",
      "        [-0.4351,  0.2548, -0.2129, -0.0719, -0.0990, -0.3179, -0.1735, -0.2096,\n",
      "         -0.0214, -0.4165],\n",
      "        [-0.1324,  0.4363,  0.1585, -0.2600, -0.0047,  0.3543,  0.3872, -0.0148,\n",
      "          0.0569, -0.0956],\n",
      "        [ 0.0802,  0.3596,  0.1570, -0.0631, -0.4467,  0.3036, -0.0944, -0.0638,\n",
      "         -0.1506, -0.1038],\n",
      "        [-0.3177, -0.2271, -0.0447,  0.3379,  0.2533,  0.0039,  0.3141, -0.2741,\n",
      "          0.4330, -0.2474],\n",
      "        [ 0.3454, -0.1362, -0.0643, -0.3449, -0.2171,  0.1571, -0.1023, -0.0461,\n",
      "          0.3734,  0.4104],\n",
      "        [ 0.4420,  0.2549, -0.2980,  0.2233, -0.4047, -0.0682, -0.3600,  0.1502,\n",
      "         -0.3566,  0.4434],\n",
      "        [-0.3054, -0.4307,  0.2650,  0.2031,  0.0135,  0.3681, -0.0345,  0.4231,\n",
      "         -0.3044,  0.2158]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# apply(fn) Weight Initializatins\n",
    "\n",
    "# use to initialize the weights of all layers in a neural network using a custom initialization function\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "#define a custom weight initialization function\n",
    "def init_weights(m):\n",
    "    if isinstance(m,nn.Linear): # check if the module is a LInear layer\n",
    "        nn.init.xavier_uniform_(m.weight) #Xavier initializaiton for weights\n",
    "        if m.bias is not None:\n",
    "            nn.init.zeros_(m.bias) #zero-initializae biases\n",
    "\n",
    "class FeedForwardNet(nn.Module):\n",
    "    def __init__(self, input_size, hidden_sizes, output_size):\n",
    "        super().__init__()\n",
    "        self.input_layer = nn.Linear(input_size, hidden_sizes[0])\n",
    "        self.hidden_layers = nn.ModuleList([\n",
    "            nn.Linear(hidden_sizes[i],hidden_sizes[i + 1]) for i in range(len(hidden_sizes) - 1)\n",
    "        ])\n",
    "        self.output_layer = nn.Linear(hidden_sizes[-1],output_size)\n",
    "    def forward(self,x):\n",
    "        x = torch.relu(self.input_layers(x))\n",
    "        for layer in self.hidden_layers:\n",
    "            x = torch.relu(layer(x))\n",
    "        return self.output_layer(x)\n",
    "    \n",
    "input_size = 10\n",
    "hidden_sizes = [20,30,40]\n",
    "output_size = 5\n",
    "model = FeedForwardNet(input_size, hidden_sizes, output_size)\n",
    "\n",
    "#apply the weight initialization function to all layers\n",
    "model.apply(init_weights)\n",
    "\n",
    "#print the initialized weights of the first layer \n",
    "print(\"Initialized weights of input_layer:\")\n",
    "print(model.input_layer.weight)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ad3dc07b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fc1.weight: requires_grad = False\n",
      "fc1.bias: requires_grad = False\n",
      "fc2.weight: requires_grad = False\n",
      "fc2.bias: requires_grad = False\n",
      "fc3.weight: requires_grad = False\n",
      "fc3.bias: requires_grad = False\n"
     ]
    }
   ],
   "source": [
    "#apply(fn) Freezing Layers\n",
    "\n",
    "# use to freeze specific layers (disable gradient computation) in a model\n",
    "\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "\n",
    "def freeze_layers(m):\n",
    "    if isinstance(m, nn.Linear): #Freeze only Linear layers\n",
    "        for param in m.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "\n",
    "class SimpleModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(10,20)\n",
    "        self.fc2 = nn.Linear(20,30)\n",
    "        self.fc3 = nn.Linear(30,5)\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        return self.fc3(x)\n",
    "    \n",
    "\n",
    "#create the model\n",
    "model = SimpleModel()\n",
    "\n",
    "#apply the freeze function to all layers\n",
    "model.apply(freeze_layers)\n",
    "\n",
    "for name,param in model.named_parameters():\n",
    "    print(f\"{name}: requires_grad = {param.requires_grad}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "74b305ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layers: Conv2d, Parameters: 320\n",
      "Layers: Conv2d, Parameters: 320\n",
      "Layers: Linear, Parameters: 401536\n",
      "Layers: Linear, Parameters: 1290\n",
      "Layers: ConvNet, Parameters: 403466\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ConvNet(\n",
       "  (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv2): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (fc1): Linear(in_features=3136, out_features=128, bias=True)\n",
       "  (fc2): Linear(in_features=128, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#apply(fn) Logging Layer Informations\n",
    "\n",
    "#log each layer information in the model\n",
    "\n",
    "#define a loggin function\n",
    "\n",
    "def log_layers(m):\n",
    "    print(f\"Layers: {m.__class__.__name__}, Parameters: {sum(p.numel() for p in m.parameters())}\")\n",
    "\n",
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1,32,kernel_size = 3, stride=1, padding = 1)\n",
    "        self.conv2 = nn.Conv2d(1,32,kernel_size = 3, stride=1, padding = 1)\n",
    "        self.fc1 = nn.Linear(64 * 7 * 7 , 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = torch.relu(self.conv1(x))\n",
    "        x = torch.max_pool2d(x,2)\n",
    "        x = torch.relu(self.conv2(x))\n",
    "        x = torch.max_pool2d(x,2)\n",
    "        x = x.view(x.size(0) - 1)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        return self.fc2(x)\n",
    "\n",
    "model = ConvNet()\n",
    "model.apply(log_layers)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b6b76d8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before bfloat16 conversion\n",
      "fc1.weight:torch.float32\n",
      "fc1.bias:torch.float32\n",
      "fc2.weight:torch.float32\n",
      "fc2.bias:torch.float32\n",
      "fc3.weight:torch.float32\n",
      "fc3.bias:torch.float32\n",
      "\n",
      "After bfloat16 conversion:\n",
      "fc1.weight:torch.bfloat16\n",
      "fc1.bias:torch.bfloat16\n",
      "fc2.weight:torch.bfloat16\n",
      "fc2.bias:torch.bfloat16\n",
      "fc3.weight:torch.bfloat16\n",
      "fc3.bias:torch.bfloat16\n",
      "\n",
      " Output shape torch.Size([1, 5])\n",
      "Output dtype: torch.bfloat16\n"
     ]
    }
   ],
   "source": [
    "#bloat16()\n",
    "\n",
    "# to cast all floating-point parameters and buffer of a model to bfloat16 data type.mro\n",
    "\n",
    "# this is particularly supports bfloat16 ,suc as moden CPUs or TPUs\n",
    "\n",
    "import torch \n",
    "\n",
    "import torch.nn as nn\n",
    "\n",
    "#define a simple neural network\n",
    "class SimpleModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(10,20)\n",
    "        self.fc2 = nn.Linear(20,30)\n",
    "        self.fc3 = nn.Linear(30,5)\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        return self.fc3(x)\n",
    "    \n",
    "#create the model\n",
    "model = SimpleModel()\n",
    "\n",
    "#print the initial data types of the parameters\n",
    "print('before bfloat16 conversion')\n",
    "for name, param, in model.named_parameters():\n",
    "    print(f\"{name}:{param.dtype}\")\n",
    "\n",
    "\n",
    "#convert the model to bfloat16\n",
    "model = model.bfloat16()\n",
    "\n",
    "#print the data types after the conversion\n",
    "print(\"\\nAfter bfloat16 conversion:\")\n",
    "for name, param in model.named_parameters():\n",
    "    print(f\"{name}:{param.dtype}\")\n",
    "\n",
    "#test the model with dummy input in bfloat16\n",
    "dummy_input = torch.rand(1,10,dtype=torch.bfloat16) #input in bfloat16\n",
    "output = model(dummy_input)\n",
    "print(\"\\n Output shape\", output.shape)\n",
    "print(\"Output dtype:\", output.dtype)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ff50e566",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all buffers (recurse = True):\n",
      "<class 'torch.Tensor'> torch.Size([20])\n",
      "<class 'torch.Tensor'> torch.Size([5, 10])\n",
      "<class 'torch.Tensor'> torch.Size([30])\n",
      "<class 'torch.Tensor'> torch.Size([30])\n",
      "<class 'torch.Tensor'> torch.Size([])\n",
      "<class 'torch.Tensor'> torch.Size([20])\n",
      "<class 'torch.Tensor'> torch.Size([5, 10])\n"
     ]
    }
   ],
   "source": [
    "#buffer(recursive = True)\n",
    "\n",
    "# used to iterate over all buffers of a module (and optionally its submodules) . Buffers are tensors that are part fo the module but are not trainable parameters.\n",
    "# Example include running statistics in BatchNorm layers or fixed embeddings\n",
    "\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "\n",
    "#define a model with buffers\n",
    "class MyModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        #trainable parameters\n",
    "        self.fc1 = nn.Linear(10,20)\n",
    "        self.fc2 = nn.Linear(20,30)\n",
    "\n",
    "        #registering buffers\n",
    "        self.register_buffer(\"running mean\", torch.zeros(20))\n",
    "        self.register_buffer(\"fixed_embeddings\", torch.randn(5,10))\n",
    "\n",
    "        #submodule with its own buffer\n",
    "        self.submodule = nn.BatchNorm1d(30)\n",
    "\n",
    "    def forwar(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        return self.submodule(x)\n",
    "    \n",
    "\n",
    "model = MyModel()\n",
    "\n",
    "print(\"all buffers (recurse = True):\")\n",
    "for buf in model.buffers(recurse = True):\n",
    "    print(type(buf), buf.size())\n",
    "\n",
    "#interate over only direct buffers (recurse = False)\n",
    "for buf in model.buffers(recurse = False):\n",
    "    print(type(buf),buf.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b865421b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 5])\n"
     ]
    }
   ],
   "source": [
    "# compile() \n",
    "\n",
    "# powerful feature introduced to optimize the execution of models by leveraging advanced compiler techniques\n",
    "# compiles forward method of a torch.nn.Module using torch.compile() which can significantly imporve performance by optmizing the model computation graph\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class SimpleModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(10,20)\n",
    "        self.fc2 = nn.Linear(20,30)\n",
    "        self.fc3 = nn.Linear(30,5)\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        return self.fc3(x)\n",
    "\n",
    "#create model and move it to the appropriate device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = SimpleModel().to(device)\n",
    "\n",
    "#compile the model\n",
    "compiled_model = torch.compile(model) #equivalent to calling model.compile\n",
    "\n",
    "dummy_input = torch.randn(16,10,device = device)\n",
    "\n",
    "output = compiled_model(dummy_input)\n",
    "\n",
    "print(\"Output shape:\", output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "de1471b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 5])\n"
     ]
    }
   ],
   "source": [
    "# compile() Customization of compile\n",
    "\n",
    "compiled_model = torch.compile(\n",
    "    model,\n",
    "    backend = \"inductor\",\n",
    "    fullgraph=True,\n",
    "    dynamic=False\n",
    ")\n",
    "\n",
    "output = compiled_model(dummy_input)\n",
    "print(\"Output shape:\", output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e6bce5bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial device of parameters\n",
      "fc1.weight:cpu\n",
      "fc1.bias:cpu\n",
      "fc2.weight:cpu\n",
      "fc2.bias:cpu\n",
      "fc3.weight:cpu\n",
      "fc3.bias:cpu\n",
      "\n",
      " Device of parameters after moving to GPU:\n",
      "fc1.weight:cpu\n",
      "fc1.bias:cpu\n",
      "fc2.weight:cpu\n",
      "fc2.bias:cpu\n",
      "fc3.weight:cpu\n",
      "fc3.bias:cpu\n",
      "\n",
      " Output shape: torch.Size([16, 5])\n",
      "Output device cpu\n"
     ]
    }
   ],
   "source": [
    "#cuda(device = None)\n",
    "\n",
    "#used to move al model parameters and buffer to a GPU for a sepcifc GPU if multiple are avaiable.\n",
    "# important when you want to leverage GPU accelration for trainng or inference\n",
    "\n",
    "import torch \n",
    "import torch.nn as nn \n",
    "\n",
    "#define a simple neural network\n",
    "class SimpleMethod(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(10,20)\n",
    "        self.fc2 = nn.Linear(20,30)\n",
    "        self.fc3 = nn.Linear(30,5)\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        return self.fc3(x)\n",
    "    \n",
    "model = SimpleModel()\n",
    "\n",
    "#check the initial device of the model's parameters\n",
    "print(\"Initial device of parameters\")\n",
    "\n",
    "for name , param in model.named_parameters():\n",
    "    print(f\"{name}:{param.device}\")\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "#verify that the model's parameters are now on the GPU\n",
    "print(\"\\n Device of parameters after moving to GPU:\")\n",
    "#move the model to the GPU\n",
    "for name, param in model.named_parameters():\n",
    "    print(f\"{name}:{param.device}\")\n",
    "\n",
    "#create dummy input data and move it to the same device\n",
    "dummy_input = torch.rand(16,10).to(device)\n",
    "\n",
    "output = model(dummy_input)\n",
    "print(\"\\n Output shape:\", output.shape)\n",
    "print(\"Output device\", output.device)\n",
    "    \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ee7c10d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before double conversation\n",
      "fc1.weight: torch.float32\n",
      "fc1.bias: torch.float32\n",
      "fc2.weight: torch.float32\n",
      "fc2.bias: torch.float32\n",
      "fc3.weight: torch.float32\n",
      "fc3.bias: torch.float32\n",
      "\n",
      " After double conversation:\n",
      "fc1.weight:torch.float64\n",
      "fc1.bias:torch.float64\n",
      "fc2.weight:torch.float64\n",
      "fc2.bias:torch.float64\n",
      "fc3.weight:torch.float64\n",
      "fc3.bias:torch.float64\n",
      "\n",
      " OUtput shape: torch.Size([1, 5])\n",
      "Output dtype: torch.float64\n"
     ]
    }
   ],
   "source": [
    "#double cast all floating-point paramets and buffer of a model to the torch.float64 \n",
    "\n",
    "import torch \n",
    "import torch.nn as nn \n",
    "\n",
    "class SimpleModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(10,20)\n",
    "        self.fc2 = nn.Linear(20,30)\n",
    "        self.fc3 = nn.Linear(30,5)\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        return self.fc3(x)\n",
    "    \n",
    "model = SimpleModel()\n",
    "\n",
    "print(\"Before double conversation\")\n",
    "for name, param in model.named_parameters():\n",
    "    print(f\"{name}: {param.dtype}\")\n",
    "\n",
    "#convert the model to double precision\n",
    "model = model.double()\n",
    "\n",
    "print(\"\\n After double conversation:\")\n",
    "for name, param in model.named_parameters():\n",
    "    print(f\"{name}:{param.dtype}\")\n",
    "\n",
    "#test the model with dummy input in double precision\n",
    "dummy_input = torch.randn(1,10, dtype=torch.float64) #input in double precision\n",
    "output = model(dummy_input)\n",
    "\n",
    "print(\"\\n OUtput shape:\", output.shape)\n",
    "print(\"Output dtype:\", output.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "48f53bd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model in training mode:\n",
      "MyModel(\n",
      "  (fc1): Linear(in_features=10, out_features=20, bias=True)\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      "  (bn): BatchNorm1d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (fc2): Linear(in_features=20, out_features=5, bias=True)\n",
      ")\n",
      "\n",
      " Outout in training mode: tensor([[-0.3455, -0.6189,  0.7044, -1.5280,  0.4210],\n",
      "        [-0.9519, -0.2885,  0.3518,  1.1750,  0.5380],\n",
      "        [-0.1468,  0.4640, -0.1338, -0.0340, -0.7176],\n",
      "        [ 0.6771,  0.6091, -0.5829,  0.2539, -0.6382]],\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "\n",
      " Model in evaluation mode:\n",
      "MyModel(\n",
      "  (fc1): Linear(in_features=10, out_features=20, bias=True)\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      "  (bn): BatchNorm1d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (fc2): Linear(in_features=20, out_features=5, bias=True)\n",
      ")\n",
      "\n",
      " Output in evaluation mode: tensor([[-0.1544,  0.3611, -0.0028, -0.3084, -0.1717],\n",
      "        [-0.1890,  0.0386,  0.1557,  0.0462, -0.0052],\n",
      "        [ 0.0559,  0.0224, -0.1005, -0.2568, -0.1569],\n",
      "        [ 0.0126,  0.0644, -0.1864, -0.1334, -0.1827]])\n"
     ]
    }
   ],
   "source": [
    "#eval()\n",
    "\n",
    "# used to set model into evaluatio mode. important for certain layers or modules that behave diferently during raining and evaliatons\n",
    "# for example dropout, randomly drops units during raining but does not drop any units during evaluation\n",
    "# also batchnorm uses running statistics (mean and variance) during evaluation instead of batch statistics\n",
    "\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "\n",
    "#define a model with dropout and batchnorm layers\n",
    "class MyModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(10,20)\n",
    "        self.dropout = nn.Dropout(p = 0.5)\n",
    "        self.bn = nn.BatchNorm1d(20)\n",
    "        self.fc2 = nn.Linear(20,5)\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.bn(x)\n",
    "        return self.fc2(x)\n",
    "    \n",
    "model = MyModel()\n",
    "\n",
    "model.train()\n",
    "print(\"Model in training mode:\")\n",
    "print(model)\n",
    "\n",
    "#perform a forward pass with training mode\n",
    "dummy_input = torch.randn(4,10)\n",
    "output_train = model(dummy_input)\n",
    "print(\"\\n Outout in training mode:\", output_train)\n",
    "\n",
    "#set the model to evaluation mode\n",
    "model.eval()\n",
    "print(\"\\n Model in evaluation mode:\")\n",
    "print(model)\n",
    "\n",
    "#perform a forward pass with evaluatin mode\n",
    "with torch.no_grad():\n",
    "    output_eval = model(dummy_input)\n",
    "print(\"\\n Output in evaluation mode:\", output_eval)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "40ed8bc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MyModel(\n",
      "  running mean: torch.Size([20]), fixed_embeddings: torch.Size([5, 10])\n",
      "  (fc1): Linear(in_features=10, out_features=20, bias=True)\n",
      "  (fc2): Linear(in_features=20, out_features=30, bias=True)\n",
      "  (submodule): BatchNorm1d(30, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "#extra_repr\n",
    "#override extra_repr methdinclude information about buffer \n",
    "\n",
    "import torch \n",
    "import torch.nn as nn \n",
    "\n",
    "#define a model with buffer\n",
    "class MyModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        #trainable parameters\n",
    "        self.fc1 = nn.Linear(10,20)\n",
    "        self.fc2 = nn.Linear(20,30)\n",
    "\n",
    "        #registering buffers\n",
    "        self.register_buffer(\"running_mean\", torch.zeros(20))\n",
    "        self.register_buffer(\"fixed_embeddings\", torch.randn(5,10))\n",
    "        self.submodule = nn.BatchNorm1d(30)\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        return self.submodule(x)\n",
    "    \n",
    "    def extra_repr(self):\n",
    "        return f\"running mean: {self.running_mean.size()}, fixed_embeddings: {self.fixed_embeddings.size()}\"\n",
    "\n",
    "#instantiate the model\n",
    "model = MyModel()\n",
    "# print the model to see the extra represenation\n",
    "print(model)\n",
    "    \n",
    "\"\"\"\"\n",
    "this method is overriden to return a strin that provides additional information about the module,\n",
    "\n",
    "it returns the sizes of the running_mean and fixed_embeddings buffers\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "535bfeec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before float():\n",
      "Weight datatype: torch.float32\n",
      "Runnign mean datatype: torch.float32\n",
      "\n",
      " After float():\n",
      "Weight datatype: torch.float32\n",
      "Running mean datatype torch.float32\n",
      "\n",
      " After float() again:\n",
      "Weight datatpye: torch.float64\n",
      "running mean datatype: torch.float64\n"
     ]
    }
   ],
   "source": [
    "#float \n",
    "\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "\n",
    "#define a simpel model with paraemters and buffers\n",
    "\n",
    "class MyModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        #trainable parameter (default is float32)\n",
    "        self.weight = nn.Parameter(torch.randn(3,3))\n",
    "\n",
    "        #buffer (default is float32)\n",
    "        self.register_buffer(\"running_mean\", torch.zeros(3))\n",
    "\n",
    "    def forward(self,x):\n",
    "        return x @ self.weight + self.running_mean\n",
    "    \n",
    "model = MyModel()\n",
    "\n",
    "#print the datatype of parameters and buffers before casting\n",
    "print(\"Before float():\")\n",
    "print(\"Weight datatype:\", model.weight.dtype)\n",
    "\n",
    "print(\"Runnign mean datatype:\", model.running_mean.dtype)\n",
    "\n",
    "#cast all parameters and buffers to float (32-bit floating point)\n",
    "model.float()\n",
    "\n",
    "#print the datatype of parameters and buffers after casting\n",
    "print(\"\\n After float():\")\n",
    "print(\"Weight datatype:\", model.weight.dtype)\n",
    "print(\"Running mean datatype\", model.running_mean.dtype)\n",
    "\n",
    "\n",
    "model.double() #cast double precision\n",
    "print(\"\\n After float() again:\")\n",
    "print(\"Weight datatpye:\", model.weight.dtype)\n",
    "print(\"running mean datatype:\", model.running_mean.dtype)\n",
    "\n",
    "# casts all floating point parameter and buffer of the mode to the float datatpye torch.float32 \n",
    "\n",
    "# dtyoe attrubte fo tensor indicates datatypes, by default pytorch uses toch.float32 \n",
    "\n",
    "# float() double() is a in-place modification so no need to reassign the results.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f1324d8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input tensor shape torch.Size([5, 10])\n",
      "Output tensor shape: torch.Size([5, 10])\n",
      "Output tensor:\n",
      " tensor([[-0.3420,  0.0117,  0.1513, -0.1669,  0.2344, -0.3389, -0.1194, -0.0338,\n",
      "         -0.0648,  0.0806],\n",
      "        [-0.0349,  0.1871,  0.2086, -0.0350,  0.3173, -0.3457, -0.0485, -0.0875,\n",
      "         -0.2528,  0.0297],\n",
      "        [-0.1342,  0.1871,  0.2244, -0.2599,  0.1047, -0.1203, -0.0630, -0.2873,\n",
      "          0.1868,  0.4255],\n",
      "        [-0.0844,  0.2295,  0.1941, -0.0726,  0.1734, -0.4147, -0.2767, -0.2628,\n",
      "         -0.1395,  0.1654],\n",
      "        [-0.2090,  0.2179,  0.0762,  0.2524,  0.3752,  0.1334,  0.0876, -0.1751,\n",
      "         -0.0287,  0.1636]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "#forward \n",
    "\n",
    "#you should call model(x) directly instead of caling method.forward()\n",
    "# this ensure that all any register hoooks (pre-forward , post-forward ) are executed. \n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class MyModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(10,20) #fully connected layer 1\n",
    "        self.fc2 = nn.Linear(20,10) # fully connected layer 2\n",
    "        self.relu = nn.ReLU() #activation function\n",
    "\n",
    "    def forward(self,x):\n",
    "        #define the foward pass\n",
    "        x = self.fc1(x) #pass input throgu the first layer\n",
    "        x = self.relu(x) #apply ReLU activation \n",
    "        x = self.fc2(x) #pass through the second layer \n",
    "        return x \n",
    "    \n",
    "model = MyModel()\n",
    "\n",
    "#craete a random input tensor\n",
    "input_tensor = torch.randn(5,10)\n",
    "# batch of 5 samples , each with 10 features\n",
    "\n",
    "#perform forward pass by calling model\n",
    "output = model(input_tensor)\n",
    "\n",
    "print(\"input tensor shape\", input_tensor.shape)\n",
    "print(\"Output tensor shape:\", output.shape)\n",
    "print(\"Output tensor:\\n\", output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd0a1191",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved 'running_mean' buffer:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "\n",
      "Retrieved 'fixed_embeddings' buffer:\n",
      "tensor([[-0.0379, -0.1254, -0.2757, -0.8203,  2.3026, -0.7584, -0.7222, -0.3929,\n",
      "          1.5857, -0.5442],\n",
      "        [ 0.8620,  0.5481, -0.0808, -1.3729, -0.0415,  0.2268,  1.9648,  0.1972,\n",
      "          0.1739, -0.7899],\n",
      "        [-1.8245,  0.7981,  0.7574,  0.3576, -0.0595,  0.8876,  0.1681,  1.2019,\n",
      "         -0.3573, -1.1934],\n",
      "        [ 0.3252,  1.9988,  1.9587, -0.1001, -0.7791, -0.1302, -0.7127, -1.3451,\n",
      "          0.0548,  0.5923],\n",
      "        [ 0.4716,  1.1301,  0.8396, -0.0492,  0.6691,  1.9465, -0.1013,  0.0844,\n",
      "         -1.1672, -1.7064]])\n",
      "\n",
      "Retrieved 'submodule.running_var' buffer:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])\n",
      "\n",
      "Error: MyModel has no attribute `non_existent_buffer`\n"
     ]
    }
   ],
   "source": [
    "#get_buffer(target)\n",
    "\n",
    "# retrieve a specific buffer from a module using fully-qualified string name. \n",
    "# buffer are non-trainable tensors that are part of the module's state such as runnig statistics in BatchNorm\n",
    "\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "\n",
    "class MyModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        #register buffers\n",
    "        self.register_buffer(\"running_mean\", torch.zeros(10))\n",
    "\n",
    "        self.register_buffer(\"fixed_embeddings\", torch.randn(5,10))\n",
    "\n",
    "        # add a submodule with its own buffer \n",
    "        self.submodule = nn.BatchNorm1d(10)\n",
    "        self.submodule.register_buffer(\"running_var\", torch.ones(10)) # buffer in submodule\n",
    "\n",
    "    def forward(self,x):\n",
    "        return self.submodule(x)\n",
    "    \n",
    "#instantiate the model\n",
    "model = MyModel()\n",
    "\n",
    "try:\n",
    "    #get the  running_mean buffer from the main module\n",
    "    running_mean = model.get_buffer(\"running_mean\")\n",
    "    print(\"Retrieved 'running_mean' buffer:\")\n",
    "    print(running_mean)\n",
    "\n",
    "    #get the fixed_embeddigngs buffer fromt eh main module\n",
    "    fixed_embeddings = model.get_buffer(\"fixed_embeddings\")\n",
    "    print(\"\\nRetrieved 'fixed_embeddings' buffer:\")\n",
    "    print(fixed_embeddings)\n",
    "\n",
    "    #get the running_var buffer from the submodule\n",
    "\n",
    "    running_var = model.get_buffer(\"submodule.running_var\")\n",
    "    print(\"\\nRetrieved 'submodule.running_var' buffer:\")\n",
    "    print(running_var)\n",
    "\n",
    "    #attempt to get a non-existent buffer (will raiase error)\n",
    "    non_existent_buffer = model.get_buffer(\"non_existent_buffer\")\n",
    "\n",
    "except AttributeError as e:\n",
    "    print(f\"\\nError: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9f8b2fa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial extra state: {'description': 'this is extra state', 'version': 1.0}\n",
      "\n",
      " Modified extra state: {'description': 'this is extra state', 'version': 2.0}\n",
      "\n",
      " Restored extra state: {'description': 'this is extra state', 'version': 2.0}\n"
     ]
    }
   ],
   "source": [
    "#get_extra_sate() \n",
    "\n",
    "#return any additional state that should be included in module's state_dict\n",
    "\n",
    "import torch \n",
    "import torch.nn as nn \n",
    "\n",
    "class MyModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        #trainable parameter\n",
    "        self.weight = nn.Parameter(torch.randn(3,3))\n",
    "\n",
    "        #extra state (non-tensor object)\n",
    "        self.extra_state = {\"description\":\"this is extra state\",\"version\": 1.0}\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x @ self.weight \n",
    "\n",
    "    def get_extra_state(self):\n",
    "        #return the extra state to be saved in the state_dict\n",
    "        return self.extra_state\n",
    "    \n",
    "    def set_extra_state(self,state):\n",
    "        self.extra_state = state \n",
    "\n",
    "model = MyModel()\n",
    "\n",
    "# here we print the model's initial extra state\n",
    "print(\"Initial extra state:\", model.extra_state)\n",
    "\n",
    "state_dict = model.state_dict()\n",
    "\n",
    "#modify the extra state \n",
    "model.extra_state['version'] = 2.0 \n",
    "print('\\n Modified extra state:', model.extra_state)\n",
    "\n",
    "#load the saved state_dict (restoring the original extra state)\n",
    "model.load_state_dict(state_dict)\n",
    "\n",
    "#print the restored extra state\n",
    "print('\\n Restored extra state:', model.extra_state)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "98c7fe6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved 'weight parameter:\n",
      "Parameter containing:\n",
      "tensor([[ 0.7960,  1.2377, -0.7411],\n",
      "        [-0.1748, -2.5137, -0.2854],\n",
      "        [ 0.8596,  0.8421, -0.4042]], requires_grad=True)\n",
      "\n",
      " Retrieved bias parameter:\n",
      "Parameter containing:\n",
      "tensor([0., 0., 0.], requires_grad=True)\n",
      "\n",
      "Retrieved submodule.weight parameter:\n",
      "Parameter containing:\n",
      "tensor([[ 0.5092,  0.0822,  0.1512],\n",
      "        [ 0.2763,  0.5701, -0.4478],\n",
      "        [-0.2466, -0.5344, -0.0660]], requires_grad=True)\n",
      "\n",
      "Error: MyModel has no attribute `non_existet_param`\n"
     ]
    }
   ],
   "source": [
    "#get_parameter(target)\n",
    "\n",
    "# retrieve specific parameter from a module using fully-qualified string name. \n",
    "# parameters are trainable tensors that are part of the module's state\n",
    "\n",
    "import torch \n",
    "import torch.nn as nn \n",
    "\n",
    "class MyModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        #define trainable parameters \n",
    "        self.weight = nn.Parameter(torch.randn(3,3)) #parameter 1\n",
    "        self.bias = nn.Parameter(torch.zeros(3)) # parameter 2\n",
    "\n",
    "        #add a subodule with its own parameter\n",
    "        self.submodule = nn.Linear(3,3)\n",
    "\n",
    "    def forward(self,x):\n",
    "        return self.submodule(x @ self.weight + self.bias)\n",
    "    \n",
    "#instantiate the model\n",
    "model = MyModel()\n",
    "\n",
    "try:\n",
    "    #get the weight parameter from the main module\n",
    "    weight = model.get_parameter(\"weight\")\n",
    "    print(\"Retrieved 'weight parameter:\")\n",
    "    print(weight)\n",
    "\n",
    "    #get the bias parameter from the main module \n",
    "    bias = model.get_parameter('bias')\n",
    "    print('\\n Retrieved bias parameter:')\n",
    "    print(bias)\n",
    "\n",
    "    #get tje 'weight' parameter from the submodule \n",
    "    submodule_weight = model.get_parameter('submodule.weight')\n",
    "    print('\\nRetrieved submodule.weight parameter:')\n",
    "    print(submodule_weight)\n",
    "\n",
    "    non_existent_param = model.get_parameter('non_existet_param')\n",
    "except AttributeError as e:\n",
    "    print(f'\\nError: {e}')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47bb0d1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved net_b submodule:\n",
      "Sequential(\n",
      "  (0): Conv2d(16, 33, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (1): ReLU()\n",
      "  (2): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      ")\n",
      "\n",
      "Retrieved linear submodule\n",
      "Linear(in_features=100, out_features=200, bias=True)\n",
      "\n",
      " Retreived net_b.0 submodule (Conv2d):\n",
      "Conv2d(16, 33, kernel_size=(3, 3), stride=(1, 1))\n",
      "\n",
      "Error: MyModel has no attribute `non_existent_submodule`\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#get_submodule \n",
    "\n",
    "# used to retrieve a specific submodule from a module usign a fully-qualified string name\n",
    "\n",
    "# useful when working with deeply nested modules , as it aalows to directly access a submodule wihtout iterating thorugh the entire module hierarchy\n",
    "import torch \n",
    "import torch.nn as nn \n",
    "\n",
    "class MyModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.net_b = nn.Sequential(\n",
    "            nn.Conv2d(16, 33, kernel_size=(3, 3)),  # Submodule 1\n",
    "            nn.ReLU(),                             # Submodule 2\n",
    "            nn.MaxPool2d(kernel_size=(2, 2))       # Submodule 3\n",
    "        )\n",
    "\n",
    "        self.linear = nn.Linear(100,200)\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = self.net_b(x)\n",
    "        x = x.view(x.size(0), -1) #flatten the tensor\n",
    "        x = self.liner(x)\n",
    "        return x \n",
    "    \n",
    "model = MyModel()\n",
    "\n",
    "try:\n",
    "    net_b = model.get_submodule('net_b')\n",
    "    print('Retrieved net_b submodule:')\n",
    "    print(net_b)\n",
    "\n",
    "    linear = model.get_submodule('linear')\n",
    "    print('\\nRetrieved linear submodule')\n",
    "    print(linear)\n",
    "\n",
    "    #get the first layer of 'net_b' (conv2d)\n",
    "    conv_layer = model.get_submodule('net_b.0')\n",
    "    print('\\n Retreived net_b.0 submodule (Conv2d):')\n",
    "    print(conv_layer)\n",
    "\n",
    "    non_existent_submodule = model.get_submodule(\"non_existent_submodule\")\n",
    "\n",
    "except AttributeError as e:\n",
    "    print(f'\\nError: {e}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e8dc9d9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before half():\n",
      "Weight datatype: torch.float32\n",
      "Running mean datatype torch.float32\n",
      "\n",
      " After half():\n",
      "Weight datatype: torch.float16\n",
      "Running mean datatype: torch.float16\n",
      "\n",
      "After double():\n",
      "Wegiht datatype: torch.float64\n",
      "Running mean datatype: torch.float64\n",
      "\n",
      " after half() again:\n",
      "weight datatype: torch.float16\n",
      "running mean datatype torch.float16\n"
     ]
    }
   ],
   "source": [
    "#half()\n",
    "\n",
    "#used to cast all floating-point parameters and buffers of a module to the half dataype\n",
    "# particularly useful when working with models that need to use half-precision floating-point numbers such as when optimizing for memory usage or when\n",
    "\n",
    "import torch \n",
    "import torch.nn as nn \n",
    "\n",
    "#define a simple model with parameters and buffers\n",
    "class MyModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        #trainable parameter (default is float32)\n",
    "        self.weight = nn.Parameter(torch.randn(3,3))\n",
    "\n",
    "        self.register_buffer('running_mean',torch.zeros(3))\n",
    "    def forward(self,x):\n",
    "        return x @ self.weight + self.running_mean\n",
    "    \n",
    "model = MyModel()\n",
    "\n",
    "print('Before half():')\n",
    "print('Weight datatype:', model.weight.dtype)\n",
    "print('Running mean datatype', model.running_mean.dtype) #should be torch.float32\n",
    "\n",
    "#cast all parameters and buffers to half (16-bit floating point)\n",
    "model.half()\n",
    "\n",
    "#print the datatpye of parameters and buffer after casting \n",
    "print('\\n After half():')\n",
    "print('Weight datatype:', model.weight.dtype)\n",
    "print('Running mean datatype:', model.running_mean.dtype)\n",
    "\n",
    "#example with double precision 64-bit floating point\n",
    "model.double()\n",
    "print('\\nAfter double():')\n",
    "print('Wegiht datatype:', model.weight.dtype)\n",
    "print('Running mean datatype:', model.running_mean.dtype)\n",
    "\n",
    "#cast back to half 16-bit floating point\n",
    "model.half()\n",
    "print('\\n after half() again:')\n",
    "print('weight datatype:', model.weight.dtype)\n",
    "print('running mean datatype', model.running_mean.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "cd001442",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'poptorch'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[49]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mnn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnn\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpoptorch\u001b[39;00m  \u001b[38;5;66;03m# Graphcore's PopTorch library for IPU support\u001b[39;00m\n\u001b[32m     11\u001b[39m \u001b[38;5;66;03m# Define a simple model\u001b[39;00m\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mMyModel\u001b[39;00m(nn.Module):\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'poptorch'"
     ]
    }
   ],
   "source": [
    "#ipu(device = None)\n",
    "\n",
    "# method specific to Graphcore's IPU (intelligence processing unit) hardware\n",
    "# used to move al model parameters and buffers ot the IPU device\n",
    "# moving models to CPUs or GPUs , but specific for IPU hardware\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import poptorch  # Graphcore's PopTorch library for IPU support\n",
    "\n",
    "# Define a simple model\n",
    "class MyModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(10, 20)\n",
    "        self.fc2 = nn.Linear(20, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Instantiate the model\n",
    "model = MyModel()\n",
    "\n",
    "# Print the device of model parameters before moving to IPU\n",
    "print(\"Before moving to IPU:\")\n",
    "for name, param in model.named_parameters():\n",
    "    print(f\"{name} is on device: {param.device}\")\n",
    "\n",
    "# Move the model to IPU\n",
    "model.ipu()  # Move all parameters and buffers to IPU\n",
    "\n",
    "# Print the device of model parameters after moving to IPU\n",
    "print(\"\\nAfter moving to IPU:\")\n",
    "for name, param in model.named_parameters():\n",
    "    print(f\"{name} is on device: {param.device}\")\n",
    "\n",
    "# Optional: Specify a specific IPU device\n",
    "model.ipu(device=1)  # Move to IPU device 1\n",
    "\n",
    "# Print the device of model parameters after moving to a specific IPU device\n",
    "print(\"\\nAfter moving to IPU device 1:\")\n",
    "for name, param in model.named_parameters():\n",
    "    print(f\"{name} is on device: {param.device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d36d7fa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error when strict=True: Error(s) in loading state_dict for MyModel:\n",
      "\tMissing key(s) in state_dict: \"fc3.weight\", \"fc3.bias\". \n",
      "\n",
      "Loading with strict=False:\n",
      "Missing keys: ['fc3.weight', 'fc3.bias']\n",
      "Unexpected keys: []\n",
      "\n",
      "Parameters after loading with assign=True:\n",
      "fc1.weight: Parameter containing:\n",
      "tensor([[ 9.3234e-02, -1.0406e-01,  2.0072e-01,  1.0068e-01, -2.6003e-01,\n",
      "         -6.9717e-02, -1.3650e-01,  3.0242e-01, -5.5836e-02,  1.6532e-01],\n",
      "        [ 2.0841e-01, -2.1912e-01,  1.9119e-01, -4.9851e-02,  5.7902e-02,\n",
      "         -1.9379e-02,  2.4167e-01, -1.0543e-01, -1.3502e-01,  7.4048e-02],\n",
      "        [-1.5762e-01, -2.3877e-01, -2.5111e-01,  2.1742e-01, -2.3223e-01,\n",
      "         -2.0470e-01,  1.5878e-02, -9.4169e-02, -6.3247e-02, -5.5704e-02],\n",
      "        [ 1.6315e-04, -1.3842e-01, -1.3518e-01, -7.3822e-02,  2.1311e-01,\n",
      "          1.4191e-01,  4.4531e-02, -1.4384e-01, -1.2044e-01,  1.2828e-01],\n",
      "        [-2.4574e-01, -2.9267e-01, -1.1814e-01, -2.8761e-01,  2.9364e-01,\n",
      "          9.9065e-02,  3.1010e-01,  2.0061e-02,  1.9692e-01, -1.8270e-01],\n",
      "        [-3.2125e-02,  2.4021e-01,  3.0711e-01, -9.3214e-02, -1.0455e-01,\n",
      "          9.0392e-02,  2.2153e-01,  1.2073e-01, -3.0683e-01,  2.5005e-01],\n",
      "        [-2.7626e-01,  8.9621e-02,  8.3369e-02, -8.4280e-02, -2.2907e-01,\n",
      "         -6.7015e-02,  2.5633e-02, -3.1495e-01, -1.1851e-01, -9.9094e-02],\n",
      "        [-1.7861e-01,  1.9247e-01,  6.7305e-02,  1.9000e-01, -1.9256e-01,\n",
      "          1.2006e-01, -2.6401e-01, -1.0692e-01,  1.4510e-01,  2.5973e-01],\n",
      "        [-1.6279e-01, -1.9831e-01, -1.1172e-01, -9.0672e-02, -2.9029e-01,\n",
      "         -6.2640e-02,  9.6852e-02,  2.6725e-02,  5.6102e-02,  3.4471e-02],\n",
      "        [-3.1592e-01,  3.0891e-01,  4.0263e-02,  1.2682e-01,  2.1913e-01,\n",
      "         -2.3975e-01, -1.0129e-01, -3.0219e-01, -1.0011e-01, -4.0262e-02],\n",
      "        [-2.2071e-01,  1.7561e-01, -2.3224e-01, -1.1769e-01,  1.4421e-02,\n",
      "         -9.2059e-02,  2.4866e-01, -2.4263e-01, -2.7567e-01, -1.9816e-01],\n",
      "        [-2.0427e-01, -2.0833e-01,  4.1005e-02, -1.2643e-01, -2.0693e-01,\n",
      "         -2.5196e-01, -3.8270e-02, -1.2659e-01,  1.6739e-01,  2.1617e-01],\n",
      "        [-9.1453e-02,  1.5839e-01,  3.4165e-02, -1.7566e-01,  1.1939e-01,\n",
      "          2.3469e-01, -2.4115e-01, -5.4368e-02,  3.0325e-01, -2.4944e-01],\n",
      "        [ 3.0411e-01,  1.9349e-01, -2.0860e-01, -2.5827e-01,  1.4748e-02,\n",
      "          1.2897e-01, -9.7909e-02,  8.3378e-02,  1.0373e-01,  2.3833e-01],\n",
      "        [ 2.1600e-01,  8.5629e-02,  8.1126e-02,  2.5392e-01, -9.1367e-02,\n",
      "          1.7340e-01, -1.8493e-01,  2.2819e-01,  2.5510e-01,  1.8136e-01],\n",
      "        [ 1.5078e-01,  1.9980e-01, -2.0860e-01, -2.2299e-01,  6.1646e-02,\n",
      "         -2.4573e-01,  3.0542e-01,  1.1009e-01,  1.5359e-01, -1.8041e-01],\n",
      "        [ 2.0571e-01, -3.3550e-02, -5.4483e-02,  1.5240e-01, -2.7789e-01,\n",
      "          2.6674e-01,  9.5721e-02, -2.4339e-01, -1.5415e-01, -1.8706e-01],\n",
      "        [-2.7436e-01,  7.9873e-02, -5.0431e-02,  1.0236e-01, -1.4163e-01,\n",
      "          9.5067e-02, -1.3717e-01, -1.5685e-01,  1.7093e-01,  1.9615e-01],\n",
      "        [-1.4320e-01,  1.8631e-01,  1.0708e-01,  2.2494e-01,  2.2161e-01,\n",
      "         -1.6785e-01,  1.3577e-01, -3.9981e-02, -1.1126e-01,  2.5639e-01],\n",
      "        [-1.4628e-01,  1.7814e-01, -1.6272e-01, -8.9942e-03, -1.1062e-02,\n",
      "         -2.9837e-01,  2.2176e-01,  1.8426e-01, -1.8190e-01, -1.7613e-01]],\n",
      "       requires_grad=True)\n",
      "fc1.bias: Parameter containing:\n",
      "tensor([ 0.0445, -0.1308,  0.1549, -0.0417,  0.0433,  0.0323,  0.0322, -0.1095,\n",
      "         0.2518,  0.0565, -0.0530,  0.1185, -0.0617,  0.0004,  0.0574,  0.2898,\n",
      "        -0.1377,  0.0323,  0.2989,  0.2124], requires_grad=True)\n",
      "fc2.weight: Parameter containing:\n",
      "tensor([[-0.1024, -0.0974, -0.0287, -0.0640,  0.2018, -0.1678, -0.1583,  0.1932,\n",
      "          0.0021,  0.0071,  0.1542,  0.1679,  0.1481,  0.1296,  0.1446, -0.0848,\n",
      "          0.0017, -0.0636, -0.0286, -0.1188],\n",
      "        [-0.0407,  0.0051,  0.0056,  0.1247,  0.0149,  0.2179, -0.2023, -0.0261,\n",
      "          0.0911, -0.1829,  0.1018,  0.2148, -0.2145, -0.2035, -0.0114,  0.0756,\n",
      "          0.2189, -0.0553, -0.2146,  0.1310],\n",
      "        [-0.0185,  0.0694, -0.0550,  0.0932, -0.2131,  0.0543, -0.0853,  0.1210,\n",
      "         -0.1886, -0.1245, -0.1924, -0.0542, -0.0215, -0.0051, -0.1231,  0.0507,\n",
      "         -0.1603, -0.1381,  0.1848, -0.1721],\n",
      "        [-0.1420, -0.2172,  0.0102,  0.2030, -0.0753,  0.0875, -0.0012,  0.1114,\n",
      "          0.0686,  0.1471, -0.2088,  0.1862,  0.0706, -0.0402,  0.1288, -0.0230,\n",
      "          0.1082,  0.1115,  0.1676,  0.0038],\n",
      "        [ 0.2122, -0.1828, -0.2073,  0.1112,  0.1419,  0.1118, -0.0190,  0.0217,\n",
      "         -0.1385, -0.0100,  0.0991, -0.0930,  0.1249,  0.1803,  0.1967,  0.0138,\n",
      "         -0.1438, -0.2152,  0.0103,  0.0106],\n",
      "        [ 0.0803,  0.0262, -0.0252,  0.1979, -0.2174,  0.0908, -0.0128,  0.0896,\n",
      "         -0.1437,  0.1907, -0.0685, -0.2221,  0.1247,  0.2030, -0.0481, -0.2142,\n",
      "          0.1577, -0.0174,  0.0004,  0.0694],\n",
      "        [ 0.1491, -0.0764, -0.1406,  0.1117,  0.1577,  0.1046, -0.0957, -0.0326,\n",
      "          0.2021, -0.0610,  0.1498,  0.0165,  0.1572, -0.0020,  0.2114,  0.1608,\n",
      "          0.0237, -0.0021,  0.0796, -0.1423],\n",
      "        [ 0.0823,  0.0785,  0.0666, -0.0790,  0.1184, -0.1056, -0.0226, -0.1412,\n",
      "          0.0602, -0.2200, -0.2233,  0.0245,  0.1435,  0.0140, -0.2226, -0.1679,\n",
      "          0.2053, -0.1398, -0.0941,  0.0106],\n",
      "        [ 0.1748,  0.2068, -0.0103, -0.0530, -0.1952, -0.0825,  0.0962,  0.1512,\n",
      "          0.0531,  0.0247,  0.0675,  0.1857,  0.1531, -0.0376, -0.1824, -0.0121,\n",
      "         -0.0474, -0.0405, -0.1717, -0.0747],\n",
      "        [-0.0593,  0.0157, -0.2141, -0.0330,  0.0858,  0.0032,  0.1145,  0.0495,\n",
      "         -0.1173, -0.0773,  0.1816, -0.1610, -0.0723,  0.0737, -0.1147,  0.1159,\n",
      "          0.2147,  0.0080,  0.0655,  0.1857]], requires_grad=True)\n",
      "fc2.bias: Parameter containing:\n",
      "tensor([-0.0765, -0.1281, -0.1772, -0.1114, -0.0097,  0.2114, -0.2089, -0.1272,\n",
      "        -0.1978, -0.1192], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "#load_state_dict(state_dict, strict = True, assign =False)\n",
    "\n",
    "#used to load the state of a model (parameters and buffers) from a dictionary state_dict\n",
    "\n",
    "#commonly used to load pretrained model\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Define a simple model\n",
    "class MyModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(10, 20)\n",
    "        self.fc2 = nn.Linear(20, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Instantiate the model\n",
    "model = MyModel()\n",
    "\n",
    "# Save the model's state_dict (simulating a checkpoint)\n",
    "checkpoint = model.state_dict()\n",
    "\n",
    "# Modify the model (e.g., add a new layer)\n",
    "model.fc3 = nn.Linear(10, 5)\n",
    "\n",
    "# Attempt to load the saved state_dict into the modified model\n",
    "try:\n",
    "    # Load with strict=True (default)\n",
    "    model.load_state_dict(checkpoint, strict=True)\n",
    "except RuntimeError as e:\n",
    "    print(f\"Error when strict=True: {e}\")\n",
    "\n",
    "# Load with strict=False (ignore missing or unexpected keys)\n",
    "result = model.load_state_dict(checkpoint, strict=False)\n",
    "print(\"\\nLoading with strict=False:\")\n",
    "print(\"Missing keys:\", result.missing_keys)  # Keys in the model but not in the checkpoint\n",
    "print(\"Unexpected keys:\", result.unexpected_keys)  # Keys in the checkpoint but not in the model\n",
    "\n",
    "# Example with assign=True\n",
    "# Create a new model and load the checkpoint with assign=True\n",
    "new_model = MyModel()\n",
    "new_model.load_state_dict(checkpoint, assign=True)\n",
    "\n",
    "# Verify that the parameters are loaded correctly\n",
    "print(\"\\nParameters after loading with assign=True:\")\n",
    "for name, param in new_model.named_parameters():\n",
    "    print(f\"{name}: {param}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "62eec05d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All modules in the network:\n",
      "0 -> MyModel(\n",
      "  (fc1): Linear(in_features=10, out_features=20, bias=True)\n",
      "  (fc2): Linear(in_features=20, out_features=10, bias=True)\n",
      "  (submodule): Sequential(\n",
      "    (0): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      ")\n",
      "1 -> Linear(in_features=10, out_features=20, bias=True)\n",
      "2 -> Linear(in_features=20, out_features=10, bias=True)\n",
      "3 -> Sequential(\n",
      "  (0): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (1): ReLU()\n",
      "  (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      ")\n",
      "4 -> Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1))\n",
      "5 -> ReLU()\n",
      "6 -> MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "\n",
      "Modules in a network with a shared layers:\n",
      "6->Sequential(\n",
      "  (0): Linear(in_features=2, out_features=2, bias=True)\n",
      "  (1): Linear(in_features=2, out_features=2, bias=True)\n",
      ")\n",
      "6->Linear(in_features=2, out_features=2, bias=True)\n"
     ]
    }
   ],
   "source": [
    "#modules() return an interator over all module sin the network, include top-level module and its submodule\n",
    "\n",
    "#useful for inspecting or modifying all parts of a model. \n",
    "\n",
    "import torch \n",
    "import torch.nn as nn \n",
    "\n",
    "class MyModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        \n",
    "        super().__init__()\n",
    "        #define layers \n",
    "        self.fc1 = nn.Linear(10,20)\n",
    "        self.fc2 = nn.Linear(20,10)\n",
    "\n",
    "        #define a sequantial submodule\n",
    "        self.submodule = nn.Sequential(\n",
    "            nn.Conv2d(1,16,kernel_size =3),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2)\n",
    "        )\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "    \n",
    "model = MyModel()\n",
    "\n",
    "#iterative over all modules in the network \n",
    "print('All modules in the network:')\n",
    "for idx, module in enumerate(model.modules()):\n",
    "    print(f\"{idx} -> {module}\")\n",
    "\n",
    "#example with shared layers \n",
    "shared_layer = nn.Linear(2,2)\n",
    "net = nn.Sequential(shared_layer, shared_layer)\n",
    "\n",
    "print('\\nModules in a network with a shared layers:')\n",
    "for ifx , module in enumerate(net.modules()):\n",
    "    print(f'{idx}->{module}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccd20d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tia(device = None)\n",
    "\n",
    "# specific to Meta' MTIA (Meta Training and Inference Accelerator) hardware \n",
    "\n",
    "# used to move all model parameters and buffers to the MTIA device .index\n",
    "# analogous to the `to(device)` method used for moving models to CPUs or GPUs but its tailored for MTIA hardware\n",
    "\n",
    "# since MITA-speficic funtionality is not standard PyTorck library , and require Meta's epcilaized framework. so no code will be generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "72bc6121",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All buffers in the model:\n",
      "\n",
      "Direct buffers in the model (recurse = False):\n",
      "\n",
      " Accessing the running__var buffer in the submodule:\n",
      "\n",
      "Buffers iwth prefix model.\n",
      "\n",
      " Accessing the running_var buffer in the submodule\n"
     ]
    }
   ],
   "source": [
    "# named_buffer(prefix ='', recurse = True, remove_duplicate = True)\n",
    "\n",
    "# used to iterate oer all buffers in a module , yielding both the name of the buffer in a module , yileding both the name of the niffer and the bffer itself.\n",
    "\n",
    "# buffers are non trainable tenosrs that are part of the module's state such as runnig statistics in BatchNorm layers or fixed embeddings \n",
    "\n",
    "\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "\n",
    "class Mymode(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.register_buffer(\"running_mean\", torch.zeros(10)) #buffer 1\n",
    "        self.register_buffer('fixed_embeddings',torch.randn(5,10))  #buffer 2\n",
    "\n",
    "        #add a submodule with it own buffer \n",
    "        self.submodule = nn.BatchNorm1d(10)\n",
    "        self.submodule.register_buffer('running_var', torch.ones(10)) #bufer in submodule \n",
    "\n",
    "    def forward(self,x):\n",
    "        return self.submodule()\n",
    "    \n",
    "model = MyModel()\n",
    "\n",
    "#interate over all buffers in the model\n",
    "print('All buffers in the model:')\n",
    "for name, buf in model.named_buffers():\n",
    "    print(f\"{name}:{buf.size()}\")\n",
    "\n",
    "#iterate over only direct buffers (recurse = False)\n",
    "print('\\nDirect buffers in the model (recurse = False):')\n",
    "\n",
    "for name, buf in model.named_buffers(recurse = False):\n",
    "    print(f\"{name}: {buf.size()}\")\n",
    "\n",
    "print('\\n Accessing the running__var buffer in the submodule:')\n",
    "for name , buf in model.named_buffers(recurse = False):\n",
    "    print(f'{name}:{buf.size()}')\n",
    "\n",
    "#iterate over buffers with a custom prefix \n",
    "print('\\nBuffers iwth prefix model.')\n",
    "for name, buf in model.named_buffers(prefix = 'model'):\n",
    "    print(f'{name}:{buf.size()}')\n",
    "\n",
    "#access a specific buffer by name \n",
    "print('\\n Accessing the running_var buffer in the submodule')\n",
    "for name, buf in model.named_buffers():\n",
    "    if name == \"submodule.running_var\":\n",
    "        print(f\"{name}: {buf}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee39b51d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# named_children\n",
    "\n",
    "https://chat.deepseek.com/a/chat/s/47c58dc4-c246-4404-b900-8cfadc9bbee8\n",
    "\n",
    "https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c4a30463",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Immedate child module with names:\n",
      "fc1: Linear(in_features=10, out_features=20, bias=True)\n",
      "fc2: Linear(in_features=20, out_features=30, bias=True)\n",
      "submodule: Sequential(\n",
      "  (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (1): ReLU()\n",
      "  (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      ")\n",
      "\n",
      " Accessing specific child modules:\n",
      "Found fc1: Linear(in_features=10, out_features=20, bias=True)\n",
      "Found submodule: Sequential(\n",
      "  (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (1): ReLU()\n",
      "  (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "#named_children \n",
    "\n",
    "#to iterate over the immediate modules of a model, yield both name of each child module and the module itself \n",
    "\n",
    "# useful to inspect or manipulate specifc submoduels ofa model by their naems\n",
    "\n",
    "import torch \n",
    "import torch.nn as nn \n",
    "\n",
    "class MyModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        #immediate child modules\n",
    "        self.fc1 = nn.Linear(10,20) #fully connected layer 1\n",
    "        self.fc2 = nn.Linear(20,30)  #fully connected layer 2\n",
    "\n",
    "        #submodule (nested module)\n",
    "\n",
    "        self.submodule = nn.Sequential(\n",
    "            nn.Conv2d(1,32, kernel_size = 3, stride = 1, padding = 1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size = 2)\n",
    "        )\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "\n",
    "        return x\n",
    "\n",
    "model = MyModel()\n",
    "\n",
    "#iterate over immediate child modules using named_children()\n",
    "\n",
    "print(\"Immedate child module with names:\")\n",
    "for name , child in model.named_children():\n",
    "    print(f\"{name}: {child}\")\n",
    "\n",
    "# example , access specific child modules by name\n",
    "print(\"\\n Accessing specific child modules:\")\n",
    "for name, child in model.named_children():\n",
    "    if name in ['fc1','submodule']:\n",
    "        print(f\"Found {name}: {child}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "67fd6b5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All modules with names:\n",
      ":MyModel(\n",
      "  (fc1): Linear(in_features=10, out_features=20, bias=True)\n",
      "  (fc2): Linear(in_features=20, out_features=30, bias=True)\n",
      "  (submodule): Sequential(\n",
      "    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      ")\n",
      "fc1:Linear(in_features=10, out_features=20, bias=True)\n",
      "fc2:Linear(in_features=20, out_features=30, bias=True)\n",
      "submodule:Sequential(\n",
      "  (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (1): ReLU()\n",
      "  (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      ")\n",
      "submodule.0:Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "submodule.1:ReLU()\n",
      "submodule.2:MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n"
     ]
    }
   ],
   "source": [
    "#named_modules \n",
    "\n",
    "#used to recursively iterate over all modules in a model\n",
    "# yield both the name of each moduel and the module itself, inclide its immediate children all nested submodules\n",
    "\n",
    "import torch \n",
    "import torch.nn as nn \n",
    "\n",
    "#define a model with multiple layers and submodules\n",
    "class MyModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        #immediate child modules\n",
    "        self.fc1 = nn.Linear(10,20) #fully connected layer\n",
    "        self.fc2 = nn.Linear(20,30) #fully connected layer\n",
    "\n",
    "        #submodule (nested module)\n",
    "        self.submodule = nn.Sequential(\n",
    "            nn.Conv2d(1,32,kernel_size=3,stride =1,padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size = 2)\n",
    "        )\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        return x \n",
    "\n",
    "model = MyModel()\n",
    "\n",
    "#iterate over al modules using named_modules()\n",
    "print(\"All modules with names:\")\n",
    "for name, module in model.named_modules():\n",
    "    print(f\"{name}:{module}\")\n",
    "\n",
    "#model.named_modules iterates over all modules , including the model itself its immediate children and all nested submodules\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a175e9ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All parameters with names:\n",
      "fc1.weight: torch.Size([20, 10])\n",
      "fc1.bias: torch.Size([20])\n",
      "fc2.weight: torch.Size([30, 20])\n",
      "fc2.bias: torch.Size([30])\n",
      "\n",
      " Accessing specific parmeters:\n",
      "Found bias fc1.bias, Size: torch.Size([20])\n",
      "Found bias fc2.bias, Size: torch.Size([30])\n"
     ]
    }
   ],
   "source": [
    "#named_parameters(prefix='',recurse=True,remove_duplicate=True)\n",
    "\n",
    "#return an interator over module parameters, yielding both the name the parameters as well as the parameter itself\n",
    "\n",
    "import torch \n",
    "import torch.nn as nn \n",
    "\n",
    "class MyModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        #immediate child modules\n",
    "        self.fc1 = nn.Linear(10,20) #fully connected layer 1\n",
    "        self.fc2 = nn.Linear(20,30) #fully connected layer 2\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        return x \n",
    "    \n",
    "model = MyModel()\n",
    "\n",
    "#iterate over all parameters using named_parameters()\n",
    "print(\"All parameters with names:\")\n",
    "for name, param in model.named_parameters():\n",
    "    print(f\"{name}: {param.size()}\")\n",
    "\n",
    "#example : access specific parameters by name \n",
    "print(\"\\n Accessing specific parmeters:\")\n",
    "for name, param in model.named_parameters():\n",
    "    if 'bias' in name:\n",
    "        print(f\"Found bias {name}, Size: {param.size()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f2732999",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All parameters\n",
      "Type : <class 'torch.nn.parameter.Parameter'>, Size: torch.Size([20, 10])\n",
      "Type : <class 'torch.nn.parameter.Parameter'>, Size: torch.Size([20])\n",
      "Type : <class 'torch.nn.parameter.Parameter'>, Size: torch.Size([30, 20])\n",
      "Type : <class 'torch.nn.parameter.Parameter'>, Size: torch.Size([30])\n",
      "\n",
      " Optimizer parameters:\n",
      "type : <class 'torch.nn.parameter.Parameter'>, Size: torch.Size([20, 10])\n",
      "type : <class 'torch.nn.parameter.Parameter'>, Size: torch.Size([20])\n",
      "type : <class 'torch.nn.parameter.Parameter'>, Size: torch.Size([30, 20])\n",
      "type : <class 'torch.nn.parameter.Parameter'>, Size: torch.Size([30])\n"
     ]
    }
   ],
   "source": [
    "#parameters(recurse = True)\n",
    "\n",
    "import torch \n",
    "import torch.nn as nn \n",
    "\n",
    "\n",
    "class MyModl(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        #immediate child modules\n",
    "        self.fc1 = nn.Linear(10,20) #fully connected layer 1\n",
    "        self.fc2 = nn.Linear(20,20) #fully connected layer 2\n",
    "\n",
    "        #submodule (nested module)\n",
    "        self.submodule = nn.Sequential(\n",
    "            nn.Conv2d(1,32,kernel_size=3, stride=1,padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size =2 )\n",
    "        )\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        return x \n",
    "    \n",
    "model = MyModel()\n",
    "\n",
    "print(\"All parameters\")\n",
    "for param in model.parameters():\n",
    "    print(f\"Type : {type(param)}, Size: {param.size()}\")\n",
    "\n",
    "#example : passing parameters to an optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "print('\\n Optimizer parameters:')\n",
    "for param_group in optimizer.param_groups:\n",
    "    for param in param_group['params']:\n",
    "        print(f\"type : {type(param)}, Size: {param.size()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "310d05a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full Backward Hook:\n",
      "Module : Linear(in_features=3, out_features=1, bias=True)\n",
      "Gradient Inpit: (tensor([[-0.5285,  0.1666,  0.3691]]),)\n",
      "Gradient Output: (tensor([[1.]]),)\n"
     ]
    }
   ],
   "source": [
    "#register_full_backward deprecated use register_full_backward_hook()\n",
    "\n",
    "# hook trigered during backward pass , allow to inspect or modify gradients\n",
    "\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "\n",
    "class SimpleModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc = nn.Linear(3,1)\n",
    "\n",
    "    def forward(self,x):\n",
    "        return self.fc(x)\n",
    "    \n",
    "#define a full backward hook function \n",
    "def full_backward_hook(module, grad_input,grad_output):\n",
    "    print(\"Full Backward Hook:\")\n",
    "    print(f\"Module : {module}\")\n",
    "    print(f\"Gradient Inpit: {grad_input}\")\n",
    "    print(f\"Gradient Output: {grad_output}\")\n",
    "\n",
    "# create the model\n",
    "model = SimpleModel()\n",
    "\n",
    "#register the full backward hook on the fully conntected layer\n",
    "hook_handle = model.fc.register_full_backward_hook(full_backward_hook)\n",
    "\n",
    "#foward pass \n",
    "x = torch.tensor([[1.0,2.0,3.0]], requires_grad = True)\n",
    "output = model(x)\n",
    "output.backward()\n",
    "\n",
    "hook_handle.remove()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "069edc49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model state_dict\n",
      "weight:torch.Size([10, 5])\n",
      "running_mean:torch.Size([20])\n",
      "fixed_embedding:torch.Size([20, 10])\n",
      "\n",
      "Accessing buffers:\n",
      "running_mean: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "fixed_embeddings: tensor([[-1.1692,  0.9233, -1.3743, -0.0412, -0.6657, -0.4694,  1.1795,  0.0048,\n",
      "         -0.2036, -0.9306],\n",
      "        [-0.2119,  1.9368, -0.1809,  1.2844,  0.4287, -0.4781, -0.6198, -1.3535,\n",
      "         -0.1595, -1.6089],\n",
      "        [-1.6512, -0.5887, -0.7414,  0.5946,  0.7417,  2.4140,  1.3768,  1.9308,\n",
      "         -0.2244, -0.5625],\n",
      "        [ 1.0054, -0.9115, -0.0934, -2.0115, -1.6865,  0.8628, -1.7416,  0.5485,\n",
      "         -0.2257, -0.6000],\n",
      "        [-0.9187, -0.5879, -0.0720,  0.6459,  0.2475,  0.4282,  0.4157,  1.3314,\n",
      "         -0.4986,  0.0343],\n",
      "        [-1.7999, -0.8960, -1.8708, -1.6024,  0.2459,  0.6762,  0.8101,  0.1302,\n",
      "         -0.8468, -0.2464],\n",
      "        [ 1.2704, -0.2843,  0.8097,  0.2247, -0.2556,  0.6125,  0.9254, -0.4050,\n",
      "         -1.1324,  1.6882],\n",
      "        [ 0.1232, -0.5229, -0.3620,  0.1882, -0.2703,  2.2683,  1.1863,  1.6206,\n",
      "         -0.1861,  0.1376],\n",
      "        [ 0.0195,  0.5895, -1.3170,  0.5660,  0.1374,  0.7970, -0.0686, -1.1154,\n",
      "          0.5078, -0.7681],\n",
      "        [-0.0546,  0.1522, -0.3307,  0.7734,  0.0862, -1.4019, -0.7127, -0.2757,\n",
      "          0.2396,  1.7815],\n",
      "        [ 0.8003,  0.6314, -1.1274,  0.0532, -0.9982,  1.3315, -0.4657,  0.0265,\n",
      "          1.2319, -1.4312],\n",
      "        [-1.1126,  0.2224, -0.6726,  0.9741,  1.1275,  0.2184,  0.3518,  0.6518,\n",
      "         -0.2972,  1.3734],\n",
      "        [-0.5760, -0.7465, -0.6834, -1.3494,  0.1716, -0.0084, -1.0739,  0.5054,\n",
      "          0.3836,  0.2357],\n",
      "        [-1.5255, -0.4673, -2.0819,  0.9225, -1.5580,  0.8251,  0.5191, -1.8103,\n",
      "          1.6566,  1.1951],\n",
      "        [ 0.1870, -1.9823,  0.7523,  0.7594, -0.4793, -0.2895,  0.2246, -0.3657,\n",
      "         -2.0273,  0.5037],\n",
      "        [ 0.2117, -0.5957, -0.3105, -0.2470,  1.6828, -0.9286,  0.2083, -0.8836,\n",
      "          1.0953, -1.2715],\n",
      "        [ 1.1485,  1.1336,  0.5535,  0.5511, -0.0806, -2.5242,  0.6347, -0.6773,\n",
      "          1.5469, -1.2167],\n",
      "        [-0.7095,  0.3307,  0.8427, -1.0604, -0.4698, -0.4880,  0.1928,  1.0575,\n",
      "          0.1932, -0.5366],\n",
      "        [ 0.2558, -0.6639,  2.7112, -1.5340, -0.6860, -0.8084,  1.4669,  0.4945,\n",
      "          0.8546,  0.3701],\n",
      "        [-1.0177, -0.5920, -1.7345,  0.0378, -0.0939,  0.8852, -0.8653,  0.3526,\n",
      "          0.4587, -0.7881]])\n",
      "\n",
      "Output shape: torch.Size([4, 5])\n"
     ]
    }
   ],
   "source": [
    "#register_buffer() \n",
    "\n",
    "# used to register a tensor as a buffer in a module. \n",
    "# unlike parameters buffer are not trainable bu they are part of the module;s state and will be saved in state_dict\n",
    "# buffer use to run statistics in BatchNorm layers or fixed embeddings \n",
    "\n",
    "import torch \n",
    "import torch.nn as nn \n",
    "\n",
    "#define a model with custom buffers \n",
    "class MyModel(nn.Module):\n",
    "    def __init__(self, num_features):\n",
    "        super().__init__()\n",
    "        #register a buffer for running mean \n",
    "        self.register_buffer('running_mean', torch.zeros(num_features)) #parameter for running mean\n",
    "        self.register_buffer('fixed_embedding', torch.randn(num_features,10)) #parameter for fixed embeddings\n",
    "        self.weight = nn.Parameter(torch.randn(10, 5)) #parameter for comparison\n",
    "\n",
    "    def forward(self,x):\n",
    "        #use the running mean buffer in the forward pass\n",
    "        x = x - self.running_mean.unsqueeze(0) #subtract running mean from input\n",
    "        x = x @ self.fixed_embedding # matrix multiplication\n",
    "        #use the trainable weight parameter\n",
    "        return x @ self.weight \n",
    "\n",
    "#create the model\n",
    "num_features = 20\n",
    "model = MyModel(num_features)\n",
    "\n",
    "#print the mode state_duct to see the registered buffer and parameters\n",
    "print('Model state_dict')\n",
    "for name, param in model.state_dict().items():\n",
    "    print(f\"{name}:{param.size()}\")\n",
    "\n",
    "#access the buffers as attributes\n",
    "print('\\nAccessing buffers:')\n",
    "print('running_mean:', model.running_mean)\n",
    "print('fixed_embeddings:', model.fixed_embedding)\n",
    "\n",
    "#perform a foward pass\n",
    "dummy_input = torch.randn(4, num_features)\n",
    "output = model(dummy_input)\n",
    "print('\\nOutput shape:', output.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "550ca99b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Forward Hook:\n",
      "Module: Linear(in_features=20, out_features=5, bias=True)\n",
      "Input (args): (tensor([[0.9887, 0.9279, 0.0000, 1.6666, 0.9149, 0.1565, 0.0000, 0.0000, 0.4082,\n",
      "         0.0000, 1.0419, 0.0000, 0.0000, 0.0000, 0.3589, 0.6129, 0.6456, 0.7229,\n",
      "         0.0000, 0.5827],\n",
      "        [0.0000, 0.0000, 0.0000, 0.5168, 0.0000, 0.0000, 0.0000, 0.8494, 0.0000,\n",
      "         0.0000, 0.6775, 0.7629, 0.0000, 0.0000, 0.0000, 0.1395, 0.0000, 0.2999,\n",
      "         0.1937, 0.0000],\n",
      "        [0.7397, 0.8591, 0.0000, 0.8880, 0.7910, 0.2205, 0.0000, 1.5006, 0.0000,\n",
      "         0.0000, 0.0414, 1.5801, 0.0000, 0.0000, 0.0000, 0.3989, 0.0000, 0.4936,\n",
      "         0.0000, 0.1047],\n",
      "        [0.0000, 0.0000, 1.7948, 0.0000, 0.4380, 0.0000, 0.4965, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.9101, 0.0000, 0.3110, 0.0000,\n",
      "         0.0396, 1.0976]], grad_fn=<ReluBackward0>),)\n",
      "Output: tensor([[-0.0539, -0.1256,  0.1501, -0.5554, -0.4071],\n",
      "        [-0.2102, -0.0720, -0.3877, -0.2682, -0.0719],\n",
      "        [-0.3707, -0.0906, -0.1941, -0.5034, -0.3508],\n",
      "        [ 0.1536, -0.0296,  0.1560, -0.4427,  0.2300]],\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Modified Output: tensor([[-0.1077, -0.2511,  0.3001, -1.1109, -0.8142],\n",
      "        [-0.4203, -0.1440, -0.7754, -0.5364, -0.1439],\n",
      "        [-0.7413, -0.1813, -0.3882, -1.0069, -0.7017],\n",
      "        [ 0.3072, -0.0592,  0.3121, -0.8855,  0.4599]], grad_fn=<MulBackward0>)\n",
      "\n",
      "Final Output:\n",
      "tensor([[-0.1077, -0.2511,  0.3001, -1.1109, -0.8142],\n",
      "        [-0.4203, -0.1440, -0.7754, -0.5364, -0.1439],\n",
      "        [-0.7413, -0.1813, -0.3882, -1.0069, -0.7017],\n",
      "        [ 0.3072, -0.0592,  0.3121, -0.8855,  0.4599]], grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "#register_forward_hook register a hook that is executed after the forward()\n",
    "# useful for inspecting or modifying the inputs an dputptus of a module during the forward pas\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Define a simple model\n",
    "class SimpleModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(10, 20)  # Fully connected layer 1\n",
    "        self.fc2 = nn.Linear(20, 5)   # Fully connected layer 2\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        return self.fc2(x)\n",
    "\n",
    "# Create the model\n",
    "model = SimpleModel()\n",
    "\n",
    "# Define a forward hook function\n",
    "def forward_hook(module, args, output):\n",
    "    print(\"\\nForward Hook:\")\n",
    "    print(f\"Module: {module}\")\n",
    "    print(f\"Input (args): {args}\")  # Inputs to the module\n",
    "    print(f\"Output: {output}\")      # Output from the module\n",
    "\n",
    "    # Optionally modify the output\n",
    "    output = output * 2  # Double the output\n",
    "    print(f\"Modified Output: {output}\")\n",
    "    return output  # Return the modified output\n",
    "\n",
    "# Register the forward hook on the second fully connected layer (fc2)\n",
    "hook_handle = model.fc2.register_forward_hook(forward_hook)\n",
    "\n",
    "# Perform a forward pass\n",
    "dummy_input = torch.randn(4, 10)  # Batch size: 4, Input features: 10\n",
    "output = model(dummy_input)\n",
    "\n",
    "print(\"\\nFinal Output:\")\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "805b5a1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Forward Pre-Hook\n",
      "ModuleL Linear(in_features=10, out_features=20, bias=True)\n",
      "Input (args):(tensor([[ 0.2961,  1.2313, -0.4940, -0.0205, -0.0507,  0.4216, -1.8702,  0.4123,\n",
      "         -0.1422, -0.2483],\n",
      "        [-0.0921, -1.5266,  2.1024, -0.4903,  0.9804, -0.0072,  0.4120, -0.7442,\n",
      "         -0.1839,  1.0655],\n",
      "        [-0.3003, -2.0432,  0.8264,  1.7306,  1.1460, -1.4550,  0.8153,  1.3339,\n",
      "         -0.5971,  0.4146],\n",
      "        [-0.1170, -1.0051,  0.6520, -1.0000,  1.0511,  0.5122, -1.0182,  0.7830,\n",
      "          0.5140,  0.3190]]),)\n",
      "Modified Input:tensor([[ 0.5922,  2.4626, -0.9881, -0.0409, -0.1013,  0.8433, -3.7404,  0.8246,\n",
      "         -0.2845, -0.4965],\n",
      "        [-0.1843, -3.0532,  4.2049, -0.9805,  1.9607, -0.0144,  0.8240, -1.4884,\n",
      "         -0.3677,  2.1309],\n",
      "        [-0.6005, -4.0863,  1.6528,  3.4612,  2.2920, -2.9099,  1.6307,  2.6678,\n",
      "         -1.1943,  0.8291],\n",
      "        [-0.2340, -2.0102,  1.3040, -1.9999,  2.1022,  1.0244, -2.0363,  1.5661,\n",
      "          1.0279,  0.6381]])\n",
      "\n",
      "Final Output\n",
      "tensor([[ 0.0100, -0.0221, -0.6078, -0.6121,  0.1140],\n",
      "        [ 0.2412,  0.0329, -0.2668,  0.1518, -0.1087],\n",
      "        [ 0.4563,  0.2881,  1.0780,  0.3266, -0.9572],\n",
      "        [-0.6215, -0.0280, -0.3775, -0.1420,  0.0203]],\n",
      "       grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "#register_forward_pre_hook()\n",
    "# al;ows you to register a hook that is executed before the forward() method of a module is called\n",
    "# this is useful for inspecting or modifting the inputs to a module before they are processed \n",
    "\n",
    "import torch \n",
    "import torch.nn as nn \n",
    "\n",
    "class SimpleModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(10,20)\n",
    "        self.fc2 = nn.Linear(20,5)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        return self.fc2(x)\n",
    "    \n",
    "model = SimpleModel()\n",
    "\n",
    "def forward_pre_hook(module, args):\n",
    "    print('\\nForward Pre-Hook')\n",
    "    print(f'ModuleL {module}')\n",
    "    print(f'Input (args):{args}')\n",
    "\n",
    "    modified_input = args[0] * 2 \n",
    "    print(f'Modified Input:{modified_input}')\n",
    "    return (modified_input,) #return modifed input as tuple\n",
    "\n",
    "hook_handle = model.fc1.register_forward_pre_hook(forward_pre_hook)\n",
    "\n",
    "dummy_input = torch.randn(4,10)\n",
    "output = model(dummy_input)\n",
    "\n",
    "print('\\nFinal Output')\n",
    "print(output)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ee4032a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Full Backward Hook;\n",
      "Module Linear(in_features=10, out_features=5, bias=True)\n",
      "Gradient Input: (tensor([[ 0.4963, -0.3214,  0.1429, -0.0377, -0.3262, -0.0023, -0.9644,  0.5581,\n",
      "          0.0258, -0.7973],\n",
      "        [ 0.4963, -0.3214,  0.1429, -0.0377, -0.3262, -0.0023, -0.9644,  0.5581,\n",
      "          0.0258, -0.7973],\n",
      "        [ 0.4963, -0.3214,  0.1429, -0.0377, -0.3262, -0.0023, -0.9644,  0.5581,\n",
      "          0.0258, -0.7973],\n",
      "        [ 0.4963, -0.3214,  0.1429, -0.0377, -0.3262, -0.0023, -0.9644,  0.5581,\n",
      "          0.0258, -0.7973]]),)\n",
      "Gradient Output: (tensor([[1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1.]]),)\n",
      "Modified Gradient Input: [tensor([[ 0.9925, -0.6427,  0.2857, -0.0755, -0.6524, -0.0046, -1.9287,  1.1163,\n",
      "          0.0517, -1.5946],\n",
      "        [ 0.9925, -0.6427,  0.2857, -0.0755, -0.6524, -0.0046, -1.9287,  1.1163,\n",
      "          0.0517, -1.5946],\n",
      "        [ 0.9925, -0.6427,  0.2857, -0.0755, -0.6524, -0.0046, -1.9287,  1.1163,\n",
      "          0.0517, -1.5946],\n",
      "        [ 0.9925, -0.6427,  0.2857, -0.0755, -0.6524, -0.0046, -1.9287,  1.1163,\n",
      "          0.0517, -1.5946]])]\n"
     ]
    }
   ],
   "source": [
    "#register_full_backward_hook()\n",
    "\n",
    "# allows you to register a hook that is executed during the backward_pass when gradients are computed \n",
    "# usefil for inspecting or modifying gradients as the flow through the model.\n",
    "# grad_input and grad_output are tuples containing gradeints with respect to the inputs and outputs of the module , respetifcly\n",
    "\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "\n",
    "class SimpleModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc = nn.Linear(10,5)\n",
    "\n",
    "    def forward(self,x):\n",
    "        return self.fc(x)\n",
    "\n",
    "model = SimpleModel()\n",
    "\n",
    "def full_backward_hook(module, grad_input, grad_output):\n",
    "    print('\\n Full Backward Hook;')\n",
    "    print(f'Module {module}')\n",
    "    print(f'Gradient Input: {grad_input}')\n",
    "    print(f'Gradient Output: {grad_output}')\n",
    "\n",
    "    #optionally modify the gradient input\n",
    "    modified_grad_input = [g * 2 if g is not None else None for g in grad_input]\n",
    "    print(f'Modified Gradient Input: {modified_grad_input}')\n",
    "    return modified_grad_input #return the modified gradient\n",
    "\n",
    "hook_handle = model.fc.register_full_backward_hook(full_backward_hook)\n",
    "\n",
    "dummy_input = torch.randn(4,10,requires_grad=True)\n",
    "output = model(dummy_input)\n",
    "\n",
    "loss = output.sum()\n",
    "loss.backward()\n",
    "\n",
    "hook_handle.remove()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "de56fc63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Bakcward Pre-Hook:\n",
      "Module : Linear(in_features=10, out_features=5, bias=True)\n",
      "Gradient Output (before computation): (tensor([[1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1.]]),)\n",
      "Modified Gradient Output:[tensor([[2., 2., 2., 2., 2.],\n",
      "        [2., 2., 2., 2., 2.],\n",
      "        [2., 2., 2., 2., 2.],\n",
      "        [2., 2., 2., 2., 2.]])]\n"
     ]
    }
   ],
   "source": [
    "#register_full_backward_pre_hook()\n",
    "# allow to register backward pre-hook on a module\n",
    "# the hook is executed before the gradeitns for the modele are computed during the backward pass\n",
    "# provides access to the gradients with respect to the module's outputs and allows you to optionally modify them\n",
    "\n",
    "import torch \n",
    "import torch.nn as nn \n",
    "\n",
    "class SimpleModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc = nn.Linear(10,5)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        return self.fc(x)\n",
    "    \n",
    "model = SimpleModel()\n",
    "\n",
    "def backward_pre_hook(module, grad_output):\n",
    "    print('\\n Bakcward Pre-Hook:')\n",
    "    print(f'Module : {module}')\n",
    "    print(f'Gradient Output (before computation): {grad_output}')\n",
    "\n",
    "    modified_grad_output = [g*2 if g is not None else None for g in grad_output]\n",
    "    print(f'Modified Gradient Output:{modified_grad_output}')\n",
    "    return modified_grad_output\n",
    "\n",
    "hook_handle = model.fc.register_full_backward_pre_hook(backward_pre_hook)\n",
    "\n",
    "dummy_input = torch.randn(4,10,requires_grad=True) #batch size 4 input features 10\n",
    "output = model(dummy_input)\n",
    "\n",
    "#perform a backward pass \n",
    "loss = output.sum()\n",
    "loss.backward()\n",
    "\n",
    "#remove the hook after use\n",
    "hook_handle.remove()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7388cb08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading state_dict.. \n",
      "\n",
      " load state dict post-hook:\n",
      "Module: SimpleMethod(\n",
      "  (fc1): Linear(in_features=10, out_features=20, bias=True)\n",
      "  (fc2): Linear(in_features=20, out_features=5, bias=True)\n",
      ")\n",
      "Incomaptible keys before modifications: _IncompatibleKeys(missing_keys=['fc2.weight'], unexpected_keys=['unexpected_key'])\n"
     ]
    }
   ],
   "source": [
    "#register_load_state_dict_post_hook()\n",
    "\n",
    "#allows to register a post hook that is executed after the load_state_dict method od a module is called\n",
    "# can be ised to inspect or modify the incompatible_keys \n",
    "\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "\n",
    "class SimpleMethod(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(10,20)\n",
    "        self.fc2 = nn.Linear(20,5)\n",
    "\n",
    "#creat two models one for saving and one for loading\n",
    "model_to_save = SimpleMethod()\n",
    "model_to_load = SimpleMethod()\n",
    "\n",
    "#modift the state dict of the model_to_save to simulate incopatible keys\n",
    "state_dict = model_to_save.state_dict()\n",
    "del state_dict['fc2.weight'] #simulate a missing key\n",
    "state_dict['unexpected_key'] = torch.randn(5) #simluate an unexpected key\n",
    "\n",
    "#define a post hook function\n",
    "def load_state_dict_post_hook(module, incompatible_keys):\n",
    "    print('\\n load state dict post-hook:')\n",
    "    print(f'Module: {module}')\n",
    "    print(f'Incomaptible keys before modifications: {incompatible_keys}')\n",
    "\n",
    "    #modift incompatible_keys inpace\n",
    "    incompatible_keys.missing_keys[:] = [key for key in incompatible_keys.missing_keys if 'fc2' not in key]\n",
    "    incompatible_keys.unexpected_keys.clear()\n",
    "\n",
    "hook_handle = model_to_load.register_load_state_dict_post_hook(load_state_dict_post_hook)\n",
    "#load the modified state dict into the model_to_load\n",
    "print('Loading state_dict.. ')\n",
    "model_to_load.load_state_dict(state_dict, strict = False)\n",
    "\n",
    "#remove the hook after use\n",
    "hook_handle.remove()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "82003771",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading state_dict...\n",
      "\n",
      "Load State Dict Pre-Hook:\n",
      "Module: SimpleModel(\n",
      "  (fc1): Linear(in_features=10, out_features=20, bias=True)\n",
      "  (fc2): Linear(in_features=20, out_features=5, bias=True)\n",
      ")\n",
      "State Dict Before Modification: ['fc1.weight', 'fc1.bias', 'fc2.bias', 'unexpected_key']\n",
      "Adding missing 'fc2.weight' key to state_dict...\n",
      "Removing unexpected 'unexpected_key' from state_dict...\n",
      "State DIct After Modification: ['fc1.weight', 'fc1.bias', 'fc2.bias', 'fc2.weight']\n"
     ]
    }
   ],
   "source": [
    "#register_load_state_dict_pre_hook()\n",
    "\n",
    "# allows you to register a pre-hook that is executed before the load_state_dict()\n",
    "# hook can be used to inspect or modify the state_dict befor eit is loaded into the model\n",
    "\n",
    "import torch \n",
    "import torch.nn as nn \n",
    "#modify the state_dict of the model_to_save to simulate incompatible keys\n",
    "\n",
    "\n",
    "class SimpleModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(10,20)\n",
    "        self.fc2 = nn.Linear(20,5)\n",
    "\n",
    "model_to_save = SimpleModel()\n",
    "model_to_load = SimpleModel()\n",
    "\n",
    "\n",
    "state_dict = model_to_save.state_dict()\n",
    "del state_dict['fc2.weight'] #stimulate a missing key\n",
    "state_dict['unexpected_key'] = torch.randn(5)\n",
    "\n",
    "#define a pre-hook function\n",
    "def load_state_dict_pre_hook(module, state_dict, prefix, local_metadata, strict, missing_keys, unexpected_keys, error_msgs):\n",
    "    print(\"\\nLoad State Dict Pre-Hook:\")\n",
    "    print(f\"Module: {module}\")\n",
    "    print(f\"State Dict Before Modification: {list(state_dict.keys())}\")\n",
    "\n",
    "    # Add the missing 'fc2.weight' key with default initialization\n",
    "    if 'fc2.weight' not in state_dict:\n",
    "        print(\"Adding missing 'fc2.weight' key to state_dict...\")\n",
    "        state_dict['fc2.weight'] = torch.zeros_like(module.fc2.weight)\n",
    "\n",
    "    # Remove the unexpected key\n",
    "    if 'unexpected_key' in state_dict:\n",
    "        print(\"Removing unexpected 'unexpected_key' from state_dict...\")\n",
    "        del state_dict['unexpected_key']\n",
    "\n",
    "    print(f'State DIct After Modification: {list(state_dict.keys())}')\n",
    "\n",
    "hook_handle = model_to_load.register_load_state_dict_pre_hook(load_state_dict_pre_hook)\n",
    "\n",
    "# Load the modified state_dict into the model_to_load\n",
    "print(\"Loading state_dict...\")\n",
    "model_to_load.load_state_dict(state_dict, strict=True)\n",
    "\n",
    "# Remove the hook after use\n",
    "hook_handle.remove()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b429125",
   "metadata": {},
   "outputs": [],
   "source": [
    "#register_module alias for add_module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "11cf4bbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model state_dict\n",
      "custom_weight:torch.Size([5])\n",
      "fc.weight:torch.Size([1, 5])\n",
      "fc.bias:torch.Size([1])\n",
      "\n",
      " Accessing custom parameter:\n",
      "custom_weight: Parameter containing:\n",
      "tensor([ 0.1465, -0.9626, -0.5179, -1.7237,  1.6209], requires_grad=True)\n",
      "\n",
      "Output shape: torch.Size([4, 1])\n"
     ]
    }
   ],
   "source": [
    "#register_parameter \n",
    "\n",
    "#allows you to explicitly add a parameter to a module\n",
    "# useful when you want to define custom parameters that are not directly created by laters like nn.Linear or nn.Conv2d\n",
    "# paramters registered using register_parameter() are treated as trainable and will be included in the module's state_dict \n",
    "\n",
    "import torch \n",
    "import torch.nn as nn \n",
    "\n",
    "class CustomModel(nn.Module):\n",
    "    def __init__(self, num_features):\n",
    "        super().__init__()\n",
    "\n",
    "        #register a custom trainable parameter\n",
    "        self.register_parameter('custom_weight', nn.Parameter(torch.randn(num_features)))\n",
    "\n",
    "        #a regular fully connected layer for comparison\n",
    "        self.fc = nn.Linear(num_features, 1)\n",
    "\n",
    "    def forward(self,x):\n",
    "        #use the custom parameter in the forward pass\n",
    "        x = x * self.custom_weight\n",
    "        return self.fc(x)\n",
    "    \n",
    "\n",
    "model = CustomModel(num_features=5)\n",
    "print('Model state_dict')\n",
    "for name, param in model.state_dict().items():\n",
    "    print(f\"{name}:{param.size()}\")\n",
    "\n",
    "#access the custom parameter as an attribute\n",
    "print('\\n Accessing custom parameter:')\n",
    "print('custom_weight:',model.custom_weight)\n",
    "\n",
    "dummy_input = torch.randn(4, num_features)\n",
    "output = model(dummy_input)\n",
    "print('\\nOutput shape:', output.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "edb08e12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calling state_dict()\n",
      "\n",
      " State Dict Post-Hook:\n",
      "Module: SimpleModel(\n",
      "  (fc1): Linear(in_features=10, out_features=20, bias=True)\n",
      "  (fc2): Linear(in_features=20, out_features=5, bias=True)\n",
      ")\n",
      "State Dict Before Modification : ['fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias']\n",
      "Removing fc2.weight from state_dict\n",
      "Adding custom_key to state_dict\n",
      "State Dict After Modification: ['fc1.weight', 'fc1.bias', 'fc2.bias', 'custom_key']\n",
      "fc1.weight:torch.Size([20, 10])\n",
      "fc1.bias:torch.Size([20])\n",
      "fc2.bias:torch.Size([5])\n",
      "custom_key:torch.Size([1])\n"
     ]
    }
   ],
   "source": [
    "#register_state_dict_post_hook()\n",
    "\n",
    "# use to register a post-hook that is executed after the state_dict() method of a module is called.\n",
    "# this hook can be used to inspect or modify the state_dict before it is returned\n",
    "\n",
    "import torch \n",
    "import torch.nn as nn \n",
    "\n",
    "class SimpleModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(10,20)\n",
    "        self.fc2 = nn.Linear(20 , 5)\n",
    "\n",
    "model = SimpleModel()\n",
    "\n",
    "def state_dict_post_hook(module,state_dict, prefix , local_metadata):\n",
    "    print('\\n State Dict Post-Hook:')\n",
    "    print(f'Module: {module}')\n",
    "    print(f'State Dict Before Modification : {list(state_dict.keys())}')\n",
    "\n",
    "    if 'fc2.weight' in state_dict:\n",
    "        print('Removing fc2.weight from state_dict')\n",
    "        del state_dict['fc2.weight']\n",
    "    \n",
    "    if 'custom_key' not in state_dict:\n",
    "        print('Adding custom_key to state_dict')\n",
    "        state_dict['custom_key'] = torch.tensor([42.0])\n",
    "\n",
    "    print(f'State Dict After Modification: {list(state_dict.keys())}')\n",
    "\n",
    "hook_handle = model.register_state_dict_post_hook(state_dict_post_hook)\n",
    "\n",
    "print('Calling state_dict()')\n",
    "state_dict = model.state_dict()\n",
    "for key, value in state_dict.items():\n",
    "    print(f'{key}:{value.size() if isinstance(value, torch.Tensor) else value}')\n",
    "\n",
    "hook_handle.remove()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7b355828",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calling state_dict()...\n",
      "\n",
      "State Dict Pre-Hook\n",
      "Module : SimpleModel(\n",
      "  (fc1): Linear(in_features=10, out_features=20, bias=True)\n",
      "  (fc2): Linear(in_features=20, out_features=5, bias=True)\n",
      ")\n",
      "Prefix: \n",
      "Keep Vars: False\n",
      "Modifying custom_buffer before state_dict()\n",
      "\n",
      " Final State Dict:\n",
      "custom_buffer: tensor([2., 2., 2., 2., 2.])\n",
      "fc1.weight: tensor([[ 1.1114e-02,  2.6485e-01,  7.1813e-02,  6.4798e-02,  2.4110e-01,\n",
      "          2.2708e-01,  2.1536e-01,  4.4444e-02,  2.1228e-01, -5.4929e-02],\n",
      "        [ 1.1388e-01,  2.9384e-01, -4.6838e-02,  2.3594e-01,  7.6249e-02,\n",
      "          5.2240e-02,  1.6616e-01,  1.8772e-01, -2.1465e-01,  1.7900e-01],\n",
      "        [-2.3969e-01, -1.5891e-02,  3.0292e-01, -2.0144e-01,  4.7090e-02,\n",
      "         -1.7050e-01,  1.3062e-01,  1.1197e-01, -1.1315e-02,  2.5014e-01],\n",
      "        [-1.8129e-01, -1.2033e-01, -1.7847e-01, -1.2628e-01,  2.4070e-01,\n",
      "         -7.5194e-02,  2.7970e-01,  1.3442e-01, -1.1633e-01,  5.6283e-02],\n",
      "        [-2.7280e-01,  8.8173e-02, -2.4256e-01, -2.0110e-01, -1.3094e-01,\n",
      "          9.7791e-03,  2.9732e-01,  1.4136e-01, -1.2295e-01,  6.0339e-02],\n",
      "        [-1.2975e-01, -1.5787e-01, -2.9385e-01,  2.1777e-01, -2.8194e-01,\n",
      "          7.6164e-02,  2.6298e-01, -1.6595e-01,  2.5960e-01,  6.2647e-02],\n",
      "        [-2.6632e-01, -2.0317e-01,  2.5192e-01,  1.1742e-01, -7.0627e-03,\n",
      "         -1.3204e-01,  2.1416e-01,  1.9185e-01, -2.9652e-01,  1.9787e-01],\n",
      "        [-2.7815e-01, -2.3022e-01,  1.4454e-01, -2.2936e-01,  1.0916e-01,\n",
      "         -3.3134e-02,  1.4407e-01,  1.9071e-01, -1.5613e-01,  3.1000e-01],\n",
      "        [ 2.3303e-01,  1.0263e-01,  2.3349e-01,  2.0251e-01, -2.6271e-01,\n",
      "         -6.1662e-02,  1.8565e-01,  2.1624e-01, -2.0142e-01, -1.7340e-01],\n",
      "        [-3.0616e-01,  1.0193e-01, -1.4584e-01,  1.5183e-02, -2.3315e-01,\n",
      "         -1.9823e-01,  1.6251e-01,  1.9868e-01,  1.4140e-01,  1.1268e-01],\n",
      "        [-1.5232e-01, -1.6954e-01, -1.3829e-01,  2.1607e-01, -6.0109e-02,\n",
      "          1.4031e-01, -2.3903e-01,  4.0306e-02,  2.9285e-01,  2.7575e-01],\n",
      "        [ 1.4308e-01, -1.0778e-01, -6.4756e-03,  1.0975e-01, -2.3917e-01,\n",
      "         -1.6432e-03, -5.1748e-02,  9.0273e-02,  3.2249e-02, -3.1456e-01],\n",
      "        [ 2.1372e-02, -2.8019e-01, -2.4918e-01, -8.5454e-02, -2.2758e-01,\n",
      "         -1.3517e-01, -4.8272e-02,  2.7108e-01, -1.3606e-01, -9.3672e-03],\n",
      "        [ 1.7280e-01,  1.5784e-02, -2.3862e-01, -1.9105e-01, -5.2046e-03,\n",
      "          3.0093e-01,  6.0681e-02,  2.6634e-01, -1.2859e-01,  2.6724e-02],\n",
      "        [ 2.6484e-01, -5.9021e-03,  1.2724e-01,  3.8203e-02,  2.2775e-02,\n",
      "          9.4870e-03, -2.5388e-01,  2.5117e-01, -1.7729e-01, -2.4701e-01],\n",
      "        [-1.0534e-01, -1.6516e-01,  2.6891e-01, -2.4808e-01,  1.7073e-01,\n",
      "          2.5841e-01,  1.6916e-01,  2.9758e-01, -2.0268e-01,  1.9058e-01],\n",
      "        [-2.4977e-01,  5.6244e-02,  3.2059e-02,  1.0222e-01,  1.2906e-01,\n",
      "         -3.5554e-02, -1.0766e-01,  1.8416e-01, -2.3207e-01,  7.7317e-05],\n",
      "        [ 9.9820e-02,  1.4687e-01, -3.1362e-01, -2.4564e-02, -1.1238e-01,\n",
      "          2.9481e-01, -2.1887e-01, -1.9699e-01,  1.1603e-01,  3.0851e-01],\n",
      "        [ 1.3188e-01,  2.8294e-01,  9.3496e-02,  6.2356e-02,  2.8022e-01,\n",
      "         -5.4992e-02, -1.7363e-01, -9.9816e-02,  9.5147e-02,  2.5901e-01],\n",
      "        [ 2.4429e-01, -5.0925e-02, -1.5382e-01,  3.1165e-01, -2.9407e-01,\n",
      "          1.1719e-01,  5.8523e-02,  3.0688e-01, -7.1138e-02, -1.3326e-01]])\n",
      "fc1.bias: tensor([-0.3128, -0.2051, -0.1096, -0.1502,  0.2409, -0.0497,  0.2256,  0.0269,\n",
      "        -0.0791,  0.0432, -0.0160,  0.2579,  0.2851, -0.1435,  0.2156,  0.0516,\n",
      "         0.2800,  0.1136,  0.2624, -0.1279])\n",
      "fc2.weight: tensor([[ 0.0281,  0.2113, -0.0710, -0.0390, -0.1964,  0.1736, -0.0479, -0.0995,\n",
      "          0.1411,  0.0655,  0.2107,  0.1723, -0.0485,  0.0309, -0.0083, -0.1144,\n",
      "         -0.1657, -0.2228,  0.1251, -0.0928],\n",
      "        [ 0.1849,  0.0959,  0.0048, -0.1358, -0.1065, -0.1112,  0.0602,  0.0052,\n",
      "          0.0229,  0.1563, -0.2083, -0.1082, -0.0405,  0.2128,  0.1919, -0.0590,\n",
      "          0.1956,  0.1160,  0.1317,  0.0779],\n",
      "        [ 0.1638, -0.1534,  0.1171, -0.1664,  0.1710, -0.2201, -0.1749,  0.0282,\n",
      "         -0.0145, -0.1553, -0.1748, -0.1044, -0.1347, -0.0369,  0.2170, -0.0087,\n",
      "          0.0759,  0.1160,  0.1347, -0.0617],\n",
      "        [ 0.0014, -0.1797, -0.1747, -0.0470,  0.1815, -0.1843,  0.2017,  0.0799,\n",
      "         -0.1618,  0.2201,  0.1662, -0.2176,  0.0361, -0.2037,  0.1507, -0.1067,\n",
      "         -0.0882, -0.1861,  0.2221, -0.0466],\n",
      "        [-0.2000,  0.1400, -0.1649,  0.2187,  0.1204,  0.1102, -0.1285, -0.1059,\n",
      "          0.1300,  0.0353, -0.0582,  0.0115, -0.0085, -0.0305,  0.1336,  0.0827,\n",
      "          0.1653, -0.0840, -0.2064,  0.0047]])\n",
      "fc2.bias: tensor([-0.0519, -0.0448, -0.2171, -0.1624,  0.1568])\n"
     ]
    }
   ],
   "source": [
    "#register_state_dict_pre_hook()\n",
    "\n",
    "# register a pre-hook that is executed before the state_dict() method of a module is called\n",
    "# this hook can be usde to inspect or modift the state of the model before the state_dict is generated\n",
    "\n",
    "import torch \n",
    "import torch.nn as nn \n",
    "\n",
    "class SimpleModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(10,20)\n",
    "        self.fc2 = nn.Linear(20,5)\n",
    "\n",
    "        #add a buffer that will be included in the state_dict\n",
    "        self.register_buffer('custom_buffer', torch.ones(5))\n",
    "\n",
    "#create the model\n",
    "model = SimpleModel()\n",
    "\n",
    "#define a state_dict pre-hook function\n",
    "def state_dict_pre_hook(module, prefix, keep_vars):\n",
    "    print('\\nState Dict Pre-Hook')\n",
    "    print(f'Module : {module}')\n",
    "    print(f'Prefix: {prefix}')\n",
    "    print(f'Keep Vars: {keep_vars}')\n",
    "\n",
    "    if hasattr(module, 'custom_buffer'):\n",
    "        print('Modifying custom_buffer before state_dict()')\n",
    "        module.custom_buffer *= 2\n",
    "hook_handle = model.register_state_dict_pre_hook(state_dict_pre_hook)\n",
    "print('Calling state_dict()...')\n",
    "state_dict = model.state_dict()\n",
    "print('\\n Final State Dict:')\n",
    "for key, value in state_dict.items():\n",
    "    print(f'{key}: {value}')\n",
    "hook_handle.remove()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "088b3a9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calling state_dict()\n",
      "\n",
      "State Dict Pre-Hook:\n",
      "Module: SimpleModel(\n",
      "  (fc1): Linear(in_features=10, out_features=20, bias=True)\n",
      "  (fc2): Linear(in_features=20, out_features=5, bias=True)\n",
      ")\n",
      "Prefix: \n",
      "Keep Vars: False\n",
      "Modifying custom_buffer before state_dict()\n",
      "\n",
      "Final State Dict:\n",
      "custom_buffer:tensor([2., 2., 2., 2., 2.])\n",
      "fc1.weight:tensor([[-0.1155,  0.2292,  0.0573, -0.3049, -0.0555,  0.1106,  0.0952, -0.2587,\n",
      "         -0.1162,  0.0899],\n",
      "        [-0.2827, -0.1889,  0.2165,  0.1744,  0.0199,  0.2662,  0.1119,  0.2396,\n",
      "         -0.0439,  0.3129],\n",
      "        [-0.2989,  0.1222, -0.0627, -0.0303, -0.0262, -0.0352,  0.1268, -0.2019,\n",
      "         -0.1527, -0.0622],\n",
      "        [ 0.2302, -0.0513,  0.1327, -0.0952,  0.1496, -0.1316,  0.1000,  0.0267,\n",
      "         -0.2992, -0.1106],\n",
      "        [-0.2221, -0.1115,  0.1748, -0.2518,  0.1159,  0.2741,  0.0249,  0.0375,\n",
      "          0.2054,  0.2271],\n",
      "        [-0.2687, -0.0807, -0.1639,  0.0248, -0.0882, -0.0107, -0.2943,  0.0908,\n",
      "          0.0523,  0.0212],\n",
      "        [ 0.0494, -0.2712, -0.0424,  0.2253,  0.3115, -0.2283,  0.2694,  0.3138,\n",
      "          0.2667,  0.2746],\n",
      "        [-0.0729, -0.0988,  0.0434, -0.1398, -0.2589, -0.2745,  0.3057,  0.2291,\n",
      "          0.2060,  0.1352],\n",
      "        [ 0.0229, -0.2647, -0.1380, -0.0976, -0.2048,  0.2692,  0.2802,  0.0537,\n",
      "          0.2087,  0.1170],\n",
      "        [-0.0438, -0.2925, -0.0836, -0.1196, -0.2159,  0.1585, -0.2528, -0.2774,\n",
      "         -0.0534, -0.3124],\n",
      "        [-0.2608,  0.0028,  0.1281, -0.0546, -0.1384, -0.0727, -0.0839,  0.1532,\n",
      "          0.0624,  0.2738],\n",
      "        [ 0.0031, -0.1006, -0.1272,  0.0289,  0.0663,  0.2897, -0.2663, -0.1253,\n",
      "          0.0712,  0.1557],\n",
      "        [-0.1541, -0.2104,  0.0749,  0.2553, -0.2308, -0.1738, -0.0283,  0.2645,\n",
      "         -0.0346,  0.1057],\n",
      "        [-0.1004, -0.1587, -0.1919,  0.1540, -0.1247,  0.2131,  0.0686,  0.3110,\n",
      "          0.0594,  0.0339],\n",
      "        [-0.0018,  0.0836, -0.2104, -0.1784, -0.2305, -0.2923, -0.0670, -0.0286,\n",
      "         -0.1073, -0.1998],\n",
      "        [-0.1042, -0.2453, -0.0285,  0.1530,  0.2947, -0.2212,  0.0985,  0.0226,\n",
      "         -0.1659,  0.1923],\n",
      "        [ 0.1983,  0.0646,  0.0138,  0.1858,  0.2904, -0.0920, -0.0339,  0.2536,\n",
      "         -0.1849,  0.0980],\n",
      "        [ 0.1994,  0.0750,  0.1562, -0.1415,  0.0375, -0.3128,  0.3161,  0.0116,\n",
      "         -0.1441, -0.1415],\n",
      "        [ 0.1860, -0.2698, -0.3074,  0.0395, -0.2495,  0.0536,  0.2596,  0.2406,\n",
      "          0.1899, -0.2936],\n",
      "        [-0.0778, -0.1647,  0.1694,  0.2066, -0.1432,  0.2693, -0.2627, -0.2201,\n",
      "          0.1880, -0.2139]])\n",
      "fc1.bias:tensor([ 0.2854, -0.1097, -0.0812,  0.0392, -0.2585, -0.0119, -0.1827,  0.2398,\n",
      "         0.1663,  0.1054,  0.2642,  0.0322, -0.1917,  0.1727, -0.1867, -0.0352,\n",
      "        -0.2026, -0.1442,  0.2163, -0.0670])\n",
      "fc2.weight:tensor([[ 1.7147e-01, -1.3440e-01, -9.4636e-03,  6.7619e-02,  2.1157e-01,\n",
      "         -1.9009e-01,  3.1730e-02,  5.3419e-05,  9.2227e-02, -8.9340e-02,\n",
      "         -8.0550e-02,  1.7064e-01, -1.1126e-01, -2.0567e-01, -3.8196e-02,\n",
      "         -9.7352e-02,  4.0389e-03, -2.2338e-01,  1.7135e-02, -5.7879e-02],\n",
      "        [-1.8902e-01,  1.2733e-01,  1.3487e-01, -9.4675e-02, -1.3291e-01,\n",
      "          2.2448e-02,  6.8145e-02,  1.8041e-01, -1.3088e-01,  1.7343e-01,\n",
      "         -1.1385e-01, -1.2632e-01,  6.5110e-02,  9.0344e-02,  1.2136e-01,\n",
      "          1.2972e-01,  1.7048e-01, -1.4570e-01, -9.1672e-02, -4.0989e-02],\n",
      "        [ 7.4270e-02, -1.6195e-01,  3.4686e-02, -2.0108e-01, -1.5089e-02,\n",
      "         -5.8032e-02, -3.0515e-03,  7.0617e-02, -1.4478e-01, -1.4561e-01,\n",
      "         -1.8537e-01,  1.2357e-01,  9.4906e-02,  5.7443e-02,  1.4601e-03,\n",
      "         -4.4055e-02, -1.4019e-02, -1.0597e-01,  2.1802e-02,  7.7010e-03],\n",
      "        [ 1.1487e-01, -1.4211e-01, -3.4640e-02,  2.8480e-02,  1.5266e-01,\n",
      "         -1.4148e-01, -9.8594e-02,  1.1868e-01, -1.7476e-01, -1.2066e-01,\n",
      "         -1.1253e-01,  9.5469e-02, -8.0417e-02, -2.1961e-01, -7.0782e-02,\n",
      "         -1.8029e-01, -1.9200e-01, -1.7011e-01, -2.1172e-01, -2.3441e-03],\n",
      "        [ 1.0423e-01, -7.5308e-02,  1.1011e-01, -1.0342e-01, -8.2272e-02,\n",
      "         -1.3172e-01,  1.7112e-01,  9.8398e-02, -4.8244e-02,  7.5089e-02,\n",
      "          1.4772e-01,  8.4011e-02,  1.6422e-01, -6.6436e-02, -1.0504e-01,\n",
      "          1.2525e-01,  1.2906e-01, -1.6791e-01,  7.2501e-02, -7.1832e-02]])\n",
      "fc2.bias:tensor([-0.0458, -0.1684, -0.0249, -0.0121,  0.2184])\n"
     ]
    }
   ],
   "source": [
    "#register_state_dict_pre_hook()\n",
    "\n",
    "#method allows to regiter hook that is executed before the state_dict method of a module is called\n",
    "# this hook can be used to inspect or modift the state of the model before the state_dict is generated\n",
    "\n",
    "import torch \n",
    "import torch.nn as nn \n",
    "\n",
    "class SimpleModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(10,20)\n",
    "        self.fc2 = nn.Linear(20,5)\n",
    "\n",
    "        self.register_buffer('custom_buffer', torch.ones(5))\n",
    "\n",
    "model = SimpleModel()\n",
    "\n",
    "def state_dict_pre_hook(module, prefix,keep_vars):\n",
    "    print('\\nState Dict Pre-Hook:')\n",
    "    print(f'Module: {module}')\n",
    "    print(f'Prefix: {prefix}')\n",
    "    print(f'Keep Vars: {keep_vars}')\n",
    "\n",
    "    #modify the model's state before generating the state_dict\n",
    "    if hasattr(module, 'custom_buffer'):\n",
    "        print('Modifying custom_buffer before state_dict()')\n",
    "        module.custom_buffer *=2 \n",
    "\n",
    "hook_handle = model.register_state_dict_pre_hook(state_dict_pre_hook)\n",
    "\n",
    "#call state_dict() and observe the modifications\n",
    "print('calling state_dict()')\n",
    "state_dict = model.state_dict()\n",
    "print('\\nFinal State Dict:')\n",
    "for key, value in state_dict.items():\n",
    "    print(f'{key}:{value}')\n",
    "hook_handle.remove()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "821808a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving state_dict\n",
      "Custom info before loading: Modified Value\n",
      "\n",
      "Loading state_dict...\n",
      "Custom info after loading:Modified Value\n"
     ]
    }
   ],
   "source": [
    "#set_extra_state() used to hadnel extra state stored in state_dict\n",
    "# useful when want to save an dload custom attributes or metadat that are not part of the standard parameters or buffers of a module\n",
    "\n",
    "import torch \n",
    "import torch.nn as nn \n",
    "\n",
    "class CustomModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc = nn.Linear(10,5)\n",
    "\n",
    "        #custom attribute to store extra state\n",
    "        self.custom_info = 'Initial Value'\n",
    "\n",
    "    def forward(self,x):\n",
    "        return self.fc(x)\n",
    "    \n",
    "def get_extra_state(self):\n",
    "    \"\"\"\n",
    "    Retrieve the extra state to be saved in the sate_dict\n",
    "    \"\"\"\n",
    "\n",
    "    print('Retrieving extra state...')\n",
    "    return {'custom_info':self.custom_info}\n",
    "\n",
    "def set_extra_state(self, state):\n",
    "    '''\n",
    "    Set the extra state loaded from the state_dict\n",
    "    '''\n",
    "    print('Setting extra state...')\n",
    "    self.custom_info = state.get('custom_info', 'Default Value')\n",
    "\n",
    "model = CustomModel()\n",
    "#prnit the model's state_dict\n",
    "print('Saving state_dict')\n",
    "torch.save(model.state_dict(), 'model_state.pth')\n",
    "\n",
    "#modify the custom_info attirbute\n",
    "model.custom_info ='Modified Value'\n",
    "print(f'Custom info before loading: {model.custom_info}')\n",
    "\n",
    "print('\\nLoading state_dict...')\n",
    "state_dict = torch.load('model_state.pth')\n",
    "print(f'Custom info after loading:{model.custom_info}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4cafba82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Model Structure:\n",
      "NestedModel(\n",
      "  (net_b): Module(\n",
      "    (net_c): Module(\n",
      "      (conv): Conv2d(16, 33, kernel_size=(3, 3), stride=(2, 2))\n",
      "    )\n",
      "    (linear): Linear(in_features=100, out_features=200, bias=True)\n",
      "  )\n",
      ")\n",
      "\n",
      "Modified Model Structure:\n",
      "NestedModel(\n",
      "  (net_b): Module(\n",
      "    (net_c): Module(\n",
      "      (conv): Linear(in_features=33, out_features=16, bias=True)\n",
      "    )\n",
      "    (linear): Linear(in_features=100, out_features=200, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "#set_submodule()\n",
    "\n",
    "#replace submodule within a model using fully-qualified name \n",
    "# useful when you want to dynamically modify parts of your model 9repacling a layer or swapping entire submodules\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Define a nested model\n",
    "class NestedModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Create submodules\n",
    "        self.net_b = nn.Module()  # Parent submodule\n",
    "        self.net_b.net_c = nn.Module()  # Nested submodule\n",
    "        self.net_b.net_c.conv = nn.Conv2d(16, 33, kernel_size=(3, 3), stride=(2, 2))  # Conv2d layer\n",
    "        self.net_b.linear = nn.Linear(100, 200)  # Linear layer\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Use the conv layer in net_b.net_c\n",
    "        return self.net_b.net_c.conv(x)\n",
    "\n",
    "# Create the model\n",
    "model = NestedModel()\n",
    "\n",
    "# Print the initial structure of the model\n",
    "print(\"Initial Model Structure:\")\n",
    "print(model)\n",
    "\n",
    "# Replace the Conv2d layer with a Linear layer\n",
    "new_linear_layer = nn.Linear(33, 16)\n",
    "model.set_submodule(\"net_b.net_c.conv\", new_linear_layer)\n",
    "\n",
    "# Modify the forward pass to handle the Linear layer\n",
    "def modified_forward(self, x):\n",
    "    # Flatten the input for the Linear layer\n",
    "    x = x.view(x.size(0), -1)  # Reshape to [batch_size, features]\n",
    "    return self.net_b.net_c.conv(x)\n",
    "\n",
    "# Update the model's forward method\n",
    "model.forward = modified_forward.__get__(model)\n",
    "\n",
    "# Print the modified structure of the model\n",
    "print(\"\\nModified Model Structure:\")\n",
    "print(model)\n",
    "\n",
    "# # Perform a forward pass with dummy input\n",
    "# dummy_input = torch.randn(1, 16, 10, 10)  # Input tensor for the Conv2d layer\n",
    "# output = model(dummy_input)\n",
    "# print(\"\\nOutput shape:\", output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "bc677d64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Parameters After share_memory()\n",
      "fc.weight:True\n",
      "fc.bias:True\n",
      "Output in worker process: tensor([[-0.4966,  0.0919, -0.3421,  0.5134, -0.1519],\n",
      "        [ 0.7050, -0.7392,  0.6057,  0.0027, -0.8711],\n",
      "        [-0.6415, -0.4897,  0.2836,  0.4208, -0.1635],\n",
      "        [-0.5252, -0.0490,  0.0269,  0.8973, -0.1599]],\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Output in worker process: tensor([[-0.4966,  0.0919, -0.3421,  0.5134, -0.1519],\n",
      "        [ 0.7050, -0.7392,  0.6057,  0.0027, -0.8711],\n",
      "        [-0.6415, -0.4897,  0.2836,  0.4208, -0.1635],\n",
      "        [-0.5252, -0.0490,  0.0269,  0.8973, -0.1599]],\n",
      "       grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "#share_memory() \n",
    "\n",
    "#used to move a tensor or module to shared memory\n",
    "# enable it o share acorss multiple processes\n",
    "# particularly useful in multiprocessing scenarios such as distrubuted training or parallel data loading where tensros or model parameters need to be accessed by multiple workers\n",
    "\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "from multiprocessing import Process\n",
    "\n",
    "class SimpleModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc = nn.Linear(10,5)\n",
    "\n",
    "    def forward(self,x):\n",
    "        return self.fc(x)\n",
    "    \n",
    "model = SimpleModel()\n",
    "\n",
    "model.share_memory()\n",
    "\n",
    "print('Model Parameters After share_memory()')\n",
    "\n",
    "for name, param in model.named_parameters():\n",
    "    print(f'{name}:{param.is_shared()}')\n",
    "\n",
    "#define a funtion to simulate a worker process\n",
    "def worker_process(model, input_tensor):\n",
    "    output = model(input_tensor) # perform a foward pass in the worker process\n",
    "    print(f'Output in worker process: {output}')\n",
    "\n",
    "shared_input = torch.randn(4,10)\n",
    "shared_input.share_memory_()\n",
    "\n",
    "process1 = Process(target=worker_process, args=(model, shared_input))\n",
    "process2 = Process(target=worker_process, args=(model, shared_input))\n",
    "\n",
    "process1.start()\n",
    "process2.start()\n",
    "\n",
    "process1.join()\n",
    "process2.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7439c153",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keys in state_dict:\n",
      "running_mean\n",
      "fc1.weight\n",
      "fc1.bias\n",
      "fc2.weight\n",
      "fc2.bias\n",
      "\n",
      "Full state_dict:\n",
      "running_mean: tensor([0., 0., 0., 0., 0.])\n",
      "fc1.weight: tensor([[-0.2667, -0.1428, -0.3120,  0.0955,  0.0934, -0.2612, -0.0013, -0.0882,\n",
      "          0.0570, -0.2672],\n",
      "        [-0.1139,  0.0882,  0.2662, -0.1231, -0.2092, -0.1870, -0.1551,  0.2779,\n",
      "          0.2236, -0.2545],\n",
      "        [ 0.2204,  0.2844,  0.0528,  0.0328, -0.0867, -0.0033, -0.2744,  0.2961,\n",
      "          0.2466,  0.1153],\n",
      "        [-0.2506, -0.0140, -0.1792, -0.1127, -0.2620, -0.2979, -0.1651,  0.1818,\n",
      "          0.2578,  0.2291],\n",
      "        [ 0.1642,  0.1232,  0.3156, -0.3137, -0.0374, -0.1578, -0.0875,  0.2946,\n",
      "          0.0517, -0.0965],\n",
      "        [-0.0508,  0.0968,  0.2908,  0.1018,  0.0919, -0.0079,  0.1661, -0.1900,\n",
      "          0.1851, -0.0072],\n",
      "        [-0.2535,  0.0816, -0.1212,  0.0435, -0.1359, -0.2821,  0.2410,  0.2737,\n",
      "          0.2468,  0.1387],\n",
      "        [-0.2934,  0.0301,  0.1314, -0.0677, -0.2594, -0.1470, -0.0372, -0.2091,\n",
      "         -0.2899,  0.1247],\n",
      "        [ 0.1925, -0.1569, -0.2958, -0.2231,  0.1216, -0.2508,  0.1696, -0.1890,\n",
      "          0.0090, -0.2010],\n",
      "        [ 0.0899,  0.0444, -0.1677, -0.0234, -0.2846, -0.1280,  0.2634, -0.0517,\n",
      "          0.1513,  0.2714],\n",
      "        [ 0.0368,  0.0805, -0.1454,  0.1877, -0.2106,  0.1615, -0.0365, -0.1337,\n",
      "          0.0409,  0.0024],\n",
      "        [ 0.1323, -0.0700, -0.2225,  0.1183, -0.0618,  0.2209, -0.0014, -0.1202,\n",
      "          0.3157,  0.0052],\n",
      "        [-0.2296, -0.2227,  0.3159, -0.3126, -0.1119,  0.1025,  0.2320, -0.0949,\n",
      "          0.1530,  0.0116],\n",
      "        [-0.2763, -0.0979, -0.0344, -0.1612,  0.0692,  0.1277,  0.1707,  0.1379,\n",
      "         -0.1078, -0.0664],\n",
      "        [ 0.1848, -0.0757, -0.3109,  0.0083,  0.2193, -0.0847, -0.2796, -0.1800,\n",
      "         -0.2557, -0.0302],\n",
      "        [ 0.2349, -0.0307,  0.2963, -0.2996, -0.2794, -0.3140,  0.0829,  0.1110,\n",
      "          0.1440,  0.1735],\n",
      "        [ 0.2506, -0.2327, -0.2954,  0.0901,  0.0503, -0.1389,  0.0289, -0.0080,\n",
      "         -0.0345, -0.1679],\n",
      "        [-0.2441, -0.2336,  0.3028,  0.2059,  0.1676, -0.2542, -0.0403, -0.0850,\n",
      "         -0.1969,  0.2207],\n",
      "        [-0.1016,  0.2738,  0.2905,  0.2409,  0.0008,  0.1408, -0.2247,  0.2008,\n",
      "         -0.2243,  0.0549],\n",
      "        [ 0.1676,  0.1691,  0.0850,  0.2890, -0.0889,  0.1346,  0.2378,  0.0392,\n",
      "         -0.2687, -0.1726]])\n",
      "fc1.bias: tensor([ 0.0077,  0.1536,  0.3011, -0.1019,  0.2979, -0.0089, -0.2795, -0.0712,\n",
      "         0.1336,  0.3011, -0.1914, -0.0353, -0.1382, -0.0922,  0.2471, -0.2302,\n",
      "        -0.3086, -0.0909,  0.3023, -0.2685])\n",
      "fc2.weight: tensor([[ 0.1516, -0.0957,  0.1331,  0.1527, -0.2031,  0.0273, -0.1787,  0.0993,\n",
      "          0.0786, -0.0395, -0.0766,  0.0622,  0.1693, -0.1549,  0.1808,  0.0282,\n",
      "          0.0265, -0.1272,  0.0785,  0.1951],\n",
      "        [ 0.1430,  0.0242,  0.0448, -0.2194, -0.2100,  0.0888, -0.1266,  0.0818,\n",
      "          0.0457,  0.2210,  0.2125, -0.1927,  0.0996,  0.0803,  0.0162, -0.0326,\n",
      "          0.1595,  0.0234,  0.1782,  0.2196],\n",
      "        [-0.1327,  0.0079, -0.1217, -0.0675,  0.2207, -0.0490, -0.1777, -0.1338,\n",
      "          0.0963, -0.1204, -0.1172,  0.1475, -0.1045, -0.0939, -0.2152, -0.2184,\n",
      "          0.0238, -0.0309,  0.1465,  0.1531],\n",
      "        [-0.1787, -0.0066,  0.0550, -0.0599, -0.2222, -0.0579, -0.0428,  0.0550,\n",
      "          0.1820, -0.0096,  0.1413,  0.0327, -0.1410, -0.0335,  0.1301,  0.0190,\n",
      "         -0.1687, -0.1461, -0.1251,  0.2087],\n",
      "        [ 0.0724, -0.0930,  0.0046,  0.1776, -0.0774,  0.1886, -0.1519,  0.0425,\n",
      "          0.0741,  0.0080,  0.1117,  0.0208, -0.1600, -0.1663, -0.1106,  0.0168,\n",
      "          0.0179,  0.1076, -0.1438, -0.0475]])\n",
      "fc2.bias: tensor([-0.1126, -0.0940, -0.2009, -0.0075,  0.0079])\n",
      "\n",
      "State dict saved to 'model_state.pth'.\n",
      "\n",
      "State dict loaded into new model.\n",
      "\n",
      "New model's state_dict:\n",
      "running_mean: tensor([0., 0., 0., 0., 0.])\n",
      "fc1.weight: tensor([[-0.2667, -0.1428, -0.3120,  0.0955,  0.0934, -0.2612, -0.0013, -0.0882,\n",
      "          0.0570, -0.2672],\n",
      "        [-0.1139,  0.0882,  0.2662, -0.1231, -0.2092, -0.1870, -0.1551,  0.2779,\n",
      "          0.2236, -0.2545],\n",
      "        [ 0.2204,  0.2844,  0.0528,  0.0328, -0.0867, -0.0033, -0.2744,  0.2961,\n",
      "          0.2466,  0.1153],\n",
      "        [-0.2506, -0.0140, -0.1792, -0.1127, -0.2620, -0.2979, -0.1651,  0.1818,\n",
      "          0.2578,  0.2291],\n",
      "        [ 0.1642,  0.1232,  0.3156, -0.3137, -0.0374, -0.1578, -0.0875,  0.2946,\n",
      "          0.0517, -0.0965],\n",
      "        [-0.0508,  0.0968,  0.2908,  0.1018,  0.0919, -0.0079,  0.1661, -0.1900,\n",
      "          0.1851, -0.0072],\n",
      "        [-0.2535,  0.0816, -0.1212,  0.0435, -0.1359, -0.2821,  0.2410,  0.2737,\n",
      "          0.2468,  0.1387],\n",
      "        [-0.2934,  0.0301,  0.1314, -0.0677, -0.2594, -0.1470, -0.0372, -0.2091,\n",
      "         -0.2899,  0.1247],\n",
      "        [ 0.1925, -0.1569, -0.2958, -0.2231,  0.1216, -0.2508,  0.1696, -0.1890,\n",
      "          0.0090, -0.2010],\n",
      "        [ 0.0899,  0.0444, -0.1677, -0.0234, -0.2846, -0.1280,  0.2634, -0.0517,\n",
      "          0.1513,  0.2714],\n",
      "        [ 0.0368,  0.0805, -0.1454,  0.1877, -0.2106,  0.1615, -0.0365, -0.1337,\n",
      "          0.0409,  0.0024],\n",
      "        [ 0.1323, -0.0700, -0.2225,  0.1183, -0.0618,  0.2209, -0.0014, -0.1202,\n",
      "          0.3157,  0.0052],\n",
      "        [-0.2296, -0.2227,  0.3159, -0.3126, -0.1119,  0.1025,  0.2320, -0.0949,\n",
      "          0.1530,  0.0116],\n",
      "        [-0.2763, -0.0979, -0.0344, -0.1612,  0.0692,  0.1277,  0.1707,  0.1379,\n",
      "         -0.1078, -0.0664],\n",
      "        [ 0.1848, -0.0757, -0.3109,  0.0083,  0.2193, -0.0847, -0.2796, -0.1800,\n",
      "         -0.2557, -0.0302],\n",
      "        [ 0.2349, -0.0307,  0.2963, -0.2996, -0.2794, -0.3140,  0.0829,  0.1110,\n",
      "          0.1440,  0.1735],\n",
      "        [ 0.2506, -0.2327, -0.2954,  0.0901,  0.0503, -0.1389,  0.0289, -0.0080,\n",
      "         -0.0345, -0.1679],\n",
      "        [-0.2441, -0.2336,  0.3028,  0.2059,  0.1676, -0.2542, -0.0403, -0.0850,\n",
      "         -0.1969,  0.2207],\n",
      "        [-0.1016,  0.2738,  0.2905,  0.2409,  0.0008,  0.1408, -0.2247,  0.2008,\n",
      "         -0.2243,  0.0549],\n",
      "        [ 0.1676,  0.1691,  0.0850,  0.2890, -0.0889,  0.1346,  0.2378,  0.0392,\n",
      "         -0.2687, -0.1726]])\n",
      "fc1.bias: tensor([ 0.0077,  0.1536,  0.3011, -0.1019,  0.2979, -0.0089, -0.2795, -0.0712,\n",
      "         0.1336,  0.3011, -0.1914, -0.0353, -0.1382, -0.0922,  0.2471, -0.2302,\n",
      "        -0.3086, -0.0909,  0.3023, -0.2685])\n",
      "fc2.weight: tensor([[ 0.1516, -0.0957,  0.1331,  0.1527, -0.2031,  0.0273, -0.1787,  0.0993,\n",
      "          0.0786, -0.0395, -0.0766,  0.0622,  0.1693, -0.1549,  0.1808,  0.0282,\n",
      "          0.0265, -0.1272,  0.0785,  0.1951],\n",
      "        [ 0.1430,  0.0242,  0.0448, -0.2194, -0.2100,  0.0888, -0.1266,  0.0818,\n",
      "          0.0457,  0.2210,  0.2125, -0.1927,  0.0996,  0.0803,  0.0162, -0.0326,\n",
      "          0.1595,  0.0234,  0.1782,  0.2196],\n",
      "        [-0.1327,  0.0079, -0.1217, -0.0675,  0.2207, -0.0490, -0.1777, -0.1338,\n",
      "          0.0963, -0.1204, -0.1172,  0.1475, -0.1045, -0.0939, -0.2152, -0.2184,\n",
      "          0.0238, -0.0309,  0.1465,  0.1531],\n",
      "        [-0.1787, -0.0066,  0.0550, -0.0599, -0.2222, -0.0579, -0.0428,  0.0550,\n",
      "          0.1820, -0.0096,  0.1413,  0.0327, -0.1410, -0.0335,  0.1301,  0.0190,\n",
      "         -0.1687, -0.1461, -0.1251,  0.2087],\n",
      "        [ 0.0724, -0.0930,  0.0046,  0.1776, -0.0774,  0.1886, -0.1519,  0.0425,\n",
      "          0.0741,  0.0080,  0.1117,  0.0208, -0.1600, -0.1663, -0.1106,  0.0168,\n",
      "          0.0179,  0.1076, -0.1438, -0.0475]])\n",
      "fc2.bias: tensor([-0.1126, -0.0940, -0.2009, -0.0075,  0.0079])\n"
     ]
    }
   ],
   "source": [
    "#state_dict()\n",
    "\n",
    "# retunrs a dictionary containing the entire sate of a module including its parametres and parsistent buffers.\n",
    "#useful for saving and loading models as well as inspecting their internal state\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Define a simple model\n",
    "class SimpleModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(10, 20)\n",
    "        self.fc2 = nn.Linear(20, 5)\n",
    "\n",
    "        # Register a buffer\n",
    "        self.register_buffer('running_mean', torch.zeros(5))\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc2(torch.relu(self.fc1(x)))\n",
    "\n",
    "# Create the model\n",
    "model = SimpleModel()\n",
    "\n",
    "# Print the keys of the state_dict\n",
    "print(\"Keys in state_dict:\")\n",
    "for key in model.state_dict().keys():\n",
    "    print(key)\n",
    "\n",
    "# Access the full state_dict\n",
    "print(\"\\nFull state_dict:\")\n",
    "for key, value in model.state_dict().items():\n",
    "    print(f\"{key}: {value}\")\n",
    "\n",
    "# Save the state_dict to a file\n",
    "torch.save(model.state_dict(), \"model_state.pth\")\n",
    "print(\"\\nState dict saved to 'model_state.pth'.\")\n",
    "\n",
    "# Load the state_dict from the file into a new model\n",
    "new_model = SimpleModel()\n",
    "new_model.load_state_dict(torch.load(\"model_state.pth\"))\n",
    "print(\"\\nState dict loaded into new model.\")\n",
    "\n",
    "# Verify that the new model has the same state\n",
    "print(\"\\nNew model's state_dict:\")\n",
    "for key, value in new_model.state_dict().items():\n",
    "    print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e49e1e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Model Parameters:\n",
      "fc.weight: torch.float32, cpu\n",
      "fc.bias: torch.float32, cpu\n",
      "\n",
      "After Moving to Device: cpu\n",
      "fc.weight: torch.float32, cpu\n",
      "fc.bias: torch.float32, cpu\n",
      "\n",
      "After Casting to Half-Precision (float16):\n",
      "fc.weight: torch.float16, cpu\n",
      "fc.bias: torch.float16, cpu\n",
      "\n",
      "After Moving to CPU and Casting to Double-Precision (float64):\n",
      "fc.weight: torch.float64, cpu\n",
      "fc.bias: torch.float64, cpu\n",
      "\n",
      "Forward Pass Output:\n",
      "tensor([[ 0.2896, -0.5687],\n",
      "        [ 0.2896, -0.5687],\n",
      "        [ 0.2896, -0.5687]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# to()\n",
    "\n",
    "# move and/or cast the parameters and buffers of amoudle to a specified device or memory format\n",
    "# useful when switchin between CPU an dGPU , chaing precision like from flaot32 to float1 , ensuring comapbility with specifc tensor formats\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Define a simple model\n",
    "class SimpleModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc = nn.Linear(2, 2)  # Fully connected layer\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc(x)\n",
    "\n",
    "# Create the model\n",
    "model = SimpleModel()\n",
    "\n",
    "# Print initial state of the model's parameters\n",
    "print(\"Initial Model Parameters:\")\n",
    "for name, param in model.named_parameters():\n",
    "    print(f\"{name}: {param.dtype}, {param.device}\")\n",
    "\n",
    "# Move the model to GPU (if available)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "print(\"\\nAfter Moving to Device:\", device)\n",
    "for name, param in model.named_parameters():\n",
    "    print(f\"{name}: {param.dtype}, {param.device}\")\n",
    "\n",
    "# Cast the model's parameters to half-precision (float16)\n",
    "model.to(dtype=torch.float16)\n",
    "\n",
    "print(\"\\nAfter Casting to Half-Precision (float16):\")\n",
    "for name, param in model.named_parameters():\n",
    "    print(f\"{name}: {param.dtype}, {param.device}\")\n",
    "\n",
    "# Move the model back to CPU and cast to double-precision (float64)\n",
    "model.to(device=torch.device(\"cpu\"), dtype=torch.float64)\n",
    "\n",
    "print(\"\\nAfter Moving to CPU and Casting to Double-Precision (float64):\")\n",
    "for name, param in model.named_parameters():\n",
    "    print(f\"{name}: {param.dtype}, {param.device}\")\n",
    "\n",
    "# Perform a forward pass with a tensor on the same device and dtype\n",
    "input_tensor = torch.ones(3, 2, dtype=torch.float64, device=torch.device(\"cpu\"))\n",
    "output = model(input_tensor)\n",
    "print(\"\\nForward Pass Output:\")\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5355cf92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Model Parameters:\n",
      "fc1.weight: cpu, torch.float32\n",
      "fc1.bias: cpu, torch.float32\n",
      "fc2.weight: cpu, torch.float32\n",
      "fc2.bias: cpu, torch.float32\n",
      "\n",
      "After Moving to Device (Empty Storage): cpu\n",
      "fc1.weight: cpu, torch.float32\n",
      "fc1.bias: cpu, torch.float32\n",
      "fc2.weight: cpu, torch.float32\n",
      "fc2.bias: cpu, torch.float32\n",
      "\n",
      "Checking if tensors are uninitialized:\n",
      "fc1.weight: 439769728\n",
      "fc1.bias: 439655424\n",
      "fc2.weight: 439123840\n",
      "fc2.bias: 439104128\n",
      "\n",
      "Forward Pass Output Shape: torch.Size([4, 5])\n"
     ]
    }
   ],
   "source": [
    "#to_empty()\n",
    "\n",
    "#move parameters and buffers of module to specified device wih=thout copying their store\n",
    "# use when you watn to allocate memory for tensors on a specific device wihtout transfering their current values. \n",
    "# tensor initialized as empty on the target device\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Define a simple model\n",
    "class SimpleModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(10, 20)  # Fully connected layer 1\n",
    "        self.fc2 = nn.Linear(20, 5)   # Fully connected layer 2\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc2(torch.relu(self.fc1(x)))\n",
    "\n",
    "# Create the model\n",
    "model = SimpleModel()\n",
    "\n",
    "# Print initial state of the model's parameters (on CPU)\n",
    "print(\"Initial Model Parameters:\")\n",
    "for name, param in model.named_parameters():\n",
    "    print(f\"{name}: {param.device}, {param.dtype}\")\n",
    "\n",
    "# Move the model to a GPU (if available) using to_empty()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to_empty(device=device)\n",
    "\n",
    "print(\"\\nAfter Moving to Device (Empty Storage):\", device)\n",
    "for name, param in model.named_parameters():\n",
    "    print(f\"{name}: {param.device}, {param.dtype}\")\n",
    "\n",
    "# Check if the tensors are empty (uninitialized)\n",
    "print(\"\\nChecking if tensors are uninitialized:\")\n",
    "for name, param in model.named_parameters():\n",
    "    print(f\"{name}: {param.data_ptr()}\")  # Data pointer indicates uninitialized storage\n",
    "\n",
    "# Perform a forward pass with dummy input on the same device\n",
    "input_tensor = torch.randn(4, 10, device=device)  # Batch size: 4, Input features: 10\n",
    "output = model(input_tensor)\n",
    "print(\"\\nForward Pass Output Shape:\", output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a60fa2fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Mode:\n",
      "Model in training mode: True\n",
      "\n",
      "After Setting to Training Mode:\n",
      "Model in training mode: True\n",
      "Dropout active: True\n",
      "BatchNorm in training mode: True\n",
      "\n",
      "Output in Training Mode (with Dropout and BatchNorm):\n",
      "tensor([[ 0.0759, -0.3735, -0.0089,  0.0603, -0.7545],\n",
      "        [-0.2788,  0.5420,  0.4794, -1.0626, -0.4399],\n",
      "        [ 0.1067,  0.7035, -0.4835,  0.2310,  0.3309],\n",
      "        [-0.4473, -0.5017, -0.1215,  0.6419,  0.3413]],\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "\n",
      "After Setting to Evaluation Mode:\n",
      "Model in training mode: False\n",
      "Dropout active: False\n",
      "BatchNorm in training mode: False\n",
      "\n",
      "Output in Evaluation Mode (without Dropout and BatchNorm updates):\n",
      "tensor([[ 0.0606,  0.1784, -0.0317, -0.4120, -0.2390],\n",
      "        [-0.0865,  0.1308,  0.3176, -0.8944, -0.5810],\n",
      "        [ 0.1183,  0.1333,  0.1105, -0.6027, -0.2551],\n",
      "        [ 0.1547,  0.1821, -0.1626, -0.4336, -0.0600]],\n",
      "       grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "#train(mode=True))\n",
    "\n",
    "#used to set the module into training mode or evaluation mode\n",
    "# important for moduels like Dropout , BatchNorm and otehrs that behave differently during trainig versus evaluation\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Define a model with Dropout and BatchNorm layers\n",
    "class SimpleModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(10, 20)\n",
    "        self.dropout = nn.Dropout(p=0.5)  # Dropout layer\n",
    "        self.bn = nn.BatchNorm1d(20)      # BatchNorm layer\n",
    "        self.fc2 = nn.Linear(20, 5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.bn(x)\n",
    "        return self.fc2(x)\n",
    "\n",
    "# Create the model\n",
    "model = SimpleModel()\n",
    "\n",
    "# Print initial mode of the model\n",
    "print(\"Initial Mode:\")\n",
    "print(f\"Model in training mode: {model.training}\")\n",
    "\n",
    "# Set the model to training mode\n",
    "model.train()\n",
    "print(\"\\nAfter Setting to Training Mode:\")\n",
    "print(f\"Model in training mode: {model.training}\")\n",
    "print(f\"Dropout active: {model.dropout.training}\")\n",
    "print(f\"BatchNorm in training mode: {model.bn.training}\")\n",
    "\n",
    "# Perform a forward pass in training mode\n",
    "input_tensor = torch.randn(4, 10)  # Batch size: 4, Input features: 10\n",
    "output_train = model(input_tensor)\n",
    "print(\"\\nOutput in Training Mode (with Dropout and BatchNorm):\")\n",
    "print(output_train)\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "model.eval()\n",
    "print(\"\\nAfter Setting to Evaluation Mode:\")\n",
    "print(f\"Model in training mode: {model.training}\")\n",
    "print(f\"Dropout active: {model.dropout.training}\")\n",
    "print(f\"BatchNorm in training mode: {model.bn.training}\")\n",
    "\n",
    "# Perform a forward pass in evaluation mode\n",
    "output_eval = model(input_tensor)\n",
    "print(\"\\nOutput in Evaluation Mode (without Dropout and BatchNorm updates):\")\n",
    "print(output_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8187c1fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Data Types:\n",
      "fc1.weight: torch.float32\n",
      "fc1.bias: torch.float32\n",
      "fc2.weight: torch.float32\n",
      "fc2.bias: torch.float32\n",
      "\n",
      "After Casting to float16:\n",
      "fc1.weight: torch.float16\n",
      "fc1.bias: torch.float16\n",
      "fc2.weight: torch.float16\n",
      "fc2.bias: torch.float16\n",
      "\n",
      "Forward Pass Output Shape: torch.Size([4, 5])\n",
      "Output Data Type: torch.float16\n",
      "\n",
      "After Casting Back to float32:\n",
      "fc1.weight: torch.float32\n",
      "fc1.bias: torch.float32\n",
      "fc2.weight: torch.float32\n",
      "fc2.bias: torch.float32\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#type(dst_type)\n",
    "\n",
    "#cast all parameters and buffers of modue to a specified type (dst_type)\n",
    "#useful when you want to change the data type of the entier model for mixed precision trainig or other purposes\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Define a simple model\n",
    "class SimpleModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(10, 20)  # Fully connected layer 1\n",
    "        self.fc2 = nn.Linear(20, 5)   # Fully connected layer 2\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc2(torch.relu(self.fc1(x)))\n",
    "\n",
    "# Create the model\n",
    "model = SimpleModel()\n",
    "\n",
    "# Print initial data types of the model's parameters\n",
    "print(\"Initial Data Types:\")\n",
    "for name, param in model.named_parameters():\n",
    "    print(f\"{name}: {param.dtype}\")\n",
    "\n",
    "# Cast the model's parameters and buffers to float16\n",
    "model.type(torch.float16)\n",
    "\n",
    "print(\"\\nAfter Casting to float16:\")\n",
    "for name, param in model.named_parameters():\n",
    "    print(f\"{name}: {param.dtype}\")\n",
    "\n",
    "# Perform a forward pass with a dummy input tensor of float16\n",
    "input_tensor = torch.randn(4, 10, dtype=torch.float16)  # Batch size: 4, Input features: 10\n",
    "output = model(input_tensor)\n",
    "print(\"\\nForward Pass Output Shape:\", output.shape)\n",
    "print(\"Output Data Type:\", output.dtype)\n",
    "\n",
    "# Cast the model back to float32\n",
    "model.type(torch.float32)\n",
    "\n",
    "print(\"\\nAfter Casting Back to float32:\")\n",
    "for name, param in model.named_parameters():\n",
    "    print(f\"{name}: {param.dtype}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8b110bad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Device:\n",
      "fc1.weight: cpu\n",
      "fc1.bias: cpu\n",
      "fc2.weight: cpu\n",
      "fc2.bias: cpu\n",
      "\n",
      "XPU is not available. Skipping XPU operations.\n"
     ]
    }
   ],
   "source": [
    "#xpu(device=None) is used to move all model parameters and buffers to the XPU device\n",
    "# the XPU is intel extenssion for pytorch\n",
    "# allow to leverage intel GPU for deep learning workloads\n",
    "# method similar to cuda() or cpu()\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Define a simple model\n",
    "class SimpleModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(10, 20)  # Fully connected layer 1\n",
    "        self.fc2 = nn.Linear(20, 5)   # Fully connected layer 2\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc2(torch.relu(self.fc1(x)))\n",
    "\n",
    "# Create the model\n",
    "model = SimpleModel()\n",
    "\n",
    "# Print initial device of the model's parameters\n",
    "print(\"Initial Device:\")\n",
    "for name, param in model.named_parameters():\n",
    "    print(f\"{name}: {param.device}\")\n",
    "\n",
    "# Move the model to the XPU device\n",
    "if torch.xpu.is_available():  # Check if XPU is available\n",
    "    model.xpu()  # Move the model to the default XPU device\n",
    "    print(\"\\nAfter Moving to XPU:\")\n",
    "    for name, param in model.named_parameters():\n",
    "        print(f\"{name}: {param.device}\")\n",
    "else:\n",
    "    print(\"\\nXPU is not available. Skipping XPU operations.\")\n",
    "\n",
    "# Perform a forward pass with a dummy input tensor on the XPU\n",
    "if torch.xpu.is_available():\n",
    "    input_tensor = torch.randn(4, 10).xpu()  # Batch size: 4, Input features: 10\n",
    "    output = model(input_tensor)\n",
    "    print(\"\\nForward Pass Output Shape:\", output.shape)\n",
    "    print(\"Output Device:\", output.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "24c849de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Training Step:\n",
      "Gradients before zero_grad():\n",
      "fc.weight: tensor([[-0.0099,  0.1420,  0.0129,  0.0040, -0.5605,  0.2090, -0.3024,  0.5251,\n",
      "         -0.2248, -0.5372],\n",
      "        [ 0.1390,  0.2457,  0.1510, -0.1780,  0.4095, -0.1225, -0.2330,  0.1415,\n",
      "         -0.0484,  0.2039],\n",
      "        [-0.1058, -0.0588, -0.0575,  0.0257, -0.2989,  0.1459, -0.0364,  0.0697,\n",
      "         -0.0378, -0.2662],\n",
      "        [-0.1883,  0.0963,  0.0410, -0.2689,  0.0857,  0.1972, -0.3440,  0.0561,\n",
      "         -0.0434, -0.2374],\n",
      "        [ 0.4255,  0.3597,  0.3066, -0.2412,  0.9135, -0.3818, -0.1576, -0.0387,\n",
      "         -0.2885,  0.3558]])\n",
      "fc.bias: tensor([ 0.3990, -0.1158,  0.1630,  0.0883, -0.1840])\n",
      "\n",
      "Gradients after zero_grad():\n",
      "fc.weight: None\n",
      "fc.bias: None\n",
      "\n",
      "Second Training Step:\n",
      "Gradients after second backward():\n",
      "fc.weight: tensor([[-0.0099,  0.1420,  0.0129,  0.0040, -0.5605,  0.2090, -0.3024,  0.5251,\n",
      "         -0.2248, -0.5372],\n",
      "        [ 0.1390,  0.2457,  0.1510, -0.1780,  0.4095, -0.1225, -0.2330,  0.1415,\n",
      "         -0.0484,  0.2039],\n",
      "        [-0.1058, -0.0588, -0.0575,  0.0257, -0.2989,  0.1459, -0.0364,  0.0697,\n",
      "         -0.0378, -0.2662],\n",
      "        [-0.1883,  0.0963,  0.0410, -0.2689,  0.0857,  0.1972, -0.3440,  0.0561,\n",
      "         -0.0434, -0.2374],\n",
      "        [ 0.4255,  0.3597,  0.3066, -0.2412,  0.9135, -0.3818, -0.1576, -0.0387,\n",
      "         -0.2885,  0.3558]])\n",
      "fc.bias: tensor([ 0.3990, -0.1158,  0.1630,  0.0883, -0.1840])\n"
     ]
    }
   ],
   "source": [
    "#zero_grad(set_to_none=True)\n",
    "\n",
    "#used to reset the gradients of all model parameters. , done at begining of each traning iteration to ensure that gradients from previous iterations do not accumulate\n",
    "# by default , setting set_to_none = True improves performance by freeing the memory oocupied bu the gradients instead of zeroing them out\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Define a simple model\n",
    "class SimpleModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc = nn.Linear(10, 5)  # Fully connected layer\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc(x)\n",
    "\n",
    "# Create the model and a dummy input\n",
    "model = SimpleModel()\n",
    "input_tensor = torch.randn(4, 10)  # Batch size: 4, Input features: 10\n",
    "target = torch.randn(4, 5) \n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "print('First Training Step:')\n",
    "output = model(input_tensor)\n",
    "loss = criterion(output,target)\n",
    "loss.backward() #compute gradietns\n",
    "\n",
    "print(\"Gradients before zero_grad():\")\n",
    "for name, param in model.named_parameters():\n",
    "    print(f\"{name}: {param.grad}\")\n",
    "\n",
    "# Reset gradients using zero_grad()\n",
    "model.zero_grad(set_to_none=True)\n",
    "print(\"\\nGradients after zero_grad():\")\n",
    "for name, param in model.named_parameters():\n",
    "    print(f\"{name}: {param.grad}\")\n",
    "\n",
    "# Perform another training step\n",
    "print(\"\\nSecond Training Step:\")\n",
    "output = model(input_tensor)\n",
    "loss = criterion(output, target)\n",
    "loss.backward()  # Compute gradients again\n",
    "print(\"Gradients after second backward():\")\n",
    "for name, param in model.named_parameters():\n",
    "    print(f\"{name}: {param.grad}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
