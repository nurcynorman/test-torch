{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "use of some DRL algorithm (PPO) to solve the classif CartPole-V1 problem in Gym.\n",
    "\n",
    "buildings blocks may include\n",
    "* batch\n",
    "* replay buffer\n",
    "* vectorized environment wrapper\n",
    "* data collector\n",
    "* trainer\n",
    "* logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2mResolved \u001b[1m51 packages\u001b[0m \u001b[2min 886ms\u001b[0m\u001b[0m\n",
      "\u001b[2mPrepared \u001b[1m6 packages\u001b[0m \u001b[2min 4.61s\u001b[0m\u001b[0m\n",
      "\u001b[2mUninstalled \u001b[1m1 package\u001b[0m \u001b[2min 5ms\u001b[0m\u001b[0m\n",
      "\u001b[2mInstalled \u001b[1m42 packages\u001b[0m \u001b[2min 6.02s\u001b[0m\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mabsl-py\u001b[0m\u001b[2m==2.2.2\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mcloudpickle\u001b[0m\u001b[2m==3.1.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mcontourpy\u001b[0m\u001b[2m==1.3.2\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mcycler\u001b[0m\u001b[2m==0.12.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mdeepdiff\u001b[0m\u001b[2m==7.0.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mdistlib\u001b[0m\u001b[2m==0.3.9\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mfarama-notifications\u001b[0m\u001b[2m==0.0.4\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mfilelock\u001b[0m\u001b[2m==3.18.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mfonttools\u001b[0m\u001b[2m==4.57.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mfsspec\u001b[0m\u001b[2m==2025.3.2\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mgrpcio\u001b[0m\u001b[2m==1.71.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mgym\u001b[0m\u001b[2m==0.26.2\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mgym-notices\u001b[0m\u001b[2m==0.0.8\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mgymnasium\u001b[0m\u001b[2m==0.28.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mh5py\u001b[0m\u001b[2m==3.13.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mjax-jumpy\u001b[0m\u001b[2m==1.0.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mkiwisolver\u001b[0m\u001b[2m==1.4.8\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mllvmlite\u001b[0m\u001b[2m==0.44.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mmarkdown\u001b[0m\u001b[2m==3.8\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mmatplotlib\u001b[0m\u001b[2m==3.10.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mmpmath\u001b[0m\u001b[2m==1.3.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mnetworkx\u001b[0m\u001b[2m==3.4.2\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mnumba\u001b[0m\u001b[2m==0.61.2\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mnumpy\u001b[0m\u001b[2m==1.26.4\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mordered-set\u001b[0m\u001b[2m==4.1.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpandas\u001b[0m\u001b[2m==2.2.3\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpettingzoo\u001b[0m\u001b[2m==1.24.3\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpillow\u001b[0m\u001b[2m==11.2.1\u001b[0m\n",
      " \u001b[31m-\u001b[39m \u001b[1mplatformdirs\u001b[0m\u001b[2m==4.3.7\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mplatformdirs\u001b[0m\u001b[2m==2.6.2\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mprotobuf\u001b[0m\u001b[2m==6.30.2\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpyparsing\u001b[0m\u001b[2m==3.2.3\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpytz\u001b[0m\u001b[2m==2025.2\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1msensai-utils\u001b[0m\u001b[2m==1.4.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1msympy\u001b[0m\u001b[2m==1.13.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mtensorboard\u001b[0m\u001b[2m==2.19.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mtensorboard-data-server\u001b[0m\u001b[2m==0.7.2\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mtianshou\u001b[0m\u001b[2m==1.1.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mtorch\u001b[0m\u001b[2m==2.6.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mtqdm\u001b[0m\u001b[2m==4.67.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mtzdata\u001b[0m\u001b[2m==2025.2\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mvirtualenv\u001b[0m\u001b[2m==20.16.3\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mwerkzeug\u001b[0m\u001b[2m==3.1.3\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!uv pip install tianshou gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "import gymnasium as gym\n",
    "import torch\n",
    "\n",
    "from tianshou.data import Collector, VectorReplayBuffer\n",
    "from tianshou.env import DummyVectorEnv\n",
    "from tianshou.policy import PPOPolicy\n",
    "from tianshou.trainer import OnpolicyTrainer\n",
    "from tianshou.utils.net.common import ActorCritic, Net\n",
    "from tianshou.utils.net.discrete import Actor, Critic\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #1: 50001it [00:17, 2910.45it/s, env_step=50000, gradient_step=200, len=118, n/ep=23, n/st=2000, rew=118.13]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #1: test_reward: 171.200000 ± 107.831164, best_reward: 171.200000 ± 107.831164 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #2: 50001it [00:16, 3012.57it/s, env_step=100000, gradient_step=400, len=96, n/ep=8, n/st=2000, rew=96.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #2: test_reward: 212.200000 ± 141.184843, best_reward: 212.200000 ± 141.184843 in #2\n"
     ]
    }
   ],
   "source": [
    "#environements\n",
    "env = gym.make(\"CartPole-v1\")\n",
    "train_envs = DummyVectorEnv([lambda: gym.make(\"CartPole-v1\") for _ in range(20)])\n",
    "test_envs = DummyVectorEnv([lambda: gym.make ('CartPole-v1') for _ in range(10)])\n",
    "\n",
    "# model & optimizer\n",
    "assert env.observation_space.shape is not None #for mypy\n",
    "net = Net(state_shape=env.observation_space.shape, hidden_sizes=[64,64], device=device)\n",
    "\n",
    "assert isinstance(env.action_space, gym.spaces.Discrete) #for mypy\n",
    "\n",
    "actor = Actor(preprocess_net = net, action_shape = env.action_space.n, device=device).to(device)\n",
    "\n",
    "critic = Critic(preprocess_net = net, device = device).to(device)\n",
    "\n",
    "actor_critic = ActorCritic(actor,critic)\n",
    "\n",
    "optim = torch.optim.Adam(actor_critic.parameters(), lr=0.0003)\n",
    "\n",
    "\n",
    "# PPO Policy\n",
    "dist = torch.distributions.Categorical\n",
    "policy: PPOPolicy = PPOPolicy(\n",
    "    actor=actor,\n",
    "    critic=critic,\n",
    "    optim=optim,\n",
    "    dist_fn=dist,\n",
    "    action_space=env.action_space,\n",
    "    action_scaling=False,\n",
    ")\n",
    "\n",
    "#collectior\n",
    "train_collector = Collector(policy, train_envs, VectorReplayBuffer(20000, len(train_envs)))\n",
    "test_collector = Collector(policy, test_envs)\n",
    "\n",
    "#trainer\n",
    "train_result = OnpolicyTrainer(\n",
    "    policy=policy,\n",
    "    batch_size=256,\n",
    "    train_collector=train_collector,\n",
    "    test_collector=test_collector,\n",
    "    max_epoch=10,\n",
    "    step_per_epoch=50000,\n",
    "    repeat_per_collect=10,\n",
    "    episode_per_test=10,\n",
    "    step_per_collect=2000,\n",
    "    stop_fn=lambda mean_reward: mean_reward >=195,\n",
    ").run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "InfoStats\n",
      "----------------------------------------\n",
      "{   'best_reward': 212.2,\n",
      "    'best_reward_std': 141.1848433791673,\n",
      "    'gradient_step': 400,\n",
      "    'test_episode': 30,\n",
      "    'test_step': 4029,\n",
      "    'timing': {   'test_time': 1.4898450374603271,\n",
      "                  'total_time': 35.28361105918884,\n",
      "                  'train_time': 33.793766021728516,\n",
      "                  'train_time_collect': 18.464709043502808,\n",
      "                  'train_time_update': 15.129051923751831,\n",
      "                  'update_speed': 2959.1256545867836},\n",
      "    'train_episode': 1425,\n",
      "    'train_step': 100000}\n"
     ]
    }
   ],
   "source": [
    "train_result.pprint_asdict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fadzw\\AppData\\Local\\uv\\cache\\archive-v0\\fZCJEF4f_-K2gvbxLFiaM\\Lib\\site-packages\\tianshou\\data\\collector.py:328: UserWarning: n_episode=3 should be larger than self.env_num=10 to collect at least one trajectory in each environment.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final reward: 332.3333333333333, length: 332.3333333333333\n"
     ]
    }
   ],
   "source": [
    "#performance\n",
    "policy.eval()\n",
    "eval_result = test_collector.collect(n_episode=3, render=False)\n",
    "print(f\"Final reward: {eval_result.returns.mean()}, length: {eval_result.lens.mean()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# batch\n",
    "\n",
    "* batch, the most basic data structure in tianshou\n",
    "* like a numpy version of python dictionary , similar to pytorch tensordict but with different type structure\n",
    "* in DRL you need to handle a lof of dictionary-format data. most algorithm would require to store state, action and reward data for every step when interacting with the environment.\n",
    "* all of them can be organized as dictionary and batch class helps in unifying terface of a diverse set of algorithms\n",
    "* batch support advanced indexing concatenation and splitting formatting print just like any other numpy array, which proved to be helpful for developers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================\n",
      "Batch(\n",
      "    a: array([4, 4]),\n",
      "    b: array([5, 5]),\n",
      ")\n",
      "========================================\n",
      "Batch(\n",
      "    a: array([4, 4]),\n",
      "    b: array([5, 5]),\n",
      ")\n",
      "========================================\n",
      "Batch(\n",
      "    action: array([1., 2., 3.]),\n",
      "    reward: array(3.66),\n",
      "    obs: Batch(\n",
      "             rgb_obs: array([[0., 0., 0.],\n",
      "                             [0., 0., 0.],\n",
      "                             [0., 0., 0.]]),\n",
      "             flatten_obs: array([1., 1., 1., 1., 1.]),\n",
      "         ),\n",
      "    extra: 'extra_string',\n",
      ")\n",
      "<class 'tianshou.data.batch.Batch'>\n",
      "[[0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]]\n",
      "========================================\n",
      "Batch(\n",
      "    obs: Batch(\n",
      "             flatten_obs: array([[1., 1., 1., 1., 1.],\n",
      "                                 [1., 1., 1., 1., 1.],\n",
      "                                 [1., 1., 1., 1., 1.]]),\n",
      "             rgb_obs: array([[[0., 0., 0.],\n",
      "                              [0., 0., 0.],\n",
      "                              [0., 0., 0.]],\n",
      "                      \n",
      "                             [[0., 0., 0.],\n",
      "                              [0., 0., 0.],\n",
      "                              [0., 0., 0.]],\n",
      "                      \n",
      "                             [[0., 0., 0.],\n",
      "                              [0., 0., 0.],\n",
      "                              [0., 0., 0.]]]),\n",
      "         ),\n",
      "    action: array([[1., 2., 3.],\n",
      "                   [1., 2., 3.],\n",
      "                   [1., 2., 3.]]),\n",
      "    reward: array([3.66, 3.66, 3.66]),\n",
      ")\n",
      "(3, 3, 3)\n"
     ]
    }
   ],
   "source": [
    "# %%capture\n",
    "\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from tianshou.data import Batch\n",
    "\n",
    "# converted from a python library\n",
    "print(\"========================================\")\n",
    "batch1 = Batch({\"a\": [4, 4], \"b\": (5, 5)})\n",
    "print(batch1)\n",
    "\n",
    "# initialization of batch2 is equivalent to batch1\n",
    "print(\"========================================\")\n",
    "batch2 = Batch(a=[4, 4], b=(5, 5))\n",
    "print(batch2)\n",
    "\n",
    "# the dictionary can be nested, and it will be turned into a nested Batch\n",
    "print(\"========================================\")\n",
    "data = {\n",
    "    \"action\": np.array([1.0, 2.0, 3.0]),\n",
    "    \"reward\": 3.66,\n",
    "    \"obs\": {\n",
    "        \"rgb_obs\": np.zeros((3, 3)),\n",
    "        \"flatten_obs\": np.ones(5),\n",
    "    },\n",
    "}\n",
    "\n",
    "batch3 = Batch(data, extra=\"extra_string\")\n",
    "print(batch3)\n",
    "# batch3.obs is also a Batch\n",
    "print(type(batch3.obs))\n",
    "print(batch3.obs.rgb_obs)\n",
    "\n",
    "# a list of dictionary/Batch will automatically be concatenated/stacked, providing convenience if you\n",
    "# want to use parallelized environments to collect data.\n",
    "print(\"========================================\")\n",
    "batch4 = Batch([data] * 3)\n",
    "print(batch4)\n",
    "print(batch4.obs.rgb_obs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch(\n",
      "    a: array([4, 4]),\n",
      "    b: array([5, 5]),\n",
      ")\n",
      "========================================\n",
      "Batch(\n",
      "    b: array([5, 5]),\n",
      "    c: Batch(\n",
      "           c1: array([0, 1, 2]),\n",
      "           c2: array(False),\n",
      "       ),\n",
      ")\n",
      "========================================\n",
      "True\n",
      "========================================\n",
      "b: [5 5]\n",
      "c: Batch(\n",
      "    c1: array([0, 1, 2]),\n",
      "    c2: array(False),\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# getting access to data\n",
    "# search or change key-value pair in a batch just as if dictionary\n",
    "\n",
    "batch1 = Batch({\"a\": [4, 4], \"b\": (5, 5)})\n",
    "print(batch1)\n",
    "\n",
    "# add or delete key-value pair in batch1\n",
    "print(\"========================================\")\n",
    "batch1.c = Batch(c1=np.arange(3), c2=False)\n",
    "del batch1.a\n",
    "print(batch1)\n",
    "\n",
    "# access value by key\n",
    "print(\"========================================\")\n",
    "assert batch1[\"c\"] is batch1.c\n",
    "print(\"c\" in batch1)\n",
    "\n",
    "# traverse the Batch\n",
    "print(\"========================================\")\n",
    "for key, value in batch1.items():\n",
    "    print(str(key) + \": \" + str(value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch(\n",
      "    obs: array([[[1., 1., 1.],\n",
      "                 [1., 1., 1.],\n",
      "                 [1., 1., 1.]],\n",
      "         \n",
      "                [[1., 1., 1.],\n",
      "                 [1., 1., 1.],\n",
      "                 [1., 1., 1.]],\n",
      "         \n",
      "                [[1., 1., 1.],\n",
      "                 [1., 1., 1.],\n",
      "                 [1., 1., 1.]],\n",
      "         \n",
      "                [[1., 1., 1.],\n",
      "                 [1., 1., 1.],\n",
      "                 [1., 1., 1.]]]),\n",
      "    info: Batch(\n",
      "              done: array([1, 1, 0, 1]),\n",
      "              failed: array([False, False, False, False]),\n",
      "          ),\n",
      "    act: array([2, 5, 0, 4]),\n",
      "    rew: array([0., 0., 0., 0.]),\n",
      "    truncated: array([False, False, False, False]),\n",
      "    terminated: array([False, False, False, False]),\n",
      ")\n",
      "[4]\n",
      "========================================\n",
      "Batch(\n",
      "    obs: array([[1., 1., 1.],\n",
      "                [1., 1., 1.],\n",
      "                [1., 1., 1.]]),\n",
      "    info: Batch(\n",
      "              done: 1,\n",
      "              failed: False,\n",
      "          ),\n",
      "    act: 2,\n",
      "    rew: 0.0,\n",
      "    truncated: False,\n",
      "    terminated: False,\n",
      ")\n",
      "Batch(\n",
      "    obs: array([[[1., 1., 1.],\n",
      "                 [1., 1., 1.],\n",
      "                 [1., 1., 1.]],\n",
      "         \n",
      "                [[1., 1., 1.],\n",
      "                 [1., 1., 1.],\n",
      "                 [1., 1., 1.]]]),\n",
      "    info: Batch(\n",
      "              done: array([1, 1]),\n",
      "              failed: array([False, False]),\n",
      "          ),\n",
      "    act: array([2, 4]),\n",
      "    rew: array([0., 0.]),\n",
      "    truncated: array([False, False]),\n",
      "    terminated: array([False, False]),\n",
      ")\n",
      "========================================\n",
      "Batch(\n",
      "    obs: array([[[1., 1., 1.],\n",
      "                 [1., 1., 1.],\n",
      "                 [1., 1., 1.]],\n",
      "         \n",
      "                [[1., 1., 1.],\n",
      "                 [1., 1., 1.],\n",
      "                 [1., 1., 1.]]]),\n",
      "    info: Batch(\n",
      "              done: array([0, 1]),\n",
      "              failed: array([False, False]),\n",
      "          ),\n",
      "    act: array([0, 4]),\n",
      "    rew: array([0., 0.]),\n",
      "    truncated: array([False, False]),\n",
      "    terminated: array([False, False]),\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "#indexing and slicing\n",
    "# if batch share same shape in certain dimesnsion , can support arary-like indexing and sclicing\n",
    "\n",
    "# Let us suppose we have collected the data from stepping from 4 environments\n",
    "step_outputs = [\n",
    "    {\n",
    "        \"act\": np.random.randint(10),\n",
    "        \"rew\": 0.0,\n",
    "        \"obs\": np.ones((3, 3)),\n",
    "        \"info\": {\"done\": np.random.choice(2), \"failed\": False},\n",
    "        \"terminated\": False,\n",
    "        \"truncated\": False,\n",
    "    }\n",
    "    for _ in range(4)\n",
    "]\n",
    "batch = Batch(step_outputs)\n",
    "print(batch)\n",
    "print(batch.shape)\n",
    "\n",
    "# advanced indexing is supported, if we only want to select data in a given set of environments\n",
    "print(\"========================================\")\n",
    "print(batch[0])\n",
    "print(batch[[0, 3]])\n",
    "\n",
    "# slicing is also supported\n",
    "print(\"========================================\")\n",
    "print(batch[-2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================\n",
      "Batch(\n",
      "    a: Batch(\n",
      "           d: Batch(\n",
      "                  e: array([3.]),\n",
      "              ),\n",
      "           b: array([1.]),\n",
      "       ),\n",
      ")\n",
      "Batch(\n",
      "    a: Batch(\n",
      "           d: Batch(\n",
      "                  e: array([6.]),\n",
      "              ),\n",
      "           b: array([4.]),\n",
      "       ),\n",
      ")\n",
      "Batch(\n",
      "    a: Batch(\n",
      "           d: Batch(\n",
      "                  e: array([3., 6.]),\n",
      "              ),\n",
      "           b: array([1., 4.]),\n",
      "       ),\n",
      ")\n",
      "========================================\n",
      "Batch(\n",
      "    a: array([[0., 0.],\n",
      "              [0., 0.],\n",
      "              [0., 0.]]),\n",
      "    b: array([[1., 1., 1.],\n",
      "              [1., 1., 1.]]),\n",
      "    c: Batch(\n",
      "           d: array([[1],\n",
      "                     [2]]),\n",
      "       ),\n",
      ")\n",
      "Batch(\n",
      "    a: array([[1., 1.],\n",
      "              [1., 1.],\n",
      "              [1., 1.]]),\n",
      "    b: array([[1., 1., 1.],\n",
      "              [1., 1., 1.]]),\n",
      "    c: Batch(\n",
      "           d: array([[0],\n",
      "                     [3]]),\n",
      "       ),\n",
      ")\n",
      "Batch(\n",
      "    c: Batch(\n",
      "           d: array([[[1],\n",
      "                      [0]],\n",
      "              \n",
      "                     [[2],\n",
      "                      [3]]]),\n",
      "       ),\n",
      "    b: array([[[1., 1., 1.],\n",
      "               [1., 1., 1.]],\n",
      "       \n",
      "              [[1., 1., 1.],\n",
      "               [1., 1., 1.]]]),\n",
      "    a: array([[[0., 0.],\n",
      "               [1., 1.]],\n",
      "       \n",
      "              [[0., 0.],\n",
      "               [1., 1.]],\n",
      "       \n",
      "              [[0., 0.],\n",
      "               [1., 1.]]]),\n",
      ")\n",
      "========================================\n",
      "<class 'generator'>\n",
      "[Batch(\n",
      "    c: Batch(\n",
      "           d: array([[[1],\n",
      "                      [0]]]),\n",
      "       ),\n",
      "    b: array([[[1., 1., 1.],\n",
      "               [1., 1., 1.]]]),\n",
      "    a: array([[[0., 0.],\n",
      "               [1., 1.]]]),\n",
      "), Batch(\n",
      "    c: Batch(\n",
      "           d: array([[[2],\n",
      "                      [3]]]),\n",
      "       ),\n",
      "    b: array([[[1., 1., 1.],\n",
      "               [1., 1., 1.]]]),\n",
      "    a: array([[[0., 0.],\n",
      "               [1., 1.]]]),\n",
      ")]\n"
     ]
    }
   ],
   "source": [
    "# aggregation and splitting\n",
    "# concat batches with compatible keys\n",
    "# try incompatible keys yourself if you feel curious\n",
    "print(\"========================================\")\n",
    "b1 = Batch(a=[{\"b\": np.float64(1.0), \"d\": Batch(e=np.array(3.0))}])\n",
    "b2 = Batch(a=[{\"b\": np.float64(4.0), \"d\": {\"e\": np.array(6.0)}}])\n",
    "b12_cat_out = Batch.cat([b1, b2])\n",
    "print(b1)\n",
    "print(b2)\n",
    "print(b12_cat_out)\n",
    "\n",
    "# stack batches with compatible keys\n",
    "# try incompatible keys yourself if you feel curious\n",
    "print(\"========================================\")\n",
    "b3 = Batch(a=np.zeros((3, 2)), b=np.ones((2, 3)), c=Batch(d=[[1], [2]]))\n",
    "b4 = Batch(a=np.ones((3, 2)), b=np.ones((2, 3)), c=Batch(d=[[0], [3]]))\n",
    "b34_stack = Batch.stack((b3, b4), axis=1)\n",
    "print(b3)\n",
    "print(b4)\n",
    "print(b34_stack)\n",
    "\n",
    "# split the batch into small batches of size 1, breaking the order of the data\n",
    "print(\"========================================\")\n",
    "print(type(b34_stack.split(1)))\n",
    "print(list(b34_stack.split(1, shuffle=True)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch(\n",
      "    b: tensor([[0., 0.],\n",
      "               [0., 0.],\n",
      "               [1., 1.],\n",
      "               [1., 1.],\n",
      "               [0., 0.],\n",
      "               [0., 0.]]),\n",
      "    a: array([0, 1, 0, 1, 0, 1]),\n",
      ")\n",
      "Batch(\n",
      "    b: array([[0., 0.],\n",
      "              [0., 0.],\n",
      "              [1., 1.],\n",
      "              [1., 1.],\n",
      "              [0., 0.],\n",
      "              [0., 0.]], dtype=float32),\n",
      "    a: array([0, 1, 0, 1, 0, 1]),\n",
      ")\n",
      "Batch(\n",
      "    b: tensor([[0., 0.],\n",
      "               [0., 0.],\n",
      "               [1., 1.],\n",
      "               [1., 1.],\n",
      "               [0., 0.],\n",
      "               [0., 0.]]),\n",
      "    a: tensor([0, 1, 0, 1, 0, 1], dtype=torch.int32),\n",
      ")\n",
      "Batch(\n",
      "    obs: Batch(\n",
      "             a: array(0.),\n",
      "             c: tensor([1., 2.]),\n",
      "         ),\n",
      "    np: array([[0., 0., 0., 0.],\n",
      "               [0., 0., 0., 0.],\n",
      "               [0., 0., 0., 0.]]),\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# batch actually supports torch tensor. usages exactly the same\n",
    "batch1 = Batch(a=np.arange(2), b=torch.zeros((2, 2)))\n",
    "batch2 = Batch(a=np.arange(2), b=torch.ones((2, 2)))\n",
    "batch_cat = Batch.cat([batch1, batch2, batch1])\n",
    "print(batch_cat)\n",
    "\n",
    "# can convert the data type easily if you no longer want to use hybrid data type anymore\n",
    "batch_cat.to_numpy_()\n",
    "print(batch_cat)\n",
    "batch_cat.to_torch_()\n",
    "print(batch_cat)\n",
    "# batch is serializable , if need to save disk or restore it\n",
    "batch = Batch(obs=Batch(a=0.0,c=torch.tensor([1.0,2.0])), np=np.zeros([3,4]))\n",
    "batch_pk = pickle.loads(pickle.dumps(batch))\n",
    "print(batch_pk)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
