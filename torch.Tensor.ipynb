{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32-bit floating point (torch.float32): tensor([1., 2., 3.])\n",
      "64-bit floating point (torch.float64): tensor([1., 2., 3.], dtype=torch.float64)\n",
      "16-bit floating point (torch.float16): tensor([1., 2., 3.], dtype=torch.float16)\n",
      "16-bit brain floating point (torch.bfloat16): tensor([1., 2., 3.], dtype=torch.bfloat16)\n",
      "32-bit complex (torch.complex32): tensor([1.+2.j, 3.+4.j], dtype=torch.complex32)\n",
      "64-bit complex (torch.complex64): tensor([1.+2.j, 3.+4.j])\n",
      "128-bit complex (torch.complex128): tensor([1.+2.j, 3.+4.j], dtype=torch.complex128)\n",
      "8-bit integer (unsigned) (torch.uint8): tensor([1, 2, 3], dtype=torch.uint8)\n",
      "16-bit integer (signed) (torch.int16): tensor([1, 2, 3], dtype=torch.uint16)\n",
      "32-bit integer (signed) (torch.int32): tensor([1, 2, 3], dtype=torch.uint32)\n",
      "64-bit integer (signed) (torch.int64): tensor([1, 2, 3], dtype=torch.uint64)\n",
      "8-bit integer (signed) (torch.int8): tensor([1, 2, 3], dtype=torch.int8)\n",
      "16-bit integer (signed) (torch.int16): tensor([1, 2, 3], dtype=torch.int16)\n",
      "32-bit integer (signed) (torch.int32): tensor([1, 2, 3], dtype=torch.int32)\n",
      "64-bit integer (signed) (torch.int64): tensor([1, 2, 3])\n",
      "Boolean (torch.bool): tensor([ True, False,  True])\n",
      "Quantized 8-bit integer (unsigned) (torch.quint8): tensor([1., 2., 3.], size=(3,), dtype=torch.quint8,\n",
      "       quantization_scheme=torch.per_tensor_affine, scale=1.0, zero_point=0)\n",
      "Quantized 8-bit integer (signed) (torch.qint8): tensor([1., 2., 3.], size=(3,), dtype=torch.qint8,\n",
      "       quantization_scheme=torch.per_tensor_affine, scale=1.0, zero_point=0)\n",
      "Quantized 32-bit integer (signed) (torch.qint32): tensor([1., 2., 3.], size=(3,), dtype=torch.qint32,\n",
      "       quantization_scheme=torch.per_tensor_affine, scale=1.0, zero_point=0)\n",
      "Quantized 4-bit integer (unsigned) (torch.quint4x2): tensor([1., 2., 3.], size=(3,), dtype=torch.quint4x2,\n",
      "       quantization_scheme=torch.per_tensor_affine, scale=1.0, zero_point=0)\n",
      "8-bit floating point, e5m2 (torch.float8_e5m2): tensor([1., 2., 3.], dtype=torch.float8_e5m2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fadzw\\AppData\\Local\\Temp\\ipykernel_18756\\2747244299.py:7: UserWarning: ComplexHalf support is experimental and many operators don't support it yet. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\EmptyTensor.cpp:51.)\n",
      "  complex32_tensor = torch.tensor([1 + 2j, 3 + 4j], dtype=torch.complex32)\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "\n",
    "float32_tensor = torch.tensor([1.0,2.0,3.0], dtype=torch.float32)\n",
    "float64_tensor = torch.tensor([1.0,2.0,3.0], dtype=torch.float64)\n",
    "float16_tensor = torch.tensor([1.0,2.0,3.0],dtype=torch.float16)\n",
    "bfloat16_tensor = torch.tensor([1.0,2.0,3.0], dtype=torch.bfloat16)\n",
    "complex32_tensor = torch.tensor([1 + 2j, 3 + 4j], dtype=torch.complex32)\n",
    "complex64_tensor = torch.tensor([1 + 2j, 3 + 4j], dtype= torch.complex64)\n",
    "complex128_tensor = torch.tensor([1 + 2j, 3 + 4j], dtype= torch.complex128)\n",
    "uint8_tensor = torch.tensor([1,2,3],dtype=torch.uint8)\n",
    "uint16_tensor = torch.tensor([1,2,3], dtype=torch.uint16)\n",
    "uint32_tensor = torch.tensor([1,2,3], dtype=torch.uint32)\n",
    "uint64_tensor = torch.tensor([1,2,3], dtype=torch.uint64)\n",
    "int8_tensor = torch.tensor([1,2,3],dtype=torch.int8)\n",
    "int16_tensor = torch.tensor([1,2,3], dtype=torch.int16)\n",
    "int32_tensor = torch.tensor([1,2,3], dtype=torch.int32)\n",
    "int64_tensor = torch.tensor([1,2,3], dtype=torch.int64)\n",
    "bool_tensor = torch.tensor([True, False , True], dtype=torch.bool)\n",
    "quint8_tensor = torch.quantize_per_tensor(torch.tensor([1.0,2.0,3.0]), scale=1.0, zero_point=0, dtype=torch.quint8)\n",
    "qint8_tensor = torch.quantize_per_tensor(torch.tensor([1.0,2.0,3.0]), scale=1.0, zero_point=0, dtype=torch.qint8)\n",
    "qint32_tensor = torch.quantize_per_tensor(torch.tensor([1.0,2.0,3.0]), scale=1.0, zero_point=0, dtype=torch.qint32)\n",
    "quint4x2_tensor = torch.quantize_per_tensor(torch.tensor([1.0,2.0,3.0]), scale=1.0, zero_point=0, dtype= torch.quint4x2)\n",
    "\n",
    "# if hasattr(torch, 'float8_e4m3fn'):\n",
    "    # float8_e43fn_tensor = torch.tensor([1.0,2.0,3.0], dtype=torch.float8_e43fn)\n",
    "if hasattr(torch, 'float8_e5m2'):\n",
    "    float8_e5m2_tensor = torch.tensor([1.0,2.0,3.0], dtype=torch.float8_e5m2)\n",
    "\n",
    "\n",
    "print(\"32-bit floating point (torch.float32):\", float32_tensor)\n",
    "print(\"64-bit floating point (torch.float64):\", float64_tensor)\n",
    "print(\"16-bit floating point (torch.float16):\", float16_tensor)\n",
    "print(\"16-bit brain floating point (torch.bfloat16):\", bfloat16_tensor)\n",
    "print(\"32-bit complex (torch.complex32):\", complex32_tensor)\n",
    "print(\"64-bit complex (torch.complex64):\", complex64_tensor)\n",
    "print(\"128-bit complex (torch.complex128):\", complex128_tensor)\n",
    "print(\"8-bit integer (unsigned) (torch.uint8):\", uint8_tensor)\n",
    "print(\"16-bit integer (signed) (torch.int16):\", uint16_tensor)\n",
    "print(\"32-bit integer (signed) (torch.int32):\", uint32_tensor)\n",
    "print(\"64-bit integer (signed) (torch.int64):\", uint64_tensor)\n",
    "print(\"8-bit integer (signed) (torch.int8):\", int8_tensor)\n",
    "print(\"16-bit integer (signed) (torch.int16):\", int16_tensor)\n",
    "print(\"32-bit integer (signed) (torch.int32):\", int32_tensor)\n",
    "print(\"64-bit integer (signed) (torch.int64):\", int64_tensor)\n",
    "print(\"Boolean (torch.bool):\", bool_tensor)\n",
    "print(\"Quantized 8-bit integer (unsigned) (torch.quint8):\", quint8_tensor)\n",
    "print(\"Quantized 8-bit integer (signed) (torch.qint8):\", qint8_tensor)\n",
    "print(\"Quantized 32-bit integer (signed) (torch.qint32):\", qint32_tensor)\n",
    "print(\"Quantized 4-bit integer (unsigned) (torch.quint4x2):\", quint4x2_tensor)\n",
    "print(\"8-bit floating point, e5m2 (torch.float8_e5m2):\", float8_e5m2_tensor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base tensor: tensor([1, 1], dtype=torch.int8)\n",
      "\n",
      "new tensor (default): tensor([[0, 1],\n",
      "        [2, 3]], dtype=torch.int8)\n",
      "\n",
      "new tensor (dtype=torch.float32): tensor([[0., 1.],\n",
      "        [2., 3.]])\n",
      "\n",
      "cuda is not available. skipping GPU example\n",
      "\n",
      " new tensor (requires_grad)=True: tensor([[0., 1.],\n",
      "        [2., 3.]], requires_grad=True)\n",
      "Gradient of New Tensor: tensor([[1., 1.],\n",
      "        [1., 1.]])\n",
      "\n",
      "Sparse Tensor (layout=torch.sparse_coo): tensor(indices=tensor([[0, 1],\n",
      "                       [1, 0]]),\n",
      "       values=tensor([3., 4.]),\n",
      "       size=(2, 2), nnz=2, layout=torch.sparse_coo)\n"
     ]
    }
   ],
   "source": [
    "#Tensor.new_tensor\n",
    "\n",
    "import torch \n",
    "\n",
    "base_tensor = torch.ones((2,), dtype=torch.int8)\n",
    "print('base tensor:',base_tensor)\n",
    "\n",
    "data = [[0,1],[2,3]]\n",
    "#same dtype and device as the base tensor\n",
    "new_tensor_default = base_tensor.new_tensor(data)\n",
    "print('\\nnew tensor (default):', new_tensor_default)\n",
    "\n",
    "#specify a different dtype\n",
    "new_tensor_float32 = base_tensor.new_tensor(data,dtype=torch.float32)\n",
    "print('\\nnew tensor (dtype=torch.float32):',new_tensor_float32)\n",
    "\n",
    "#specify a different device\n",
    "if torch.cuda.is_available():\n",
    "    new_tensr_cuda = base_tensor.new_tensor(data, device='cuda')\n",
    "    print('\\n new tensor (device=cuda):',new_tensor_cuda)\n",
    "else:\n",
    "    print('\\ncuda is not available. skipping GPU example')\n",
    "\n",
    "\n",
    "#specify requier_grad=True for autograd tracking\n",
    "new_tensor_requires_grad = base_tensor.new_tensor(data,dtype=torch.float32, requires_grad=True)\n",
    "print('\\n new tensor (requires_grad)=True:',new_tensor_requires_grad)\n",
    "\n",
    "#perform a dummy operation to demonstrate autograd\n",
    "output = new_tensor_requires_grad.sum()\n",
    "output.backward()\n",
    "print('Gradient of New Tensor:',new_tensor_requires_grad.grad)\n",
    "\n",
    "#specify layout (default is torch.strided)\n",
    "# new_tensor_strided = base_tensor.new_tensor(data, layout=torch.strided)\n",
    "# print('\\n new tensor (layout=torch.strided):',new_tensor_strided)\n",
    "\n",
    "#specify pin_memory=True (only works for CPU tensors)\n",
    "# new_tensor_pinned = base_tensor.new_tensor(data, pin_memory=True)\n",
    "# print('\\n new tensor (pin_memory=True):',new_tensor_pinned)\n",
    "\n",
    "# Alternative for pin_memory=True (only works for CPU tensors)\n",
    "# pinned_tensor = torch.tensor(data, dtype=torch.int8).pin_memory() #RuntimeError: Cannot access accelerator device when none is available.\n",
    "# print(\"\\nPinned Tensor (pin_memory=True):\", pinned_tensor)\n",
    "\n",
    "\n",
    "# Alternative for sparse layout\n",
    "indices = torch.tensor([[0, 1], [1, 0]])\n",
    "values = torch.tensor([3, 4], dtype=torch.float32)\n",
    "sparse_tensor = torch.sparse_coo_tensor(indices, values, size=(2, 2))\n",
    "print(\"\\nSparse Tensor (layout=torch.sparse_coo):\", sparse_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original tensor:\n",
      "tensor([1., 1.], dtype=torch.float64)\n",
      "dtype: torch.float64\n",
      "device cpu\n",
      "\n",
      " new tensor (inherits dtype and device from original)\n",
      "tensor([[3.1416, 3.1416, 3.1416, 3.1416],\n",
      "        [3.1416, 3.1416, 3.1416, 3.1416],\n",
      "        [3.1416, 3.1416, 3.1416, 3.1416]], dtype=torch.float64)\n",
      "dtype: torch.float64\n",
      "device: cpu\n",
      "\n",
      "CUDA is not available. Skipping GPU tensor creation.\n"
     ]
    }
   ],
   "source": [
    "#Tensor.new_full\n",
    "\n",
    "# creates a tensor for a spcified size filled with a given value and inherits properties like dtype and devvice from the original tensor unless overridden\n",
    "\n",
    "import torch \n",
    "\n",
    "tensor = torch.ones((2,), dtype=torch.float64)\n",
    "\n",
    "print('original tensor:')\n",
    "print(tensor)\n",
    "print('dtype:',tensor.dtype)\n",
    "print('device',tensor.device)\n",
    "\n",
    "#create a new tensor for size 3 4 filled with 3.141592\n",
    "new_tensor = tensor.new_full((3,4),3.141592)\n",
    "\n",
    "print('\\n new tensor (inherits dtype and device from original)')\n",
    "print(new_tensor)\n",
    "print('dtype:',new_tensor.dtype)\n",
    "print('device:',new_tensor.device)\n",
    "\n",
    "#create a new tensor on a different device and dtype\n",
    "if torch.cuda.is_available():\n",
    "    new_tensor_gpu = tensor.new_full(\n",
    "        size=(2,3),\n",
    "        fill_value=2.718,\n",
    "        dtype=torch.float32,\n",
    "        device='cuda'\n",
    "    )\n",
    "    print('\\nenw tensor on GPU with dtype = torch.float32')\n",
    "    print(new_tensor_gpu)\n",
    "    print('dtype:',new_tensor_gpu.dtype)\n",
    "    print('device:',new_tensor_gpu.device)\n",
    "else:\n",
    "    print('\\nCUDA is not available. Skipping GPU tensor creation.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original tensor:\n",
      "tensor([1., 1.], dtype=torch.float64)\n",
      "dtype: torch.float64\n",
      "device: cpu\n",
      "\n",
      " new empty tensor (inherits dtype and device from original):\n",
      "tensor([[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]], dtype=torch.float64)\n",
      "dtype: torch.float64\n",
      "device: cpu\n",
      "\n",
      "CUDA is not available . Skipping GPU tensor creation\n"
     ]
    }
   ],
   "source": [
    "#Tensor.new_empty\n",
    "\n",
    "# creates a new tensor of a specified size, filled with uninitialized data. \n",
    "# the new tensor inherits properties like dtype and device from the original tensor unless overridden\n",
    "\n",
    "import torch \n",
    "\n",
    "tensor = torch.ones((2,),dtype=torch.float64)\n",
    "\n",
    "print('original tensor:')\n",
    "print(tensor)\n",
    "print('dtype:',tensor.dtype)\n",
    "print('device:', tensor.device)\n",
    "\n",
    "new_tensor = tensor.new_empty((3,4))\n",
    "\n",
    "print('\\n new empty tensor (inherits dtype and device from original):')\n",
    "print(new_tensor)\n",
    "print('dtype:', new_tensor.dtype)\n",
    "print('device:', new_tensor.device)\n",
    "\n",
    "#create a new empty tensor on a different device\n",
    "if torch.cuda.is_available():\n",
    "    new_tensor_gpu = tensor.new_empty(\n",
    "        size=(2,3),\n",
    "        dtype=torch.float32,\n",
    "        device ='cuda'\n",
    "    )\n",
    "    print('\\n new empty tensor on GPU with dtype=torch.float32')\n",
    "    print(new_tensor_gpu)\n",
    "    print('dtype:', new_tensor_gpu.dtype)\n",
    "    print('dtype:', new_tensor_gpu.device)\n",
    "else:\n",
    "    print('\\nCUDA is not available . Skipping GPU tensor creation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original tensor:\n",
      "tensor([], dtype=torch.int32)\n",
      "dtype: torch.int32\n",
      "device: cpu\n",
      "\n",
      " nre tensosr filled with ones (inherits dtype and device from original:)\n",
      "tensor([[1, 1, 1],\n",
      "        [1, 1, 1]], dtype=torch.int32)\n",
      "dtype: torch.int32\n",
      "device: cpu\n",
      "\n",
      " CUDA is not available . Skipping GPU tensor creation\n"
     ]
    }
   ],
   "source": [
    "#Tensor.new_ones\n",
    "\n",
    "# creates a new tensor of a specified size, fillwd with ones.  THe new tensor inherits properties like dtype an device from the orignal tensor uness overridden\n",
    "\n",
    "import torch \n",
    "tensor = torch.tensor((),dtype=torch.int32)\n",
    "\n",
    "print('original tensor:')\n",
    "print(tensor)\n",
    "print('dtype:',tensor.dtype)\n",
    "print('device:',tensor.device)\n",
    "\n",
    "#filled with ones\n",
    "new_tensor = tensor.new_ones((2,3))\n",
    "print('\\n nre tensosr filled with ones (inherits dtype and device from original:)')\n",
    "print(new_tensor)\n",
    "print('dtype:',new_tensor.dtype)\n",
    "\n",
    "print('device:',new_tensor.device)\n",
    "\n",
    "# create a tensor on a different device and a dtype\n",
    "if torch.cuda.is_available():\n",
    "    new_tensor_gpu = tensor.new_ones(\n",
    "        size=(3,2),\n",
    "        dtype=torch.float32,\n",
    "        devicee='cuda'\n",
    "    )\n",
    "    print('\\nNew tensor filled with ones on GPU with dtype=torch.float32')\n",
    "    print(new_tensor_gpu)\n",
    "    print('dtype:',new_tensor_gpu.dtype)\n",
    "    print('device:',new_tensor_gpu.device)\n",
    "else:\n",
    "    print('\\n CUDA is not available . Skipping GPU tensor creation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original tensor:\n",
      "tensor([], dtype=torch.int32)\n",
      "dtype: torch.int32\n",
      "device: cpu\n",
      "\n",
      " nre tensosr filled with ones (inherits dtype and device from original:)\n",
      "tensor([[0, 0, 0],\n",
      "        [0, 0, 0]], dtype=torch.int32)\n",
      "dtype: torch.int32\n",
      "device: cpu\n",
      "\n",
      " CUDA is not available . Skipping GPU tensor creation\n"
     ]
    }
   ],
   "source": [
    "#Tensor.new_zeros\n",
    "\n",
    "# creates a new tensor of a specified size, fillwd with ones.  THe new tensor inherits properties like dtype an device from the orignal tensor uness overridden\n",
    "\n",
    "import torch \n",
    "tensor = torch.tensor((),dtype=torch.int32)\n",
    "\n",
    "print('original tensor:')\n",
    "print(tensor)\n",
    "print('dtype:',tensor.dtype)\n",
    "print('device:',tensor.device)\n",
    "\n",
    "#filled with ones\n",
    "new_tensor = tensor.new_zeros((2,3))\n",
    "print('\\n nre tensosr filled with ones (inherits dtype and device from original:)')\n",
    "print(new_tensor)\n",
    "print('dtype:',new_tensor.dtype)\n",
    "\n",
    "print('device:',new_tensor.device)\n",
    "\n",
    "# create a tensor on a different device and a dtype\n",
    "if torch.cuda.is_available():\n",
    "    new_tensor_gpu = tensor.new_zeros(\n",
    "        size=(3,2),\n",
    "        dtype=torch.float32,\n",
    "        devicee='cuda'\n",
    "    )\n",
    "    print('\\nNew tensor filled with ones on GPU with dtype=torch.float32')\n",
    "    print(new_tensor_gpu)\n",
    "    print('dtype:',new_tensor_gpu.dtype)\n",
    "    print('device:',new_tensor_gpu.device)\n",
    "else:\n",
    "    print('\\n CUDA is not available . Skipping GPU tensor creation')\n",
    "\n",
    "#Tensor.is_cuda\n",
    "# is True if the Tensor is sotred on the GPU False otherwise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "is float_tensor quantized?\n",
      "False\n",
      "\n",
      "is quantized_tensor quantized?\n",
      "True\n",
      "\n",
      " tensor details\n",
      "tensor([1., 2., 3.], size=(3,), dtype=torch.quint8,\n",
      "       quantization_scheme=torch.per_tensor_affine, scale=0.1, zero_point=0)\n",
      "scale 0.1\n",
      "zero point: 0\n",
      "dtype torch.quint8\n"
     ]
    }
   ],
   "source": [
    "#Tnesor.is_quqntized\n",
    "\n",
    "#property checks whether a tensor is quantized or not.\n",
    "# quantized tensors are sued in pytoch for low-precision computations , typically in scenarios like model optimmization for deployment on resrouce-contrained devices.\n",
    "\n",
    "import torch \n",
    "float_tensor = torch.tensor([1.0,2.0,3.0], dtype=torch.float32)\n",
    "\n",
    "print('is float_tensor quantized?')\n",
    "print(float_tensor.is_quantized)\n",
    "\n",
    "quantized_tensor = torch.quantize_per_tensor(\n",
    "    float_tensor, scale=0.1, zero_point=0, dtype=torch.quint8\n",
    ")\n",
    "\n",
    "#check if tensor is quantized\n",
    "print('\\nis quantized_tensor quantized?')\n",
    "print(quantized_tensor.is_quantized)\n",
    "\n",
    "# print details of the quantized tensor\n",
    "print('\\n tensor details')\n",
    "print(quantized_tensor)\n",
    "print('scale', quantized_tensor.q_scale())\n",
    "print('zero point:', quantized_tensor.q_zero_point())\n",
    "print('dtype',quantized_tensor.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "si regular_tensor a meta tensor?\n",
      "False\n",
      "\n",
      " is meta_tenosr a meta tensor?\n",
      "True\n",
      "\n",
      "Meta Tensor Details:\n",
      "Shape: torch.Size([3])\n",
      "Dtype: torch.float32\n",
      "Device: meta\n",
      "\n",
      "Accessing data from meta_tensor:\n",
      "tensor(..., device='meta', size=())\n"
     ]
    }
   ],
   "source": [
    "#Tensor.is_meta\n",
    "\n",
    "# this property checks whether a tensor is a meta tensor\n",
    "# meta tensors are special tensors that do not allocate memory for their data and are used primarlyy for shape and metadata inference without storing actual values\n",
    "\n",
    "import torch \n",
    "\n",
    "regular_tensor = torch.tensor([1.0, 2.0, 3.0], dtype=torch.float32)\n",
    "print('si regular_tensor a meta tensor?')\n",
    "print(regular_tensor.is_meta)\n",
    "\n",
    "meta_tensor = torch.empty(3, dtype=torch.float32, device='meta')\n",
    "print('\\n is meta_tenosr a meta tensor?')\n",
    "print(meta_tensor.is_meta)\n",
    "\n",
    "print# Print details of the meta tensor\n",
    "print(\"\\nMeta Tensor Details:\")\n",
    "print(\"Shape:\", meta_tensor.shape)\n",
    "print(\"Dtype:\", meta_tensor.dtype)\n",
    "print(\"Device:\", meta_tensor.device)\n",
    "\n",
    "# Attempt to access data from the meta tensor (will raise an error)\n",
    "try:\n",
    "    print(\"\\nAccessing data from meta_tensor:\")\n",
    "    print(meta_tensor[0])  # This will raise an error\n",
    "except RuntimeError as e:\n",
    "    print(\"Error:\", e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `torch.Tensor.device` returns torch.device object associated with tensor. this indicates whether tensro resides on the CPU or specific GPU. the device property of a tenspr tells where the tensor is located. operations between tensors on different devices will raise errors. by default tensors are created on the CPU unless explicityly moved to a GPU.\n",
    "    * `torch.device('cpu')` indicates the tensor is on the CPU.\n",
    "    * `torch.device('cuda:0')` indicates the tensor is on the first GPU.\n",
    "* `torch.Tensor.grad` stores gradient computed during backpropagation for a tensor that requires gradient tracking (requires_grad=True). Initially it is None and it gets populated after calling `backward()`.\n",
    "    * grad attribute\n",
    "        * is None by default\n",
    "        * become a tensor containing gradients after backward() called on a scalar loss or output tensor.\n",
    "        * accumulates a gradients if `backward()` is called multiple times (unless explicityly zeroed out using zero())\n",
    "    * to track gradients for a tensor\n",
    "        * set `requires_grad=True` when creating the tensor\n",
    "        * gradients are computed only for tensors involved in operations that require gradient computation\n",
    "        * when you call z.backwards() multiple times without resetting the computational graph , pytorcj will raise a runtime error. this happens because pytorch clears the intermediate vaules fo the comptational graph after the first call backward().\n",
    "            * these intermediate values are neceassary for a gradient computation, so attemptinig to compute gadients again without rebuilding the graph will fail\n",
    "* `torch.Tensor.ndim` is an alias for dim(). returns the number of dimensions of a tensor. scalar ndim 0 , vector ndim 1 matrix ndim 2\n",
    "* `torch.Tensor.real` extracts the real part of a complex-values tensor. if tensor is real-valued it simplyy returns the tensor itslef. data type like torch.cflaot and torch.cdouble will be removed and returns a new tensor containing only the real parts\n",
    "* `torch.Tensor.imag` extracts the imaginary part of a complex-valued tensor. it is only supported for tensor with complex data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU Tensor Device:\n",
      "cpu\n",
      "\n",
      "CUDA is not available. Skipping GPU-related operations.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Create a tensor on the CPU\n",
    "cpu_tensor = torch.tensor([1.0, 2.0, 3.0], dtype=torch.float32)\n",
    "\n",
    "# Check the device of the CPU tensor\n",
    "print(\"CPU Tensor Device:\")\n",
    "print(cpu_tensor.device)  # Output: cpu\n",
    "\n",
    "# Check if CUDA is available\n",
    "if torch.cuda.is_available():\n",
    "    # Move the tensor to the GPU (default GPU: cuda:0)\n",
    "    gpu_tensor = cpu_tensor.to(\"cuda\")\n",
    "    \n",
    "    # Check the device of the GPU tensor\n",
    "    print(\"\\nGPU Tensor Device:\")\n",
    "    print(gpu_tensor.device)  # Output: cuda:0\n",
    "    \n",
    "    # Move the tensor back to the CPU\n",
    "    cpu_tensor_again = gpu_tensor.to(\"cpu\")\n",
    "    \n",
    "    # Check the device after moving back to the CPU\n",
    "    print(\"\\nMoved Back to CPU Tensor Device:\")\n",
    "    print(cpu_tensor_again.device)  # Output: cpu\n",
    "else:\n",
    "    print(\"\\nCUDA is not available. Skipping GPU-related operations.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient before backward():\n",
      "None\n",
      "\n",
      "Gradient after backward():\n",
      "tensor([ 7.,  9., 11.])\n",
      "\n",
      "Gradient after second backward() call (accumulated):\n",
      "tensor([14., 18., 22.])\n",
      "\n",
      "Gradient after zeroing:\n",
      "tensor([0., 0., 0.])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Create a tensor with requires_grad=True to track gradients\n",
    "x = torch.tensor([2.0, 3.0, 4.0], requires_grad=True)\n",
    "\n",
    "# Define a function y = x^2 + 3x + 5\n",
    "y = x**2 + 3*x + 5\n",
    "\n",
    "# Compute the sum of y (scalar value) to allow backward()\n",
    "z = y.sum()\n",
    "\n",
    "# Before calling backward(), grad is None\n",
    "print(\"Gradient before backward():\")\n",
    "print(x.grad)  # Output: None\n",
    "\n",
    "# Perform backpropagation to compute gradients\n",
    "z.backward()\n",
    "\n",
    "# After calling backward(), grad contains the computed gradients\n",
    "print(\"\\nGradient after backward():\")\n",
    "print(x.grad)  # Output: [11., 13., 15.]\n",
    "\n",
    "# Recompute y and z to rebuild the computational graph\n",
    "y = x**2 + 3*x + 5\n",
    "z = y.sum()\n",
    "\n",
    "# Call backward() again without zeroing gradients (gradients accumulate)\n",
    "z.backward()\n",
    "\n",
    "print(\"\\nGradient after second backward() call (accumulated):\")\n",
    "print(x.grad)  # Output: [22., 26., 30.] (doubled due to accumulation)\n",
    "\n",
    "# Zero out the gradients to reset them\n",
    "x.grad.zero_()\n",
    "\n",
    "print(\"\\nGradient after zeroing:\")\n",
    "print(x.grad)  # Output: [0., 0., 0.]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scalar Tensor:\n",
      "Value: tensor(42)\n",
      "Number of Dimensions (ndim): 0\n",
      "\n",
      "1D Tensor (Vector):\n",
      "Shape: torch.Size([4])\n",
      "Number of Dimensions (ndim): 1\n",
      "\n",
      "2D Tensor (Matrix):\n",
      "Shape: torch.Size([2, 2])\n",
      "Number of Dimensions (ndim): 2\n",
      "\n",
      "3D Tensor:\n",
      "Shape: torch.Size([2, 3, 4])\n",
      "Number of Dimensions (ndim): 3\n",
      "\n",
      "4D Tensor (Batch of Images):\n",
      "Shape: torch.Size([8, 3, 64, 64])\n",
      "Number of Dimensions (ndim): 4\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Create a scalar tensor\n",
    "scalar = torch.tensor(42)\n",
    "print(\"Scalar Tensor:\")\n",
    "print(\"Value:\", scalar)\n",
    "print(\"Number of Dimensions (ndim):\", scalar.ndim)  # Output: 0\n",
    "print()\n",
    "\n",
    "# Create a 1D tensor (vector)\n",
    "vector = torch.tensor([1, 2, 3, 4])\n",
    "print(\"1D Tensor (Vector):\")\n",
    "print(\"Shape:\", vector.shape)\n",
    "print(\"Number of Dimensions (ndim):\", vector.ndim)  # Output: 1\n",
    "print()\n",
    "\n",
    "# Create a 2D tensor (matrix)\n",
    "matrix = torch.tensor([[1, 2], [3, 4]])\n",
    "print(\"2D Tensor (Matrix):\")\n",
    "print(\"Shape:\", matrix.shape)\n",
    "print(\"Number of Dimensions (ndim):\", matrix.ndim)  # Output: 2\n",
    "print()\n",
    "\n",
    "# Create a 3D tensor\n",
    "tensor_3d = torch.ones((2, 3, 4))\n",
    "print(\"3D Tensor:\")\n",
    "print(\"Shape:\", tensor_3d.shape)\n",
    "print(\"Number of Dimensions (ndim):\", tensor_3d.ndim)  # Output: 3\n",
    "print()\n",
    "\n",
    "# Create a 4D tensor (e.g., batch of images)\n",
    "tensor_4d = torch.randn((8, 3, 64, 64))  # Batch size=8, Channels=3, Height=64, Width=64\n",
    "print(\"4D Tensor (Batch of Images):\")\n",
    "print(\"Shape:\", tensor_4d.shape)\n",
    "print(\"Number of Dimensions (ndim):\", tensor_4d.ndim)  # Output: 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex Tensor:\n",
      "tensor([ 0.4002-0.7091j, -0.8971-0.4174j, -0.6482+0.7085j, -0.6612+1.0229j])\n",
      "\n",
      "Real Part of the Tensor:\n",
      "tensor([ 0.4002, -0.8971, -0.6482, -0.6612])\n",
      "\n",
      "Is the real part a real-valued tensor?\n",
      "False\n",
      "\n",
      "Real-Valued Tensor:\n",
      "tensor([1., 2., 3., 4.])\n",
      "\n",
      "Real Part of a Real-Valued Tensor:\n",
      "tensor([1., 2., 3., 4.])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Create a complex-valued tensor\n",
    "x = torch.randn(4, dtype=torch.cfloat)  # Random complex numbers\n",
    "print(\"Complex Tensor:\")\n",
    "print(x)\n",
    "\n",
    "# Extract the real part of the tensor\n",
    "real_part = x.real\n",
    "print(\"\\nReal Part of the Tensor:\")\n",
    "print(real_part)\n",
    "\n",
    "# Verify that the real part is a real-valued tensor\n",
    "print(\"\\nIs the real part a real-valued tensor?\")\n",
    "print(real_part.is_complex())  # Output: False\n",
    "\n",
    "# Create a real-valued tensor\n",
    "y = torch.tensor([1.0, 2.0, 3.0, 4.0])\n",
    "print(\"\\nReal-Valued Tensor:\")\n",
    "print(y)\n",
    "\n",
    "# Access the real property of a real-valued tensor\n",
    "real_y = y.real\n",
    "print(\"\\nReal Part of a Real-Valued Tensor:\")\n",
    "print(real_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex Tensor:\n",
      "tensor([-0.0473+0.2480j,  0.5865-1.1128j,  1.0534+0.5260j,  0.0574+0.0012j])\n",
      "\n",
      "Imaginary Part of the Tensor:\n",
      "tensor([ 0.2480, -1.1128,  0.5260,  0.0012])\n",
      "\n",
      "Is the imaginary part a real-valued tensor?\n",
      "False\n",
      "\n",
      "Real-Valued Tensor:\n",
      "tensor([1., 2., 3., 4.])\n",
      "\n",
      "Attempting to access the imaginary part of a real-valued tensor:\n",
      "Error: imag is not implemented for tensors with non-complex dtypes.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Create a complex-valued tensor\n",
    "x = torch.randn(4, dtype=torch.cfloat)  # Random complex numbers\n",
    "print(\"Complex Tensor:\")\n",
    "print(x)\n",
    "\n",
    "# Extract the imaginary part of the tensor\n",
    "imaginary_part = x.imag\n",
    "print(\"\\nImaginary Part of the Tensor:\")\n",
    "print(imaginary_part)\n",
    "\n",
    "# Verify that the imaginary part is a real-valued tensor\n",
    "print(\"\\nIs the imaginary part a real-valued tensor?\")\n",
    "print(imaginary_part.is_complex())  # Output: False\n",
    "\n",
    "# Attempt to access the imaginary part of a real-valued tensor\n",
    "y = torch.tensor([1.0, 2.0, 3.0, 4.0])\n",
    "print(\"\\nReal-Valued Tensor:\")\n",
    "print(y)\n",
    "\n",
    "try:\n",
    "    print(\"\\nAttempting to access the imaginary part of a real-valued tensor:\")\n",
    "    print(y.imag)\n",
    "except RuntimeError as e:\n",
    "    print(\"Error:\", e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `torch.Tensor.nbytes` returns a the total number of bytes consumed by the tensor's elements. It is calculated as \n",
    "    * nbytes = numberl() x element_size()\n",
    "    * nummel, gives number of elements in the tensor\n",
    "    * elements_size() gives the size of each element in the tensor\n",
    "    * computes the memory usage of the tensor's data in bytes\n",
    "    * only applies to tensors that do not use sparse storage layouts\n",
    "    * useful for understanding the memory footprint of tensors, especially when working with large models or datasets\n",
    "* `torch.Tensor.itemsize` property is an alias for element_size() it returns the size (in bytes) of a single element in the tensor\n",
    "* `torch.Tensor.abs` computes the element-wise absolute value of a tensor equivalent with ``\n",
    "* `torch.Tensor.acos()` alias `arccos()` computes inverse cosine (arccosine of a tensor) \n",
    "    * input values must ie in the range [-1,1] because the csine function output is bounded withing this range\n",
    "    * the output values are in radioans and lie in the range [0,pi]\n",
    "    * use for trigonometric clasculations of transofmations where you need to computes angles from cosine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "integer tensor:\n",
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6]], dtype=torch.int32)\n",
      "number of elements (numel): 6\n",
      "element size(bytes): 4\n",
      "total bytes consumed (nbytes): 24\n",
      "float tensor:\n",
      "tensor([[1., 2., 3.],\n",
      "        [4., 5., 6.]], dtype=torch.float64)\n",
      "number of elements (numel): 6\n",
      "element size (bytes): 8\n",
      "total bytes consumed (nbytes): 48\n",
      "high-dimensional tensor:\n",
      "tensor([[[ 2.0215, -0.3570, -1.9166, -0.5851],\n",
      "         [-0.6711, -0.8350,  0.8931, -0.6189],\n",
      "         [ 0.9530, -1.2006, -1.9954, -0.5458]],\n",
      "\n",
      "        [[ 0.5730, -2.1895,  0.8464,  1.1774],\n",
      "         [ 0.6392, -0.5943, -0.3627,  1.6737],\n",
      "         [-0.7921,  0.3601, -0.4904, -0.5312]]])\n",
      "element size (bytes): 4\n",
      "total bytes consumed (nbytes): 96\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "\n",
    "int_tensor = torch.tensor([[1,2,3],[4,5,6]], dtype=torch.int32)\n",
    "print('integer tensor:')\n",
    "print(int_tensor)\n",
    "print('number of elements (numel):',int_tensor.numel())\n",
    "print('element size(bytes):', int_tensor.element_size())\n",
    "print('total bytes consumed (nbytes):',int_tensor.nbytes)\n",
    "\n",
    "float_tensor = torch.tensor([[1.0,2.0,3.0],[4.0,5.0,6.0]],dtype=torch.float64)\n",
    "print('float tensor:')\n",
    "print(float_tensor)\n",
    "print('number of elements (numel):',float_tensor.numel())\n",
    "print('element size (bytes):',float_tensor.element_size())\n",
    "print('total bytes consumed (nbytes):',float_tensor.nbytes)\n",
    "\n",
    "high_dim_tensor = torch.randn(2,3,4,dtype=torch.float32)\n",
    "print('high-dimensional tensor:')\n",
    "print(high_dim_tensor)\n",
    "print('element size (bytes):',high_dim_tensor.element_size())\n",
    "print('total bytes consumed (nbytes):',high_dim_tensor.nbytes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "4\n",
      "8\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "\n",
    "int_tensor = torch.tensor([1,2,3], dtype=torch.int32)\n",
    "float32_tensor = torch.tensor([1.0,2.0,3.0], dtype=torch.float32)\n",
    "float64_tensor = torch.tensor([1,2,3], dtype=torch.float64)\n",
    "uint8_tensor = torch.tensor([1,2,3], dtype=torch.uint8)\n",
    "\n",
    "print(int_tensor.itemsize)\n",
    "print(float32_tensor.itemsize)\n",
    "print(float64_tensor.itemsize)\n",
    "print(uint8_tensor.itemsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-3.,  4., -5.,  6.])\n",
      "tensor([3., 4., 5., 6.])\n",
      "tensor([ 3.+4.j, -1.-1.j,  0.+2.j])\n",
      "tensor([5.0000, 1.4142, 2.0000])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "real_tensor = torch.tensor([-3.0, 4.0, -5.0, 6.0])\n",
    "abs_real_tensor = real_tensor.abs()\n",
    "complex_tensor = torch.tensor([3 + 4j, -1 - 1j, 0 + 2j], dtype=torch.cfloat)\n",
    "abs_complex_tensor = complex_tensor.abs()\n",
    "print(real_tensor)\n",
    "print(abs_real_tensor)\n",
    "print(complex_tensor)\n",
    "print(abs_complex_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Angular distance between users (radians): 0.7854077816009521\n",
      "Angular distance between users (degrees): 45.000553131103516\n"
     ]
    }
   ],
   "source": [
    "#  Cosine Similarity for Recommendation Systems\n",
    "# Physics Simulartion\n",
    "# Geospatial Data Analysis\n",
    "# Quantum Computing Simulations\n",
    "# Signal Processing\n",
    "import torch \n",
    "\n",
    "user1_embedding = torch.tensor([0.5,0.5,0.7071])\n",
    "user2_embedding = torch.tensor([0.7071, 0.7071, 0.0])\n",
    "\n",
    "# compute cosine similarity\n",
    "cosine_similarity = torch.dot(user1_embedding, user2_embedding)\n",
    "angular_distance_radians = torch.acos(cosine_similarity)\n",
    "angular_distance_degrees = angular_distance_radians * (180 / torch.pi)\n",
    "\n",
    "print(\"Angular distance between users (radians):\", angular_distance_radians.item())\n",
    "print(\"Angular distance between users (degrees):\", angular_distance_degrees.item())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `Tensor.add()` adds a scaler/tenosr to current tensor. opetioanll scaling the value by a factor/alpha\n",
    "* `Tensor.addbmm()` perform batch matrix-matrix multiplication and adds the result to a base tensor optionall scalling the input with beta and alpha\n",
    "* `Tensor.addcdiv()` perform an element-wise division of two tensors and adds the result scaled by a factor value to the base tensor.\n",
    "* `Tensor.addcmul()` perform element-wise multiplication of two tensors by a faactor vaue and adds it ot the base tensor\n",
    "* `Tensor.addmm()` perform matrix multiplication between two matrices and adds the result , scaled by a dactor alpha to the base tensor scaled by another factor beta\n",
    "* `Tensor.addmv()` performs a matrix-vector multiplication between a matrix and a vector scales the result by a factor, and adds it to a base tensor scaled by another factor beta , this is equivalent to calling torch.addmv()\n",
    "* `Tensor.addjoint()` computes conjugate transpose of a tensor it is particularlt useful for complex-values tensors\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[6, 7],\n",
      "        [8, 9]])\n",
      "tensor([[11, 22],\n",
      "        [33, 44]])\n",
      "tensor([[21, 42],\n",
      "        [63, 84]])\n",
      "tensor([[2, 4],\n",
      "        [4, 6]])\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "\n",
    "tensor = torch.tensor([[1,2],[3,4]])\n",
    "\n",
    "result_scalar = tensor.add(5)\n",
    "print(result_scalar)\n",
    "\n",
    "other_tensor = torch.tensor([[10,20],[30,40]])\n",
    "result_tensor = tensor.add(other_tensor)\n",
    "print(result_tensor)\n",
    "\n",
    "scaled_result = tensor.add(other_tensor, alpha=2)\n",
    "print(scaled_result)\n",
    "\n",
    "broadcast_tensor = torch.tensor([1,2]) # add a 1D tensor to a 2d tensor\n",
    "broadcast_result = tensor.add(broadcast_tensor)\n",
    "print(broadcast_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base Tensor:\n",
      "tensor([[1., 2., 3.],\n",
      "        [4., 5., 6.]])\n",
      "\n",
      "Result after addbmm (default beta=1, alpha=1):\n",
      "tensor([[ 6.7329,  6.4835,  3.8324],\n",
      "        [ 5.5145, 14.5752,  9.9945]])\n",
      "\n",
      "Result after addbmm (beta=0.5, alpha=2.0):\n",
      "tensor([[11.9657,  9.9670,  3.1648],\n",
      "        [ 5.0290, 21.6504, 10.9890]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Create a base tensor (to which the result will be added)\n",
    "base_tensor = torch.tensor([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]])  # New shape: [2, 3]\n",
    "print(\"Base Tensor:\")\n",
    "print(base_tensor)\n",
    "\n",
    "# Create batch1 and batch2 tensors for batch matrix multiplication\n",
    "batch1 = torch.randn(3, 2, 4)  # Shape: (batch_size=3, n=2, k=4)\n",
    "batch2 = torch.randn(3, 4, 3)  # Shape: (batch_size=3, k=4, m=3)\n",
    "\n",
    "# Perform addbmm with default beta=1 and alpha=1\n",
    "result = base_tensor.addbmm(batch1, batch2)\n",
    "print(\"\\nResult after addbmm (default beta=1, alpha=1):\")\n",
    "print(result)\n",
    "\n",
    "# Perform addbmm with custom beta=0.5 and alpha=2.0\n",
    "result_custom = base_tensor.addbmm(batch1, batch2, beta=0.5, alpha=2.0)\n",
    "print(\"\\nResult after addbmm (beta=0.5, alpha=2.0):\")\n",
    "print(result_custom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base Tensor:\n",
      "tensor([[1., 2.],\n",
      "        [3., 4.]])\n",
      "\n",
      "Result after addcdiv (default value=1):\n",
      "tensor([[6., 7.],\n",
      "        [8., 9.]])\n",
      "\n",
      "Result after addcdiv (value=0.5):\n",
      "tensor([[3.5000, 4.5000],\n",
      "        [5.5000, 6.5000]])\n",
      "\n",
      "Result after broadcasting addcdiv:\n",
      "tensor([[6., 7.],\n",
      "        [8., 9.]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Create a base tensor\n",
    "base_tensor = torch.tensor([[1.0, 2.0], [3.0, 4.0]])\n",
    "print(\"Base Tensor:\")\n",
    "print(base_tensor)\n",
    "\n",
    "# Create tensor1 and tensor2 for element-wise division\n",
    "tensor1 = torch.tensor([[10.0, 20.0], [30.0, 40.0]])\n",
    "tensor2 = torch.tensor([[2.0, 4.0], [6.0, 8.0]])\n",
    "\n",
    "# Perform addcdiv with default value=1\n",
    "result_default = base_tensor.addcdiv(tensor1, tensor2)\n",
    "print(\"\\nResult after addcdiv (default value=1):\")\n",
    "print(result_default)\n",
    "\n",
    "# Perform addcdiv with custom value=0.5\n",
    "result_custom = base_tensor.addcdiv(tensor1, tensor2, value=0.5)\n",
    "print(\"\\nResult after addcdiv (value=0.5):\")\n",
    "print(result_custom)\n",
    "\n",
    "# Broadcasting example: Addcdiv with smaller tensors\n",
    "base_tensor_broadcast = torch.tensor([[1.0, 2.0], [3.0, 4.0]])\n",
    "tensor1_broadcast = torch.tensor([10.0, 20.0])  # Shape: [2]\n",
    "tensor2_broadcast = torch.tensor([2.0, 4.0])   # Shape: [2]\n",
    "\n",
    "result_broadcast = base_tensor_broadcast.addcdiv(tensor1_broadcast, tensor2_broadcast)\n",
    "print(\"\\nResult after broadcasting addcdiv:\")\n",
    "print(result_broadcast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base tensor:\n",
      "tensor([[1., 2.],\n",
      "        [3., 4.]])\n",
      "\n",
      "result after cmul (default value=1)\n",
      "tensor([[ 21.,  62.],\n",
      "        [123., 204.]])\n",
      "\n",
      " Result after addcmul (value=0.5)\n",
      "tensor([[1., 2.],\n",
      "        [3., 4.]])\n",
      "\n",
      " result after broadcasting addcmul:\n",
      "tensor([[21., 62.],\n",
      "        [23., 64.]])\n"
     ]
    }
   ],
   "source": [
    "#addcmul\n",
    "\n",
    "import torch \n",
    "\n",
    "base_tensor = torch.tensor([[1.0,2.0],[3.0,4.0]])\n",
    "print('base tensor:')\n",
    "print(base_tensor)\n",
    "\n",
    "# create tensor1 and tensor2 for element-wise multiplication\n",
    "tensor1 = torch.tensor([[10.0,20.0], [30.0,40.0]])\n",
    "tensor2 = torch.tensor([[2.0,3.0],[4.0,5.0]])\n",
    "\n",
    "#perform addcmul with default value=1\n",
    "result_default = base_tensor.addcmul(tensor1, tensor2)\n",
    "print('\\nresult after cmul (default value=1)')\n",
    "print(result_default)\n",
    "\n",
    "result_custom = base_tensor.addcmul(tensor1, tensor2, value=0)\n",
    "print('\\n Result after addcmul (value=0.5)')\n",
    "print(result_custom)\n",
    "\n",
    "#broadcasting example : addcmul with smaller tensors\n",
    "base_tensor_broadcast = torch.tensor([[1.0,2.0],[3.0,4.0]])\n",
    "tensor1_broadcast = torch.tensor([10.0, 20.0])\n",
    "tensor2_broadcast = torch.tensor([2.0,3.0])\n",
    "\n",
    "result_broadcast = base_tensor_broadcast.addcmul(tensor1_broadcast, tensor2_broadcast)\n",
    "print('\\n result after broadcasting addcmul:')\n",
    "print(result_broadcast)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2.],\n",
      "        [3., 4.]])\n",
      "result after addmm (default beta=1, alpha=1)\n",
      "tensor([[ 0.5669, -2.3521],\n",
      "        [ 3.3084,  8.5904]])\n",
      "\n",
      "result after addmm (beta=0.5, alpha=2.0):\n",
      "tensor([[-0.3661, -7.7041],\n",
      "        [ 2.1169, 11.1808]])\n",
      "\n",
      " result after broadcasting addmm:\n",
      "tensor([[ 0.5669, -2.3521],\n",
      "        [ 1.3084,  6.5904]])\n"
     ]
    }
   ],
   "source": [
    "#addmm\n",
    "\n",
    "print(base_tensor)\n",
    "\n",
    "mat1 = torch.randn(2,3)\n",
    "mat2 = torch.randn(3,2)\n",
    "\n",
    "result_default = base_tensor.addmm(mat1, mat2)\n",
    "print('result after addmm (default beta=1, alpha=1)')\n",
    "print(result_default)\n",
    "\n",
    "#perform addmm with custom beta=0.5 and alpha=2.0\n",
    "result_custom = base_tensor.addmm(mat1, mat2, beta=0.5, alpha=2.0)\n",
    "print('\\nresult after addmm (beta=0.5, alpha=2.0):')\n",
    "print(result_custom)\n",
    "\n",
    "#broadcasting base tensor with shape [1,2]\n",
    "base_tensor_broadcast = torch.tensor([[1.0,2.0]])\n",
    "result_broadcast = base_tensor_broadcast.addmm(mat1 , mat2)\n",
    "print('\\n result after broadcasting addmm:')\n",
    "print(result_broadcast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparse Base Tensor:\n",
      "tensor(indices=tensor([[0, 1],\n",
      "                       [1, 2]]),\n",
      "       values=tensor([3., 4.]),\n",
      "       size=(3, 3), nnz=2, layout=torch.sparse_coo)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "sspaddmm: Argument #2: matrices expected, got 0D tensor",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 19\u001b[39m\n\u001b[32m     16\u001b[39m mat2 = torch.tensor([[ \u001b[32m0.6267\u001b[39m, -\u001b[32m0.1466\u001b[39m,  \u001b[32m0.4464\u001b[39m],\n\u001b[32m     17\u001b[39m                      [-\u001b[32m0.4601\u001b[39m, -\u001b[32m0.1870\u001b[39m, -\u001b[32m0.9420\u001b[39m]])\n\u001b[32m     18\u001b[39m \u001b[38;5;66;03m# Perform sspaddmm with default beta=1 and alpha=1\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m result_default = \u001b[43msparse_tensor\u001b[49m\u001b[43m.\u001b[49m\u001b[43msspaddmm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmat1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmat2\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     20\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mResult after sspaddmm (default beta=1, alpha=1):\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     21\u001b[39m \u001b[38;5;28mprint\u001b[39m(result_default)\n",
      "\u001b[31mRuntimeError\u001b[39m: sspaddmm: Argument #2: matrices expected, got 0D tensor"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Create a sparse base tensor (self)\n",
    "indices = torch.tensor([[0, 1], [1, 2]])  # Indices of non-zero elements\n",
    "values = torch.tensor([3.0, 4.0])         # Values of non-zero elements\n",
    "size = (3, 3)                             # Size of the sparse tensor\n",
    "sparse_tensor = torch.sparse_coo_tensor(indices, values, size)\n",
    "print(\"Sparse Base Tensor:\")\n",
    "print(sparse_tensor)\n",
    "\n",
    "# Create dense mat1 and mat2 for matrix multiplication\n",
    "mat1 = torch.tensor([[ 0.7740, -0.6338],\n",
    "                     [ 0.1909, -0.4897],\n",
    "                     [-0.4463, -0.3699]])\n",
    "\n",
    "mat2 = torch.tensor([[ 0.6267, -0.1466,  0.4464],\n",
    "                     [-0.4601, -0.1870, -0.9420]])\n",
    "# Perform sspaddmm with default beta=1 and alpha=1\n",
    "result_default = sparse_tensor.sspaddmm(mat1, mat2)\n",
    "print(\"\\nResult after sspaddmm (default beta=1, alpha=1):\")\n",
    "print(result_default)\n",
    "\n",
    "# Perform sspaddmm with custom beta=0.5 and alpha=2.0\n",
    "result_custom = sparse_tensor.sspaddmm(mat1, mat2, beta=0.5, alpha=2.0)\n",
    "print(\"\\nResult after sspaddmm (beta=0.5, alpha=2.0):\")\n",
    "print(result_custom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base tensor\n",
      "tensor([1., 2.])\n",
      "result after addmv (default beta=1, alpha=1):\n",
      "tensor([15., 34.])\n",
      "\n",
      "result after addmv (beta=0.5, alpha=2.0)\n",
      "tensor([28.5000, 65.0000])\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "\n",
    "base_tensor = torch.tensor([1.0,2.0])\n",
    "print('base tensor')\n",
    "print(base_tensor)\n",
    "\n",
    "mat = torch.tensor([[1.0,2.0,3.0],[4.0,5.0,6.0]])\n",
    "vec = torch.tensor([1.0,2.0,3.0])\n",
    "\n",
    "# perform addmv with default beta=1 and alpha=1\n",
    "result_default = base_tensor.addmv(mat, vec)\n",
    "print('\\rresult after addmv (default beta=1, alpha=1):')\n",
    "print(result_default)\n",
    "\n",
    "#perform addmv with custom beta=0.5 and alpha=2.0\n",
    "result_custom = base_tensor.addmv(mat, vec, beta=0.5, alpha=2.0)\n",
    "print('\\nresult after addmv (beta=0.5, alpha=2.0)')\n",
    "print(result_custom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base matrix\n",
      "tensor([[1., 2.],\n",
      "        [3., 4.]])\n",
      "\n",
      " result after addr (default beta=1 alpha=1):\n",
      "tensor([[ 4.,  6.],\n",
      "        [ 9., 12.]])\n",
      "\n",
      "result after addr (beta=0.5, alpha=2.0)\n",
      "tensor([[ 6.5000,  9.0000],\n",
      "        [13.5000, 18.0000]])\n",
      "\n",
      " base matrix after add_ (in-place modification)\n",
      "tensor([[ 6.5000,  9.0000],\n",
      "        [13.5000, 18.0000]])\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "\n",
    "base_matrix = torch.tensor([[1.0,2.0],[3.0,4.0]])\n",
    "print('base matrix')\n",
    "print(base_matrix)\n",
    "\n",
    "vec1 = torch.tensor([1.0,2.0])\n",
    "vec2 = torch.tensor([3.0,4.0])\n",
    "\n",
    "result_default = base_matrix.addr(vec1, vec2)\n",
    "print('\\n result after addr (default beta=1 alpha=1):')\n",
    "print(result_default)\n",
    "\n",
    "result_custom = base_matrix.addr(vec1, vec2, beta=0.5, alpha=2.0)\n",
    "print('\\nresult after addr (beta=0.5, alpha=2.0)')\n",
    "print(result_custom)\n",
    "\n",
    "#perform addr_\n",
    "base_matrix.addr_(vec1,vec2, beta=0.5, alpha=2.0)\n",
    "print('\\n base matrix after add_ (in-place modification)')\n",
    "print(base_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "are tensors close with default tolerences True\n",
      "are tensors close with custom tolerances? True\n",
      "are tensors not close? False\n"
     ]
    }
   ],
   "source": [
    "#addjoint()\n",
    "\n",
    "tensor1 = torch.tensor([1.0,2.0,3.0])\n",
    "tensor2 = torch.tensor([1.0,2.00001,3.0])\n",
    "\n",
    "are_close_default = torch.allclose(tensor1, tensor2)\n",
    "print('are tensors close with default tolerences', are_close_default)\n",
    "\n",
    "are_close_custom = torch.allclose(tensor1, tensor2, rtol=1e-5, atol=1e-8)\n",
    "print('are tensors close with custom tolerances?', are_close_custom)\n",
    "\n",
    "tensor3 = torch.tensor([1.0,2.1,3.0])\n",
    "are_not_close = torch.allclose(tensor1, tensor3)\n",
    "print('are tensors not close?', are_not_close)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checks if all elements of two tensors are close withihon tolerance\n",
    "\n",
    "#allclose\n",
    "\n",
    "a = torch.tensor([1.0,2.0,3.0])\n",
    "b = torch.tensor([1.0,2.00001,2.99999])\n",
    "\n",
    "print(torch.allclose(a,b)) # True \n",
    "\n",
    "c = torch.tensor([1.0,2.1,3.0])\n",
    "print(torch.allclose(a,c))  # False\n",
    "\n",
    "# maximum value of all elements or along a specific dimentsion\n",
    "# amax()\n",
    "x = torch.tensor([[1,2,3],[4,5,6]])\n",
    "print(torch.amax(x))\n",
    "\n",
    "# returns the minimum value similarly\n",
    "#amin()\n",
    "print(torch.amin(x))\n",
    "print(torch.amin(x,dim=1))\n",
    "\n",
    "# returns both min and max at the same time\n",
    "#aminmax\n",
    "min_vals , max_vals = torch.aminmax(, dim=1)\n",
    "print(\"Min:\", min_vals)\n",
    "print(\"Max:\", max_vals)\n",
    "\n",
    "\n",
    "# computes the angle in randians of each element in a complex-valued tensor\n",
    "# angle()\n",
    "tensor = torch.tensor([1 + 1j, -1 -1j], dtype=torch.cfloat)\n",
    "print('complex tensor:')\n",
    "print(tensor)\n",
    "\n",
    "angles = tensor.angle()\n",
    "print('\\nangles in radians')\n",
    "print(angles)\n",
    "\n",
    "#  applies a function to each element of the tensor in-place\n",
    "tensor = torch.tensor([1.0,2.0,3.0,4.0])\n",
    "print('original tensor:')\n",
    "print(tensor)\n",
    "\n",
    "tensor.apply_(lambda x:x ** 2)\n",
    "print('\\n tensor after applyingi lambda functions:')\n",
    "print(tensor)\n",
    "\n",
    "#returns the index of the maximum value along a specified dimension\n",
    "\n",
    "tensor = torch.tensor([[1,3,4],[2,4,6]])\n",
    "print('tensor:')\n",
    "print(tensor)\n",
    "\n",
    "argmax_result = tensor.argmax(dim=1)\n",
    "print('\\nindex of maximum value along dim=1')\n",
    "print(argmax_result)\n",
    "\n",
    "#returns the index of the minimum value along a specified dimension\n",
    "print('\\nindex of the minimum value along dim=1',tensor.argmin(dim=1))\n",
    "\n",
    "#returns the indices that would sort the tensor along a specified dimension\n",
    "#argsort()\n",
    "tensor = torch.tensor([3,1,4,2])\n",
    "print('\\nindices that would sort the tensor:', tensor.argsort())\n",
    "\n",
    "# returns the indices of non-zero elements in the tensor\n",
    "#argwhere()\n",
    "tensor = torch.tensor([[0,1],[2,0]])\n",
    "print('\\nindices of non-zero elements:', tensor.argwhere())\n",
    "\n",
    "#computes the arcsine(inverse sine) of each element in the tensor\n",
    "#asin #arcsine\n",
    "tensor = torch.tensor([-1.0,0.0,1.0])\n",
    "print('\\narcsine of each element',tensor.asin())\n",
    "\n",
    "# creates a view of the tensor with specified sizez, stride and storage offset . useful for advanced tensor amnipulations but should be used carefully as it can lead to undefined behaviur if misused\n",
    "# as_stride()\n",
    "tensor = torch.arange(9).reshapep(3,3)\n",
    "print('\\nstirded tensor (size=(2,2), stride=(3,1)):',torch.as_strided(tensor, size=(2,2), stride=(3,1)))\n",
    "\n",
    "#computes the artangent of eaech element in the tensor\n",
    "#atan\n",
    "tensor = torch.tensor([0.0, 1.0, -1.0])\n",
    "print(\"\\nArctangent of each element:\",tensor.atan())\n",
    "\n",
    "# computes the element-wise arctangent of two tensors , considering their signs ot determine the correct quadrant\n",
    "tensor1 = torch.tensor([1.0, -1.0, 1.0])\n",
    "tensor2 = torch.tensor([1.0, 1.0, -1.0])\n",
    "\n",
    "print(\"\\nElement-wise atan2 result:\",torch.atan2(tensor1, tensor2))\n",
    "\n",
    "#check if all elements in the tensor evaluate to True along a specified dimension\n",
    "#all\n",
    "tensor = torch.tensor([[True, True], [True, False]])\n",
    "print(\"\\nAre all elements True?\", tensor.all())\n",
    "print(\"\\nAre all elements True along dim=0?\",tensor.all(dim=0))\n",
    "\n",
    "#checks if any element i the tensor evalutes to True along a specified dimension\n",
    "#any()\n",
    "\n",
    "tensor = torch.tensor([[False, False], [True, False]])\n",
    "print(\"\\nIs any element True?\",tensor.any())\n",
    "print(\"\\nIs any element True along dim=1?\",tensor.any(dim=1))\n",
    "\n",
    "\n",
    "# computes the gradient of the current tensor with respect to graph leaves . this is used in autograd for back propagation\n",
    "# backward()\n",
    "x = torch.tensor([2.0, 3.0], requires_grad=True)\n",
    "y = x.pow(2).sum()\n",
    "y.backward() #compute gradients\n",
    "print(\"Gradients of x:\")\n",
    "print(x.grad)\n",
    "\n",
    "#performs batch matrix-matrix addition and multiplication \n",
    "#baddbmm\n",
    "batch1 = torch.randn(2, 3, 4)  # Shape: [2, 3, 4]\n",
    "batch2 = torch.randn(2, 4, 5)  # Shape: [2, 4, 5]\n",
    "base_tensor = torch.randn(2, 3, 5)  # Shape: [2, 3, 5]\n",
    "print(\"Result of baddbmm:\",base_tensor.baddbmm(batch1, batch2, beta=0.5, alpha=2.0))\n",
    "\n",
    "#returns a tensor where each element is independently sampled from a bernoulli distribution defined by the input tensor's values\n",
    "#bernoulli()\n",
    "probs = torch.tensor([0.3, 0.7, 0.5])\n",
    "print(\"\\nBernoulli Samples:\", probs.bernoulli())\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
