{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base Tensor:\n",
      "tensor([[0.0569, 0.4049, 0.2065, 0.2408],\n",
      "        [0.8231, 0.6954, 0.0018, 0.7668],\n",
      "        [0.3474, 0.5443, 0.5155, 0.7470],\n",
      "        [0.1728, 0.7847, 0.6770, 0.3676]])\n",
      "\n",
      "View Tensor (reshaped to 2x8):\n",
      "tensor([[0.0569, 0.4049, 0.2065, 0.2408, 0.8231, 0.6954, 0.0018, 0.7668],\n",
      "        [0.3474, 0.5443, 0.5155, 0.7470, 0.1728, 0.7847, 0.6770, 0.3676]])\n",
      "\n",
      "Do `base_tensor` and `view_tensor` share the same data?\n",
      "True\n",
      "\n",
      "After modifying the view tensor:\n",
      "View Tensor:\n",
      "tensor([[3.1400e+00, 4.0494e-01, 2.0647e-01, 2.4084e-01, 8.2310e-01, 6.9536e-01,\n",
      "         1.8490e-03, 7.6678e-01],\n",
      "        [3.4742e-01, 5.4429e-01, 5.1549e-01, 7.4701e-01, 1.7281e-01, 7.8473e-01,\n",
      "         6.7705e-01, 3.6760e-01]])\n",
      "Base Tensor (reflects the change):\n",
      "tensor([[3.1400e+00, 4.0494e-01, 2.0647e-01, 2.4084e-01],\n",
      "        [8.2310e-01, 6.9536e-01, 1.8490e-03, 7.6678e-01],\n",
      "        [3.4742e-01, 5.4429e-01, 5.1549e-01, 7.4701e-01],\n",
      "        [1.7281e-01, 7.8473e-01, 6.7705e-01, 3.6760e-01]])\n",
      "\n",
      "Transposed Tensor (non-contiguous):\n",
      "tensor([[3.1400e+00, 8.2310e-01, 3.4742e-01, 1.7281e-01],\n",
      "        [4.0494e-01, 6.9536e-01, 5.4429e-01, 7.8473e-01],\n",
      "        [2.0647e-01, 1.8490e-03, 5.1549e-01, 6.7705e-01],\n",
      "        [2.4084e-01, 7.6678e-01, 7.4701e-01, 3.6760e-01]])\n",
      "Is the transposed tensor contiguous?\n",
      "False\n",
      "\n",
      "Contiguous Tensor (after calling `.contiguous()`):\n",
      "tensor([[3.1400e+00, 8.2310e-01, 3.4742e-01, 1.7281e-01],\n",
      "        [4.0494e-01, 6.9536e-01, 5.4429e-01, 7.8473e-01],\n",
      "        [2.0647e-01, 1.8490e-03, 5.1549e-01, 6.7705e-01],\n",
      "        [2.4084e-01, 7.6678e-01, 7.4701e-01, 3.6760e-01]])\n",
      "Is the new tensor contiguous?\n",
      "True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fadzw\\AppData\\Local\\Temp\\ipykernel_23872\\844185944.py:15: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  print(base_tensor.storage().data_ptr() == view_tensor.storage().data_ptr())  # Output: True\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "base_tensor = torch.rand(4,4)\n",
    "print(\"Base Tensor:\")\n",
    "print(base_tensor)\n",
    "\n",
    "view_tensor = base_tensor.view(2,8)\n",
    "print('\\nView Tensor (reshaped to 2x8)')\n",
    "print(view_tensor)\n",
    "\n",
    "print('\\n Do `base_tensor` and `view_tensor` share the same data')\n",
    "print(base_tensor.storage.epoch().data_ptr() == view_tensor.storage().data_ptr())\n",
    "\n",
    "view_tensor[0][0] = 3.14\n",
    "print('\\n after modifying the view tensor:')\n",
    "print('view tensr:')\n",
    "print(view_tensor)\n",
    "print('base tensor (reflects the change:)')\n",
    "print(base_tensor)\n",
    "\n",
    "non_contiguous_tensor = base_tensor.transpose(0,1)\n",
    "print('\\nTranposed Tensor (non-contiguous):')\n",
    "print(non_contiguous_tensor)\n",
    "print('is the transposed tenser contiguos?')\n",
    "print(non_contiguous_tensor)\n",
    "\n",
    "contiguous_tensor = non_contiguous_tensor.contiguos()\n",
    "print('\\nContiguous Tensor (after calling `.contiguous()`):')\n",
    "print(contiguous_tensor)\n",
    "print('Is the new tensor contiguous?')\n",
    "print(contiguous_tensor.is_contiguous())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base tensor:\n",
      "tensor([[[ 0,  1,  2,  3],\n",
      "         [ 4,  5,  6,  7],\n",
      "         [ 8,  9, 10, 11]],\n",
      "\n",
      "        [[12, 13, 14, 15],\n",
      "         [16, 17, 18, 19],\n",
      "         [20, 21, 22, 23]]])\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "\n",
    "tensor = torch.arange(24).reshape(2,3,4)\n",
    "print('base tensor:')\n",
    "print(tensor)\n",
    "\n",
    "#sparse tensor for indices() example \n",
    "indices = torch.tensor([[0,1],[1,2]])\n",
    "values = torch.tensor([3.0,4.0])\n",
    "sparse_tensor = torch.sparse_coo_tensor(indices, values, size=(3,3))\n",
    "\n",
    "#1. adjoint() (Alias for .mH)\n",
    "# print('\\nAdjoint (Conjugate Transpose):',tensor.adjoint())\n",
    "\n",
    "#2. as_strided()\n",
    "# print('\\nas_strided():',torch.as_strided(tensor, size=(2,6), stride=(12,1)))\n",
    "\n",
    "#3.0 detach()\n",
    "# print('\\ndetach():',tensor.detach())\n",
    "\n",
    "#4.0 diagonal()\n",
    "# print('\\ndiagonal():',tensor.diagonal(offset=0, dim1=1, dim2=2))\n",
    "\n",
    "# 5.0 expand()\n",
    "# print('expand()',tensor.expand(3,2,3,4))\n",
    "\n",
    "# 6. expand_as()\n",
    "# other_tensor = torch.zeros(3,2,3,4)\n",
    "# print('expand_as()',tensor.expand_as(other_tensor))\n",
    "\n",
    "# # 7.0 movedim()\n",
    "# print('\\nmovedim():',(torch.movedim(tensor, source=0, destination=-1)).shape)\n",
    "\n",
    "# # 8.0 narrow()\n",
    "# print('\\nnarrow():',tensor.narrow(dim=1, start=1, length=2))\n",
    "\n",
    "# #9.0 permute()\n",
    "# print('\\npermute():', (tensor.permute(2,0,1)).shape)\n",
    "\n",
    "# # 10 select()\n",
    "# print('\\nselect():',tensor.select(dim=0,index=1))\n",
    "\n",
    "# # 11. squeeze()\n",
    "# print('\\nsqueeze()',tensor.squeeze())\n",
    "\n",
    "# # 12. tranpose()\n",
    "# print('\\ntranpose', (tensor.transpose(1,2)).shape)\n",
    "\n",
    "# # 13. t() Transfopose for 2D tensors\n",
    "# two_d_tensor = torch.rand(3,4)\n",
    "# print('\\nt():',two_d_tensor.t())\n",
    "\n",
    "# # 14 T (property for transpose)\n",
    "# print('\\nT (property):',two_d_tensor.T.shape)\n",
    "\n",
    "# # 15. H (Conjugate transpose for complex tensors)\n",
    "complex_tensor = torch.tensor([[1 + 2j, 3 + 4j], [5 + 6j, 7 + 8j]], dtype=torch.cfloat)\n",
    "# print('\\n H (Hermitian/Conjugate transpose):', complex_tensor.H)\n",
    "\n",
    "# # 16 mT (Matrix transpose property)\n",
    "# print('\\nmT (matrix transpose):', complex_tensor.mT)\n",
    "\n",
    "# # 17 mH (Matrix Hermitian/conjugate transpose property)\n",
    "# print('\\nmH matrix hermitian', complex_tensor.mH)\n",
    "\n",
    "# # 18. real 19. imag\n",
    "# print('\\nReal Part:', complex_tensor.real, '\\nImage Part:', complex_tensor.imag)\n",
    "\n",
    "# # 20 view_as_real\n",
    "# print('\\nview_as_real():',torch.view_as_real(complex_tensor))\n",
    "\n",
    "# # 21 unflatten\n",
    "# print('\\nunflatten',(tensor.unflatten(dim=1, sizes=(1,3))).shape)\n",
    "\n",
    "# # 22 unfold()\n",
    "# print('\\nunfold',(tensor.unfold(dimension=2, size=2, step=1)).shape)\n",
    "\n",
    "# # 23 unsquueze\n",
    "# print('\\nunsqueeze():', tensor.unsqueeze(dim=0))\n",
    "\n",
    "# # 24 view()\n",
    "# print('\\nview():',tensor.view(2,-1))\n",
    "\n",
    "# #25 view_as()\n",
    "# other_tensor_view = torch.zeros(2,12)\n",
    "# print('\\nview_as():', (tensor.view_as(other_tensor_view)).shape)\n",
    "\n",
    "# #26 unbind()\n",
    "# print('\\nunbind():',torch.unbind(tensor,dim=0))\n",
    "# for i,t in enumerate((torch.unbind(tensor,dim=0))):\n",
    "#     print(f'Tensor {i}: {t}')\n",
    "\n",
    "#27 split()\n",
    "# split_tensor = torch.split(tensor,split_size_or_sections=2,dim=1)\n",
    "# print('\\nsplit():')\n",
    "# for i,t in enumerate(split_tensor):\n",
    "#     print(f'H-Slit {i} : {t.shape}')\n",
    "\n",
    "\n",
    "#27 split()\n",
    "# split_tensors = torch.split(tensor, split_size_or_sections=2, dim=1)\n",
    "# print(\"\\nsplit():\")\n",
    "# for i, t in enumerate(split_tensors):\n",
    "#     print(f\"Split {i}: {t.shape}\")\n",
    "\n",
    "#28 hsplit()\n",
    "# hsplit_tensors = torch.hsplit(tensor,2)\n",
    "# print('\\nhsplit():')\n",
    "# for i,t in enumerate(hsplit_tensors):\n",
    "#     print(f'H-split {i}: {t.shape}')\n",
    "\n",
    "#29 vsplit()\n",
    "# vsplit_tensors = torch.vsplit(tensor, 2)\n",
    "# print(\"\\nvsplit():\")\n",
    "# for i, t in enumerate(vsplit_tensors):\n",
    "#     print(f\"V-Split {i}: {t.shape}\")\n",
    "\n",
    "#30 tensor_split()\n",
    "# tensor_split_tensors = torch.tensor_split(tensor, indices_or_sections=2, dim=1)\n",
    "# print('\\ntensor_split():')\n",
    "# for i,t in enumerate(tensor_split_tensors):\n",
    "#     print(f'Teensor Split: {i}:{t.shape}')\n",
    "\n",
    "#31 split_with_sizes()\n",
    "# split_with_sizes_tensors = torch.split_with_sizes(tensor,split_sizes=[1,2],dim=1)\n",
    "# print('\\nsplit_with_sizes():')\n",
    "# for i,t in enumerate(split_with_sizes_tensors):\n",
    "#     print(f'split with sizes {i}: {t.shape}')\n",
    "\n",
    "#32 swapaxes()\n",
    "# swapped_axes_tensor = torch.swapaxes(tensor, axis0=1, axis1=2)\n",
    "# print('\\nswapaxes():')\n",
    "# print(swapped_axes_tensor.shape)\n",
    "\n",
    "#swapdims()\n",
    "# swapped_dims_tensor = torch.swapdims(tensor, dim0=1,dim1=2)\n",
    "# print('\\nswapdims():')\n",
    "# print(swapped_dims_tensor)\n",
    "\n",
    "#34. chunk\n",
    "# chunk_tensors = torch.chunk(tensor, chunks=2, dim=1)\n",
    "# print('\\nchunk():')\n",
    "# for i,t in enumerate(chunk_tensors):\n",
    "#     print(f'chunk {i}: {t.shape}')\n",
    "\n",
    "#35. indices() (Sparse Tennsor Only)\n",
    "# sparse_indices = sparse_tensor.indices()\n",
    "# print(\"\\nindices() (Sparse Tensor):\")\n",
    "# print(sparse_indices)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
